{"pages":[{"title":"Curriculum Vitae (Xu Feng, undergraduate)","text":"CareerTencent Technology(Shenzhen) Co.,Ltd., Shenzhen, China (Jul 2021 - Sept 2021)I worked as a Backend Engineer (后台开发，really don’t know the precise translation) of WeChat Group, which was the first summer intern in my life. My job was to assist in the optimization and improvement of the Data Quality Platform of WeChat Search, including developing the function of bulk assigning and releasing tasks for Data Annotation Platform, optimizing the interface of pulling random logs of search information for Diff Platform (one kind ofalgorithm test system), which improved the accuracy and efficiency of performing tests for searching algorithms. Also, I created web pages for Query Analysis Platform, which helped evaluate the performance of searching algorithms. Two month was too short, but I still tried my best to understand the backend architecture, disaster tolerance, message sending&amp;recieving, searching architecture and common backend components of WeChat App and learnd to use the monitoring&amp;analysing system, modifying&amp;releasing system, quality&amp;capacity&amp;cost management system on WeChat Operation Platform. Hope the internship would be a great opening of my career. EducationXi’an Jiaotong University, Xi’an, China (Sept 2018 - Jul 2022 Expected)B.Eng. in Artificial Intelligence. After graduating from high school, AI was the most popular branch of CS at that time, partly because of which I chose it as my major. However, gradually I found that I had not much interest in AI but were crazy about conventional fields of CS, such as DB, OS, Algorithm, Internet, Software… Therefore, I mainly focused on courses of CS, but without totally giving up AI. University of California, Berkeley, CA, USA (Jan 2020 - May 2020)Berkeley International Student Program (BISP), Department of Computer Science The most wonderful experience during undergraduate years! During the semester in UCB, I enrolled in three highly challenging CS courses and was given deep insights into computer science theories. This experience inspired me to apply for international graduate programs in CS and encouraged me to concentrate on my career as a software/database/system engineer. SkillsProgramming Languages C, C++: mostly used, favorite Python, Java, SQL: occasionally used HTML/CSS/JS, Matlab: not very proficient Other Latex, Markdown, Git: proficient Shell, Linux: not bad About the WebsiteIt’s fast and easy to learned something only by reading. When it comes to writing down what you’ve learned or sharing your understandings with others, I always find that I was not truly understanding it. I hope writing blogs could help me test whether I’ve figured out the important details of each topic. And of course, sharing! 😉","link":"/about/index.html"}],"posts":[{"title":"面试-2021微信暑期实习","text":"Abstract: 记人生第一次实习面试的心理历程。。。 Quick Link： 面试-C++ 面试-计算机网络与网络编程 面试-数据库系统 1. Background2021年2月份，呕心沥血地练习了1个月的托福，成功地考出了与第一次裸考一样的分数，瞬间心灰意冷。大三下学期开学初，没啥动力继续学托福和GRE，而且上半学期没啥课，百无聊赖之际就买了本《深入理解Linux内核》一书随便翻翻。 谁知此书竟有无比玄妙之处，把我之前零零散散自学的几门课的知识连成了线，好多以前懵懵懂懂的东西现在一下子清晰起来。看完后，不禁虎躯一震，自信心爆棚，心想：留学申请要刷软背景，而且身边有大佬大二下学期就去字节实习了，我暑假也可以找个实习啊！虽然但是，贪玩的我还是去参加了4月10日的华山挑战赛😅 累死累活地爬完山回来，打开电脑准备投递实习。选哪个公司呢？目标高点，直接BAT里面选吧。字节？不喜欢玩抖音🙃 阿里？最近风评好像很差🙃 那就腾讯吧，反正QQ、微信一直都在用。 打开腾讯实习招聘，选择后台开发岗位后还要选部门。一眼望去，基本都不认识，除了WXG。WX=&gt;Wei Xin，那就这个吧🤣 谁又会知道最后竟然选择了个hard难度的？？？ 2. Preparation到腾讯校招的网站上看了下岗位要求，计划就按这个准备： 必须具备的： 扎实的编程能力；C/C++/Java开发语言；TCP/UDP网络协议及相关编程、进程间通讯编程；专业软件知识，包括算法、操作系统、软件工程、设计模式、数据结构、数据库系统、网络安全等。 有一定了解的： Python、Shell、Perl等脚本语言；MySQL及SQL语言、编程；NoSQL, Key-value存储原理。 可以加分的： 分布式系统设计与开发、负载均衡技术，系统容灾设计，高可用系统等知识。 2.1 算法具有非常薄弱的算法功底，连专门的算法课都没上过。 干脆直接上网买了算法刷题书：《labuladong的算法小抄》、《剑指offer》。我主要看的是第一本，确实很适合准备面试。乖乖地按照书上总结的题型和模板，把书上讲到的leetcode题目在网站上自己亲自敲一遍，大概100题，足够应付实习的面试了。第二本看了一点点，感觉难度要高一些。 2.2 C++先复习一下大一学的《C++ Primer Plus》，回炉重造一下。 然后看了《深度探索C++对象模型》，对面向对象理解能深一点。 接着看了一直想看却一直拖着没看的《STL源码解析》，确实受益匪浅，非常值得！ 最后结合Leetcode上官方出的C++面经，自己总结了一下：面试-C++，但是时间紧迫，没全部写完。 2.3 计算机网络之前零碎自学过UCB-CS168，现在把课件、作业都复习一下。 然后看了《TCP/IP详解：协议》，太多了，基本就是挑着看。 接着看了《UNIX网络编程：套接字》和《UNIX网络编程：进程间通信》，没时间敲代码，就看了原理。 最后结合Leetcode上官方出的计网面经，自己总结了一下：面试-计算机网络与网络编程，也没总结完。 2.4 数据库数据库就是在UCB交换时学的，印象比较深，快速过了一遍课件。简历上写了数据库的课程项目，不得不痛苦地重新梳理一下那一大堆代码。 看了《MySQL技术内幕：InnoDB存储引擎》，加深一下理解，和国外课上讲的内容差不多。 再次结合了Leetcode上官方出的数据库面经，自己总结了一下：面试-数据库系统，依旧没总结完。🥺 2.5 操作系统除了《深入理解Linux内核》，就看了《UNIX环境高级编程》，复习一下各种系统调用。 感觉各其他学科都涉及操作系统，用的比较多，所以就没总结（完全没时间了😵） 2.6 设计模式就看了几个就看不下去了，非常枯燥。感觉还是得在实际中使用，不然记不住😢 2.7 其他脚本语言：Python，Shell问题都不太大 可以加分的知识：基本都不会，也没时间学了，不如边工作边学吧🙃 3 Interview腾讯HR的效率好高，简历刚投三天，面试官的电话就到了，约在4月20日晚上。内心非常的慌，因为好多东西都没准备完。索性直接翘掉了所有课，作业全都抄，疯狂准备面试… 3.1 一面（电话）感觉一面绝对是所有轮面试里最难的，且是最重要的。后来才听说，一面的面试官是要考证上岗的，所以真的非常专业。一面表现好，后面基本就稳了！ 面试官会先打电话给你，发给你个链接去做4-5道算法题，做完后直接call面试官。做题的网站是和面试官的屏幕同步的，但是没有像牛客网那样的在线评测，也就是说没法调试。 大概做一个小时，call面试官。接下来面试官就会让你跟他讲每一题的思路，以及问你有没有更好的方法等等。算法part到这里结束。 之后，他就对着你的简历聊项目，一边聊，一边问项目涉及到的基础知识。问的超级细，细到想扣脚趾！基础知识也都挖的挺深，但绝对不会比课堂上讲的难。当时数据库还没复习完，他就一直盯着我的数据库项目问，直接当场去世🥵 最大的教训：简历上的内容一定要滚瓜烂熟，自己不太了解的千万不要写。 面试官最后会问：你还有什么想问我的？我就问了他们的主要业务是干啥的。 一面结束，面试官表示我基础还可以，回去继续等下一轮面试的通知就行。全程大约2h~2h30min左右，口干舌燥。🤒 3.2 二面（电话）+ 三面（视频）下面两轮面试形式和一面基本一致，都是一小时算法+一小时基础知识。二三面的面试官应该都是组长、leader级别的，基础知识问的少，基本就在唠嗑项目。比如给你个情景，让你回答怎么设计这个后台之类的，难度总体比一面要低。 比较尴尬的是，三面的面试官似乎没听说过数据库里的Sort Merge Join、Grace Hash Join算法，我解释了半天，他最后还问我是在哪里学的😲 3.3 HR面三轮技术面一个星期内就结束了，最后的HR面就是随便聊聊，问问你的意向之类的，基本不会挂人。offer call要等差不多2-3周才会收到。 3.4 总体感受 腾讯比较看重实习生对基础知识的掌握程度，算法题基本不会超过Leetcode的medium难度。 与面试过其他公司的同学交流后，体会到腾讯的面试流程与内容都是较为专业的，效率也很高。 4 Internship时间：2021-07-06 ~ 2021-09-09 地点：深圳腾讯滨海大厦 部门：微信事业群(WXG) - 搜索应用部 - IT民工 工作内容：搬砖 体验良好，明年再来。","link":"/2021/04/25/2021-04-25-interview-overview/"},{"title":"面试-数据库系统","text":"Abstract: 常见的数据库面试题集合，包括Leetcode面试宝典、阅读整理、课堂资料等等。 Quick Link: 面试-2021微信暑期实习 （非完整版~） 1 数据库系统基础1.0 简述一个DBMS的一般架构 一般的体系结构：分层，为上一层提供抽象接口 数据库管理系统的客户端 查询语句分析和优化：分析、检查SQL语句，优化查询方案 关系运算符：在记录和文件上执行一个数据流操作 文件和索引管理：把数据库表和记录组织成多个页，多个页形成一个逻辑文件。 缓存管理：加快查询速度 磁盘空间管理：对设备发出存取页的请求 并发控制：事务，实现并发查询，保证原子性、隔离性、一致性。 恢复：数据库崩溃时，保证数据持久性 1.1 磁盘与文件1.1.1 简述磁盘操作的特点 读取操作：将多个数据页从磁盘读取到RAM中 写入操作：将多个数据页从RAM写入到磁盘中 速度非常非常的慢 1.1.2 简述计算机中的存储层级结构 1.1.3 简述磁盘的结构，如何计算磁盘容量 结构： 盘片：一个或多个，有两个面，用于存储数据。 主轴：盘片围绕主轴旋转 组合臂：组合臂上有多个磁头臂 磁头：负责读写数据，沿磁头臂移动来寻找合适的磁道。有多少个盘面就有多少个磁头。 磁道：盘片上的一个个同心圆 扇区：磁道被划分为的一个个圆弧段，是磁盘上的最小物理存储单元。每个扇区存储512字节。 柱面：抽象出来的逻辑概念，处于同一个垂直区域的磁道称为柱面。磁盘读写数据按柱面进行，一般把数据存储到同一柱面。 容量计算：盘面数 × 柱面数(磁道数) × 扇区数 × 512 （字节） 1.1.4 如何计算磁盘访问时间 寻道时间：磁头移动到对应的磁道，~2-3ms 旋转时间：盘片旋转到对应的扇区，~0-4ms 传输时间：数据传送到RAM的时间，~0.25ms per 64KB page 1.1.5 DBMS体系结构中磁盘空间管理器的作用是什么 将数据页映射到磁盘中 将数据页从磁盘载入到内存 将数据页从内存保存到磁盘 高层结构可以依赖底层的操作读写以及分配销毁页面 1.1.6 数据库如何实现一个磁盘空间管理器依赖操作系统的文件系统。一个数据库文件可能存储在不同的文件系统中。 1.1.7 数据库的表、文件、页、记录之间的关系 表被存储为一个或多个逻辑文件 每个逻辑文件中包含多个页。在磁盘中，页被磁盘管理器管理。在内存中，页被缓存管理器管理。 每个页中含有多条记录 1.1.8 有哪些数据库文件组织结构 无序堆组织文件：记录被随意的放置到页中 聚集堆组织文件：记录和页被分组 有序组织文件：页和记录被排序 索引组织文件：如B+ Tree，可能包含记录或指向其它记录的指针 1.1.9 如何实现一个堆组织文件 使用链表：满页链表和空闲页链表 使用页目录：目录项指向相应数据页，能更快的定位页。页目录通常被载入缓存中，提高效率。 1.1.10 简述数据页的结构 slotted page 结构：既适用于定长记录，也适用于变长记录。 每个页的底部放置slot directory，包含：指向空闲位置的指针，指向记录的指针，每条记录的长度，slot的数量 1.1.11 简述变长记录(VLR)的格式 1.1.12 对堆组织文件和有序组织文件进行各种操作的时间是多少 B: 数据块（页）的个数 R：每个数据块中的记录数 D：磁盘读写平均时间 1.2 索引管理1.2.1 什么是索引，有哪些索引结构一种数据结构，能通过建立索引的键对记录进行快速查找和修改。 种类：B+ Tree，Hash, R-Tree, GIST… 1.2.2 简述B+ Tree的结构 d为树的order，最大的fan-out为2d+1。上图中d=2。高度h=2。 每个节点中的条目都满足：d&lt;= #entries&lt;=2d。 最大记录数：$$(2d+1)^{h}\\times 2d$$ 实际应用中，d约为1600，填充因子约为67%，平均fan-out约为2144 1.2.3 使用索引时，数据项有几种存放方式 Alternative 1：存值，记录的内容存储在索引文件中，不需要指针 Alternative 2：存引用，&lt;索引，匹配记录的RID&gt; Alternative 3：存引用的列表，&lt;索引，匹配记录的RID列表&gt; 1.2.4 聚集索引和非聚集索引的区别Alternative 2 和Alternative 3 的两种索引可以是聚集的或非聚集的。 聚集索引：堆文件组织中的记录根据索引排序。 聚集索引的优点： 范围搜索高效 有效利用空间局部性（顺序存取，预取，缓存） 支持压缩 聚集索引的缺点： 难以维护：需周期性更新堆文件组织的顺序 堆文件不能填满，留下足够空间便于插入。 1.2.5 对堆组织文件、有序组织文件和聚集索引文件进行各种操作的时间是多少 B: 数据块（页）的个数 R：每个数据块中的记录数 D：磁盘读写平均时间 F：非叶子节点的平均fan-out E：每个叶子节点记录的平均个数 1.3 缓冲区管理1.3.1 简述缓冲区的工作流程 1.3.2 缓冲区的页有哪些状态字段 FrameId：缓冲区中的页编号 PageId：磁盘中的页编号 Dirty：是否是脏页。脏页会被周期性地或在被替换时回写至磁盘 Pin Count：正在使用该页的进程数量 1.3.3 简述缓冲区的几种替换策略 LRU，最近最少使用，通常用哈希表加双向链表实现。适合随机存取时使用。 优点：对于某些热点页的重复访问很高效 缺点：算法较复杂，开销大。若遇到大文件的全表扫描，可能出现sequential flooding，导致命中率为0 如何解决sequential flooding：MRU或prefetch。 近似LRU（时钟置换算法）：改进LRU开销大的缺点。我们给每一个页面设置一个标记位u，u=1表示最近有使用u=0则表示该页面最近没有被使用，应该被逐出。 MRU，最近最多使用，能解决全表扫描出现的问题。如某些表连接操作。 1.3.4 为什么DBMS不使用OS自带的页面高速缓存功能 不同的文件系统，缓存机制可能不同 DBMS需要强制将特定页面刷新到磁盘的功能，比如某些日志 DBMS可以根据自己的架构特点，设计合适的缓存机制，达到最高效率 1.4 表连接1.4.1 什么时候数据库记录需要排序 去除重复记录（DISTINCT） 记录分组（GROUP BY） 便于Sort-Merge Join (SMJ)表连接算法 返回有序记录（ORDER BY） 1.4.2 什么是外部排序，具体原理是什么 给定： 一个包含所有记录的数据库文件F存储在磁盘中，占用N个数据块。 一个拥有B个数据块容量的内存。（N &gt;&gt; B） 要求：在磁盘中存入文件Fs，里面的所有记录都被排好序。 多路外部归并排序步骤： Pass 0：将F拆分成$\\lceil\\frac{N}{B}\\rceil$个子文件（B-pages的run），每个子文件送入内存中排序，再存回磁盘中。这样，磁盘中的F被分成了$\\lceil\\frac{N}{B}\\rceil$个有序子文件。 Pass 1：将内存划分为B-1个输入缓冲区和1个输出缓冲区，内存每次从磁盘载入B-1个数据块（各数据块内部已经有序），对其进行B-1路归并排序，排序结果传到输出缓冲区中，若满，则输出缓冲区将数据存入磁盘。 经过第一个Pass（可能经过若干次I/O操作），磁盘中的F被分成了$\\lceil\\frac{N}{B(B-1)}\\rceil$个有序子文件（B(B-1)-pages的run）。 使用与Pass 1中相同的方法，一直递归进行，最终将会得到1个有序文件（N-pages的run）。 开销情况： 需要多少个Pass：$1+\\lceil\\log_{B-1}\\lceil N/B\\rceil\\rceil$ 若一次存/取页面算一次I/O操作，总共需要多少次：2N*(# of passes) 1.4.3 什么时候数据库记录需要进行hash操作只需要知道记录之间是否匹配即可，并不一定需要知道顺序。如：去除重复记录，记录分组可以使用hash操作。 1.4.4 什么是外部hashing，具体原理是什么 在内存中建立一张哈希表，查找某条记录时，通过哈希表的映射，直接找到页所在的partition。需要确保每个partition的大小必须不大于B。 步骤： Divide：读取磁盘中所有的记录，使用哈希函数$h_p$，把记录存储到磁盘特定的partition中。 Conquer：读取磁盘中的每个partition，对每个不大于B的partition，使用哈希函数$h_r$建立哈希表，并写回磁盘。若某个partition大小大于B，则对那个partition继续进行Divide和Conquer操作，直至递归完成。 1.4.5 sorting和hashing各自的优点Hashing: 重复记录的删除 并行化时能把容易地平均分发 Sorting: 本来就有排序的需求 对重复记录不敏感 有时很难选出好的哈希函数 1.4.6 简述数据库查询语言如何转化成对数据的具体操作 1.4.7 什么是Simple Nested Loops Join (SNLJ)假设$S$为一张数据表，令$[S]$表示表中所有页的数量，$|S|$表示表中所有的记录数，$P_R$表示每个页中的记录数。 12345# SNLJfor record r in R: for record s in S: if r==s: add &lt;r, s&gt; to result buffer 1.4.8 什么是Page Nested Loop Join (PNLJ)1234567# PNLJfor page rp in R: for page sp in S: for record r in rp: for record s in sp: if r==s: add &lt;r, s&gt; to result buffer 1.4.9 什么是Block Nested Loop Join (BNLJ)1234567# BNLJfor block rb of B-2 pages in R: for page sp in S: for record r in rb: for record s in sp: if r==s: add &lt;r, s&gt; to result buffer 1.4.10 什么是Index Nested Loop Join (INLJ)1234# INLJfor record r in R: for record s in lookup(S, r): add &lt;r, s&gt; to result buffer 1.4.11 什么是Sort-Merge Join (SMJ)两个阶段： 先对R和S根据要连接的键值进行排序 对有序的R和S进行Merge连接 1.4.12 什么是Grace Hash Join (GHJ)两个阶段： 分组：内存划为1个输入缓冲区和B-1个输出缓冲区，输入两个表的所有数据，通过哈希函数映射键值，将数据存储到B-1个不同的partition。这样保证了R和S在每个partition的连接记录总和即为两张表的连接总数。 建立哈希表和搜寻：内存划为1个输入缓冲区，1个输出缓冲区和B-2个哈希表缓冲区。对于每个partition，载入R的记录，对连接键值建立哈希表，然后载入S的记录，对于每条S记录，在哈希表中直接寻找匹配项，发送到输出缓冲区。 123456789101112131415161718# GHJ# paritionfor currtbl in [R, S]: for page p in currtbl: read p to input buffer for record r in p: place r to output buffer # according to hash(r.joinkey) flush output buffer to disk partition if full# build &amp; probefor part in partitions: for page rp of R in part: for record r in rp: build r to memory # according to hash(r.joinkey) for page sp of S in part: for record s in sp: probe hashtable for matches # according to hash(s.joinkey) send matches to output buffer flush output buffer if full 1.4.13 对比SMJ和GHJSMJ优点： 如果输入已经排序或输出需要排序会很高效 对数据倾斜和哈希函数不敏感 GHJ优点： 如果输入已经被hash或输出需要hash会很高效 如果某一张表非常小，会很高效 1.5 并行化1.5.1 简述数据库查询并行方式的分类 Inter-query：每个查询一个线程（没有并行），需要并发控制 Intra-query（在一个单独的查询中）： Inter-operator Intra-operator 1.5.2 有哪些并行化架构 1.5.3 把数据表分发到多台机器/磁盘上的几种方式(Data Partitioning) 1.5.4 根据范围进行分组时，如何使每台机器上分发到的数据量基本相同 对数据进行随机采样，根据采样建立数据的分布直方图，然后选择合适的范围进行分组。 1.5.5 简述如何实现并行化sorting和hashingsorting: 先根据范围，将数据分发到对应的机器上，然后执行单节点sorting。 hashing: 先根据某个哈希函数，将数据分发到对应的机器上，然后执行单节点hashing。 1.5.6 简述如何实现并行化SMJ和GHJ并行化SMJ：对表R和表S分别进行并行化sorting，然后执行单节点SMJ 并行化GHJ：对表R和表S分别进行并行化hashing，然后执行单节点GHJ 1.6 查询优化（基于System R / Selinger Optimizer）1.6.1 简述查询分析和优化的流程 parser: 检查SQL语句正确性，生成语法树 rewriter: 对查询做进一步处理，生成一个个查询块。如处理视图，处理子查询 optimizer：一次优化一个查询块，利用catalog找到较小开销的查询方案。 1.6.2 简述优化器的工作原理和目标 工作原理： 每个查询块都可以用关系代数来表示，关系代数被转化成查询树，每个树节点都对应了相应的查询算子（扫描算子/全表扫描、连接算子/表连接、选择算子/条件查询、投影(projection)算子/字段选择）。但是，每个关系代数可以生成多种查询树，导致执行查询算子的次序不同，进而影响查询的效率。 需要考虑的三个问题： Plan space：给定一个查询块，我们需要考虑哪些查询方案 Cost estimation：给定一个方案，我们如何估计查询的开销 Search strategy：如何利用估计出来的开销在plan space中搜索较优的解 优化目标：找到估计开销最小的查询方案（不一定最优），避免效率极差的方案。 1.6.3 简述几种常见的优化策略 多表连接时，可以适当交换连接次序 表连接时，试采用不同的表连接方法(PNLJ/BNLJ/INLJ/SMJ/GHJ) 下推选择算子：没必要在表连接后再做选择，可以提前做选择，过滤掉不符合条件的记录，减小表连接的开销 下推投影算子：提前去除不需要的字段，减小总的数据传输量 避免交叉积（表1每条记录与表2的每条记录匹配生成新记录） 1.6.4 如何确定plan space 剪枝，只考虑left-deep join tree，避免使用交叉积。 优点： 限制搜索空间 便于使用流水线的并行操作 避免了一些效率极差的查询方案 1.6.5 如何获取cost estimation有哪些开销： 每个算子的I/O开销 每个算子输出的记录大小 总开销：# of I/O + CPU-factor * # of tuples 如何估算开销情况：数据库系统会周期性地更新Statistics &amp; Catelogs，包含关系和索引的各种信息： Selectivity（选择性）= |output| / |input| ，反应出某个算子减小输出记录大小的程度，也称为Reduce Factor。 选择性的数值越小，代表选择性越高，也就是减小输出的能力越强。 不同选择算子的选择性： col = value: sel = 1 / Nkeys col1 = col2: sel = 1 / max(Nkeys1, Nkeys2) col &gt; value: sel = (max-value) / (max-min+1) 如何更准确的估计选择性：使用数据分布直方图(histogram)。 1.6.6 如何选择Search strategy使用动态规划算法，自底向上找出最优方案： 1.7 实体关系模型（略） 1.8 函数依赖与规整化1.8.1 数据冗余会造成什么后果 有太多重复值，造成空间浪费 导致插入/删除/更新操作产生不正常结果 1.8.2 函数依赖在数据库表结构设计中有什么作用 帮助检查出数据冗余问题 帮助改进数据库表结构设计 1.8.3 一般如何改进表结构设计分解(decomposition)，把一张表的某些列分到另一个表中，形成两张表。 1.8.4 什么是函数依赖X-&gt;Y简单地说：X决定了Y，即若在一张表中，有两个tuple，它们的X字段的值相同，则它们的Y字段的值一定相同。 严格定义： 在一个关系结构R中，函数依赖X-&gt;Y表明对于每个关系实例r：$t_1\\in r, t_2\\in r,\\pi_X(t_1)=\\pi_X(t_2)=&gt;\\pi_Y(t_1)=\\pi_Y(t_2)$ 对于 A-&gt;B，如果能找到 A 的真子集 A’，使得 A’-&gt; B，那么 A-&gt;B 就是部分函数依赖，否则就是完全函数依赖。 对于 A-&gt;B，B-&gt;C，则 A-&gt;C 是一个传递函数依赖。 1.8.5 简述超级键、候选键和主键的区别超级键：一组能决定其它字段的字段。K-&gt;{all attributes} 候选键（键码）：超级键的最小子集。 主键：只含一个元素的候选键。 1.8.6 简述数据冗余产生的原因（举例）假设S为候选键，F={R-&gt;W}。 同一组(R, W)可以在表中出现多次（只要其它字段存在不同），造成冗余。 1.8.7 简述数据库的范式范式理论是为了解决以上提到四种异常（1.8.2）。高级别范式的依赖于低级别的范式，1NF 是最低级别的范式。 第一范式 (1NF) 属性不可分。 第二范式 (2NF) 每个非主属性 完全函数依赖于 键码。可以通过分解来满足。即不存在键码的一个真子集A’，使得A’能决定其它字段。 第三范式 (3NF) 每个非主属性 完全函数依赖于 键码 且 不传递函数依赖于 键码。即不存在A-&gt;B-&gt;C的情况。 BCNF 消除主属性对码的部分依赖和传递依赖。 1.9 事务1.9.1 简述有哪些并发一致性问题 丢失修改（自己改的，还没提交又被别人改了）：一个事务的更新操作被另外一个事务的更新操作替换。（T1和T2都缺少X锁） 读脏数据（读到了别人改的，但是别人后来又不改了）：在不同的事务下，当前事务可以读到另外事务未提交的数据。（T1缺少X锁或T2缺少S锁） 不可重复读(前后读取内容不一致)：不可重复读指在一个事务内多次读取同一数据集合。在这一事务还未结束前，另一事务也访问了该同一数据集合并做了修改，由于第二个事务的修改，第一次事务的两次读取的数据可能不一致。（T1缺少X锁或T2获取S锁后读完立即释放，而不是一直保持S锁到提交前） 幻读（Phantom Read）（前后读取数量不一致）：幻读本质上也属于不可重复读的情况。T1读取某个范围的数据，T2在这个范围内插入新的数据，T1再次读取这个范围的数据，此时读取的结果和和第一次读取的结果不同。（T2插入数据时，没有进行范围加锁） 1.9.2 简述事务的ACID四大性质事务指的是满足 ACID 特性的一组操作，可以通过 Commit 提交一个事务，也可以使用 Rollback 进行回滚。 Atomicity：事务中所有操作要么全部发生，要么一个都不发生。回滚可以用回滚日志（Undo Log）来实现，回滚日志记录着事务所执行的修改操作，在回滚时反向执行这些修改操作即可。 Consistency：数据库从一种一致的状态转换到另一种一致的状态。在一致性状态下，所有事务对同一个数据的读取结果都是相同的。 Isolation：一个事务所做的修改在最终提交以前，对其它事务是不可见的。 Durability：一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢失。系统发生崩溃可以用重做日志（Redo Log）进行恢复，从而实现持久性。与回滚日志记录数据的逻辑修改不同，重做日志记录的是数据页的物理修改。 1.9.3 事务ACID性质之间的关系 只有满足一致性，事务的执行结果才是正确的。 在无并发的情况下，事务串行执行，隔离性一定能够满足。此时只要能满足原子性，就一定能满足一致性。 在并发的情况下，多个事务并行执行，事务不仅要满足原子性，还需要满足隔离性，才能满足一致性。 事务满足持久化是为了能应对系统崩溃的情况。 1.9.4 简述串行化、可串行化、冲突可串行化几种调度方式的区别 串行化调度：每个事务从头执行到尾，执行期间没有任何其它事务在执行。 可串行化调度：存在某种不同于串行化的调度方式，但是结果却和串行化等价。 冲突可串行化调度：指一个调度,如果通过交换相邻两个无冲突的操作能够转换到某一个串行的调度。 1.9.5 简述两段锁协议(2PL)悲观的并发控制 事务执行过程中，若出现一个读操作，则必须在读之前获取S锁；若出现一个写操作，则必须在写之前获取X锁。直到事务取得了所有所需资源的锁，处于Lock Point。 在Lock Point之后不能再获取任何新锁，如果某时刻再也不需要某个锁，就释放它。 1.9.6 为什么2PL一定可以保证冲突可串行化当事务达到Lock Point之时，它拥有了所有需要资源的锁。 对于与它冲突的其它事务：要么处在获取锁的阶段（被当前事务阻塞，等待当前事务释放锁），要么处于释放锁的阶段（已经获取了所有需要的资源）。 因此，所有冲突的事务的执行顺序被它们的Lock Point决定，所有冲突事务Lock Point的顺序就是串行调度的顺序。 1.9.7 简述严格两段锁（S2PL），它和2PL有什么区别 获取锁的阶段与2PL相同 在事务结束后（提交或abort），释放所有的锁。 其主要区别简单来说，就是在第二阶段：2PL能随时释放锁，S2PL只能在事务结束后释放锁。S2PL可以解决cascading abort问题。 1.9.8 简述三种封锁协议一级封锁协议 事务 T 要修改数据 A 时必须加 X 锁，直到 T 结束才释放锁。（解决丢失修改问题，但读操作不受限制，即使T获取X锁，其它事务照读不误） 二级封锁协议 在一级的基础上，要求读取数据 A 时必须加 S 锁，读取完马上释放 S 锁。（解决脏读问题） 三级封锁协议 在一级的基础上，要求读取数据 A 时必须加 S 锁，直到事务结束了才能释放 S 锁。（解决不可重复读问题） 1.9.9 简述事务的四种隔离级别，它们近似对应哪种封锁协议 未提交读（READ UNCOMMITTED） 事务中的修改，即使没有提交，对其它事务也是可见的。(一级封锁） 提交读（READ COMMITTED） 一个事务只能读取已经提交的事务所做的修改。换句话说，一个事务所做的修改在提交之前对其它事务是不可见的。（二级封锁） 可重复读（REPEATABLE READ）（MySQL默认级别） 保证在同一个事务中多次读取同一数据的结果是一样的。（三级封锁） 可串行化（SERIALIZABLE）强制事务串行执行，这样多个事务互不干扰，不会出现并发一致性问题。 1.9.10 什么是死锁预防，有哪些方法在程序运行之前预防发生死锁。（针对产生原因，从根本上解决） 破坏互斥条件例如假脱机打印机技术允许若干个进程同时输出，唯一真正请求物理打印机的进程是打印机守护进程。 破坏占有和等待条件一种实现方式是规定所有进程在开始执行前请求所需要的全部资源。 破坏不可抢占条件 破坏环路等待给资源统一编号，进程只能按编号顺序来请求资源。 1.9.11 什么是死锁避免，有哪些方法在程序运行时，记录一些状态量，若判断某请求会使系统进入不安全状态，则拒绝请求，从而避免发生死锁。 银行家算法 每个事务都给它一个时间戳，当A申请资源锁的时 候，B已经获得了锁，有以下两个策略 wait-die(等待死亡)：是一种非剥夺策略，老的事务等待新的事务释放资源，即若A比B老，则等待B执行结束，否则A卷回(roll-back),一段时间后会以原先的时间戳继续申请。老的才有资格等，年轻的全部卷回。 wound-wait(伤害-等待)：是一种剥夺策略，如果A比B年轻，A才等待，A比B老，则杀死B，B回滚。换句话说，老事务不等待”你”，直接杀死”你”，抢占资源，小孩子才等。 两个方法都保证事务执行是单向的(要么老的等新的(等现存的持有锁的新事务结束，而不是说等所有新的事务申请结束了才执行老的)，要么新的等老的)，不会出现循环等待，从而避免了死锁，也都确保了老事务的优先权。 1.9.12 什么是死锁检测，有哪些方法不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复。 资源等待图，检测有无环路。 1.9.13 什么是死锁恢复，有哪些方法破除循环等待的局面 利用抢占恢复 利用回滚恢复 通过杀死进程恢复 1.9.14 简述封锁粒度MySQL 中提供了两种封锁粒度：行级锁以及表级锁。 应该尽量只锁定需要修改的那部分数据，而不是所有的资源。锁定的数据量越少，发生锁争用的可能就越小，系统的并发程度就越高。 但是加锁需要消耗资源，锁的各种操作（包括获取锁、释放锁、以及检查锁状态）都会增加系统开销。因此封锁粒度越小，系统开销就越大。 在选择封锁粒度时，需要在锁开销和并发程度之间做一个权衡。 1.9.15 简述封锁的类型读写锁 互斥锁（Exclusive），简写为 X 锁，又称写锁。 共享锁（Shared），简写为 S 锁，又称读锁。 有以下两个规定： 一个事务对数据对象 A 加了 X 锁，就可以对 A 进行读取和更新。加锁期间其它事务不能对 A 加任何锁。 一个事务对数据对象 A 加了 S 锁，可以对 A 进行读取操作，但是不能进行更新操作。加锁期间其它事务能对 A 加 S 锁，但是不能加 X 锁。 锁的兼容关系如下： 意向锁 使用意向锁（Intention Locks）可以更容易地支持多粒度封锁。 在存在行级锁和表级锁的情况下，事务 T 想要对表 A 加 X 锁，就需要先检测是否有其它事务对表 A 或者表 A 中的任意一行加了锁，那么就需要对表 A 的每一行都检测一次，这是非常耗时的。 意向锁在原来的 X/S 锁之上引入了 IX/IS，IX/IS 都是表锁，用来表示一个事务想要在表中的某个数据行上加 X 锁或 S 锁。有以下两个规定： 一个事务在获得某个数据行对象的 S 锁之前，必须先获得表的 IS 锁或者更强的锁； 一个事务在获得某个数据行对象的 X 锁之前，必须先获得表的 IX 锁。 通过引入意向锁，事务 T 想要对表 A 加 X 锁，只需要先检测是否有其它事务对表 A 加了 X/IX/S/IS 锁，如果加了就表示有其它事务正在使用这个表或者表中某一行的锁，因此事务 T 加 X 锁失败。 各种锁的兼容关系如下： 解释如下： 任意 IS/IX 锁之间都是兼容的，因为它们只表示想要对表加锁，而不是真正加锁； 这里兼容关系针对的是表级锁，而表级的 IX 锁和行级的 X 锁兼容，两个事务可以对两个数据行加 X 锁。（事务 T1想要对数据行R1加 X 锁，事务T2 想要对同一个表的数据行R2加 X 锁，两个事务都需要对该表加 IX 锁，但是 IX 锁是兼容的，并且 IX 锁与行级的 X 锁也是兼容的，因此两个事务都能加锁成功，对同一个表中的两个数据行做修改。） 1.9.16 分布式系统有什么特点 支持并行计算 不共享存储 网络可能不可靠：延迟、失序、丢包 时钟不同步 部分宕机 简单来说，就是当某台你不知道的计算机宕机了，它可能会导致你自己的计算机不能工作。 1.9.17 什么是分布式事务在分布式数据库系统中，一个事务可能要访问多个节点。分布式事务用于在分布式系统中保证不同节点间的数据一致性。 举例：电商应用中，存在订单DB和库存DB。当交易成功时，需要在订单DB中创建新订单，同时在库存DB中减少库存。两个操作必须放在一个事务中，而这两个数据库又是分布式的，因此这是一个分布式事务。 1.9.18 分布式事务中如何上锁，如何检测死锁 每个节点像非分布式事务一样单独上锁。 检测死锁：周期性地在指定的master节点处合并每个节点的资源等待图，检测全局的死锁。 1.9.19 简述二阶段提交（2PC）的过程，如果还要记录日志呢二阶段提交是一种强一致性设计，2PC 引入一个事务协调者的角色来协调管理各参与者（也可称之为各本地资源）的提交和回滚，二阶段分别指的是准备（投票）和提交两个阶段。 阶段一： 协调者向所有参与者发出“准备”的命令： 每个参与者需要向协调者回复“Yes”还是”No”的投票： 阶段二： 协调者向参与者广播投票的结果（提交还是回滚）： 参与者向协调者回复Ack信息： 2PC with Logging： 阶段一： 协调者发布prepare的命令 参与者产生prepare/abort的日志 参与者强制将prepare/abort的日志刷入磁盘 参与者回复Yes/No的投票 协调者产生commit的日志 协调者强制将commit的日志刷入磁盘 阶段二： 协调者广播投票结果 协调者产生commit/abort的日志 协调者强制将commit/abort的日志刷入磁盘 协调者回复Ack 协调者产生end日志 协调者强制将end日志刷入磁盘 总结： 1.10 恢复1.10.1 什么是预写式日志（Write-Ahead Logging, WAL） 在数据页刷入磁盘之前，强制所有关于此页的update操作的日志记录刷入磁盘。 （即UNDO日志，保证原子性） 在事务提交之前，强制所有关于此事务的操作的日志记录从日志缓冲区刷到入磁盘。 （即REDO日志，保证持久性） 1.10.2 简述ARIES恢复算法的具体流程1-几种LSN LSN：Log Sequence Number，日志序列号，单调递增 除了磁盘中存储的日志有LSN以外，其它的LSN： flushedLSN：RAM中当前被跟踪的LSN，表示当前时间 pageLSN：磁盘中数据页的LSN，表示最近一次更改这个页的时间。由于WAL的存在，保证了pageLSN &lt;= flushedLSN。 prevLSN：在日志记录LSN中，追踪被当前事务XID写的前一个LSN。便于对事务进行UNDO。 2-日志记录的格式与种类 种类： UPDATE：包含足够的信息用于REDO或UNDO COMMIT：事务提交时，先写提交日志 ABORT：事务被中断 CHECKPOINT：设置检查点，把RAM中的脏页刷新到磁盘（不一定全部刷新），利于缩短恢复时间，空出缓冲区 compensation log record (CLR) END：事务提交成功（返回）后，写入结束日志 3-日志状态记录 使用两张表来记录任一时刻事务和RAM中页的状态。 事务表：记录所有未提交（运行中）、正在提交（提交还未成功返回）和正在终止的事务的状态。 包含： XID：事务编号 Status：状态（running, committing, aborting） lastLSN：被此事务写的最近一次的LSN 脏页表（DPT）：记录所有脏页的信息 包含： PageID：在磁盘中的页面号 recLSN：第一个导致该页变脏的LSN 4-事务的正常执行流 使用WAL机制 RAM中的页被更新后，要增加pageLSN 每一步过后都要更新事务表和DPT 日志被周期性地刷入磁盘 5-事务的提交 先写入COMMIT日志 之前的所有日志都被强制刷新到磁盘上，保证flushedLSN&gt;=lastLSN commit()返回 写入END日志 6-事务的终止 需要UNDO该事务造成的update。 从事务表中找出该事务的lastLSN 在回滚前，写入ABORT日志 利用prevLSN，倒序undo该事务做过的所有update操作。每次成功的undo了一个操作，就写入一个CLR日志。 CLR中含有undonextLSN字段，指向下一个被undo的LSN。 CLR中含有REDO所需的信息，因为CLR日志可能会被REDO，但是绝不会被UNDO。 所有undo操作完成后，写入END日志。 7-CHECKPOINT 日志不能无限制的存储下去，DBMS会周期性地创建chkpt，减小崩溃后的恢复时间，空出缓冲区，减小日志存储量。 写入begin_checkpoint日志：表明下面开始创建检查点 把RAM中的脏页刷新到磁盘（不一定全部刷新） 写入end_checkpoint日志：内含当前的事务表和DPT（即当前检查点处的数据库状态） 需要把最近一次checkpoint的LSN放置在一个安全的位置（master record）。 8-崩溃后的恢复过程 无论数据库是否崩溃，在开启时都会自动执行恢复过程。 从最近一次的chkpt开始恢复，分为以下三个阶段： 分析阶段：复现出在数据库崩溃时，哪些事务没能成功提交，那些页可能没被同步到磁盘中。 REDO阶段：从最早引起脏页的那个LSN处，重做所有之后的操作 UNDO阶段：对于每个未成功提交的事务，回滚所有操作（与事务终止相同） 9-分析阶段 获取最近一次检查点处数据库的状态：事务表和DPT 从检查点后的日志开始往后扫描： 遇到END：将此事务从事务表中移除 遇到UPDATE：若此页不在DPT中，则把它加入到DPT中，更新resLSN为此时的LSN。这就是最早引起脏页的LSN。我们还不能确定崩溃时此页到底有没有被同步到磁盘中。 遇到其余日志：把此事务加入到事务表中，更新lastLSN为此时的LSN。若遇到COMMIT，则把事务状态改为提交中。 分析阶段结束后： 对所有处于提交中状态的事务：写入END日志，然后把它们从事务表中移除。因为这些事务已经进行了提交，必须确保它们的持久性。 事务表中剩余的事务：Losers! 它们在数据库崩溃时，没能进入提交这一步，需要被回滚。 DPT中的脏页：这些脏页有可能没来得及被同步到磁盘中。 10-REDO阶段 从DPT中最早的那个recLSN处开始，重做所有之后的update操作，包括CLR。同时需要相应的更新pageLSN。 REDO阶段不需要记录任何日志。 对于每个update日志，有几种不需要REDO的情况： update的页不再DPT中：因为此页在chkpt之前已经被同步到磁盘中，被从DPT中移除了 update的页在DPT中，但是它的recLSN大于update的LSN：此页在chkpt之前被同步到磁盘中，被从DPT中移除。之后又被取出，加入到了DPT中。我们可以确定这次的update操作确实将内容同步到了磁盘上。 pageLSN&gt;=LSN：说明此页在这个update操作之后又被update过，且将内容同步到了磁盘上。 11-UNDO阶段 对于每个事务表中的事务，执行回滚操作即可。（步骤同终止的情况） 1.10.3 数据库在恢复过程中又崩溃了，上述步骤能保证正确性吗分析阶段崩溃： 只是失去了一些状态量。下次重启时再分析一遍。 REDO阶段崩溃： 做过的REDO在下次重启时的分析阶段会被检测出来，然后继续执行剩余的REDO。 UNDO阶段崩溃： 由于每次UNDO一个update都会写入一个CLR，CLR中的nextundoLSN指向了下一个需要UNDO的操作。因此不会出现已经被UNDO的操作又被UNDO的局面。 1.10.4 如何限制REDO与UNDO日志的数量REDO：周期性地同步RAM和磁盘，周期性地设置检查点 UNDO：避免使用过长的事务 1.11 复制1.12 NoSQL1.13 大数据2 InnoDB存储引擎2.1 基础2.2 文件2.3 表2.4 索引2.5 锁2.6 事务2.7 备份与恢复2.8 性能优化3 SQL语言Reference: UC Berkeley CS186 Introduction to Database Systems 《Database System Concepts》- Abraham Silberschatz … 《MySQL技术内幕：InnoDB存储引擎》 - 姜承尧 数据库知识手册","link":"/2021/04/26/2021-04-26-interview-database-systems/"},{"title":"面试-C++","text":"Abstract: 常见的C++面试题集合，包括Leetcode面试宝典、阅读整理、课堂资料等等。 Quick Link: 面试-2021微信暑期实习 （非完整版~） 1 C++基础1.1 语言特性1.1.1 C++11有哪些新特性 auto 类型推导auto 关键字：自动类型推导，编译器会在 编译期间 通过初始值推导出变量的类型，通过 auto 定义的变量必须有初始值。 auto 关键字基本的使用语法如下： 1auto var = val1 + val2; // 根据 val1 和 val2 相加的结果推断出 var 的类型， 注意：编译器推导出来的类型和初始值的类型并不完全一样，编译器会适当地改变结果类型使其更符合初始化规则。 decltype 类型推导decltype 关键字：decltype 是“declare type”的缩写，译为“声明类型”。和 auto 的功能一样，都用来在编译时期进行自动类型推导。如果希望从表达式中推断出要定义的变量的类型，但是不想用该表达式的值初始化变量，这时就不能再用 auto。decltype 作用是选择并返回操作数的数据类型。区别： 12auto var = val1 + val2; decltype(val1 + val2) var1 = 0; auto 根据 = 右边的初始值 val1 + val2 推导出变量的类型，并将该初始值赋值给变量 var；decltype 根据 val1 + val2 表达式推导出变量的类型，变量的初始值和与表达式的值无关。auto 要求变量必须初始化，因为它是根据初始化的值推导出变量的类型，而 decltype 不要求，定义变量的时候可初始化也可以不初始化。 lambda 表达式lambda 表达式，又被称为 lambda 函数或者 lambda 匿名函数。 lambda匿名函数的定义: 1234[capture list] (parameter list) -&gt; return type{ function body;}; 其中： capture list：捕获列表，指 lambda 所在函数中定义的局部变量的列表，通常为空。return type、parameter list、function body：分别表示返回值类型、参数列表、函数体，和普通函数一样。举例： 1234567891011121314#include &lt;iostream&gt;#include &lt;algorithm&gt;using namespace std;int main(){ int arr[4] = {4, 2, 3, 1}; //对 a 数组中的元素进行升序排序 sort(arr, arr+4, [=](int x, int y) -&gt; bool{ return x &lt; y; } ); for(int n : arr){ cout &lt;&lt; n &lt;&lt; &quot; &quot;; } return 0;} 范围 for 语句语法格式： 123for (declaration : expression){ statement} 参数的含义： expression：必须是一个序列，例如用花括号括起来的初始值列表、数组、vector ，string 等，这些类型的共同特点是拥有能返回迭代器的 beign、end 成员。declaration：此处定义一个变量，序列中的每一个元素都能转化成该变量的类型，常用 auto 类型说明符。实例： 1234567891011121314#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;int main() { char arr[] = &quot;hello world!&quot;; for (char c : arr) { cout &lt;&lt; c; } return 0;}/*程序执行结果为：hello world!*/ 右值引用右值引用：绑定到右值的引用，用 &amp;&amp; 来获得右值引用，右值引用只能绑定到要销毁的对象。为了和右值引用区分开，常规的引用称为左值引用。举例： 12345678910111213#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;int main(){ int var = 42; int &amp;l_var = var; int &amp;&amp;r_var = var; // error: cannot bind rvalue reference of type 'int&amp;&amp;' to lvalue of type 'int' 错误：不能将右值引用绑定到左值上 int &amp;&amp;r_var2 = var + 40; // 正确：将 r_var2 绑定到求和结果上 return 0;} 标准库 move() 函数move() 函数：通过该函数可获得绑定到左值上的右值引用，该函数包括在 utility 头文件中。 智能指针 delete 函数和 default 函数 delete 函数：= delete 表示该函数不能被调用。default 函数：= default 表示编译器生成默认的函数，例如：生成默认的构造函数。 12345678910111213141516171819#include &lt;iostream&gt;using namespace std;class A{public: A() = default; // 表示使用默认的构造函数 ~A() = default; // 表示使用默认的析构函数 A(const A &amp;) = delete; // 表示类的对象禁止拷贝构造 A &amp;operator=(const A &amp;) = delete; // 表示类的对象禁止拷贝赋值};int main(){ A ex1; A ex2 = ex1; // error: use of deleted function 'A::A(const A&amp;)' A ex3; ex3 = ex1; // error: use of deleted function 'A&amp; A::operator=(const A&amp;)' return 0;} 1.1.2 C 和 C++ 的区别首先说一下面向对象和面向过程： 面向过程的思路：分析解决问题所需的步骤，用函数把这些步骤依次实现。 面向对象的思路：把构成问题的事务分解为各个对象，建立对象的目的，不是完成一个步骤，而是描述某个事务在解决整个问题步骤中的行为。 区别和联系： 语言自身：C 语言是面向过程的编程，它最重要的特点是函数，通过 main 函数来调用各个子函数。程序运行的顺序都是程序员事先决定好的。C++ 是面向对象的编程，类是它的主要特点，在程序执行过程中，先由主 main 函数进入，定义一些类，根据需要执行类的成员函数，过程的概念被淡化了（实际上过程还是有的，就是主函数的那些语句。），以类驱动程序运行，类就是对象，所以我们称之为面向对象程序设计。面向对象在分析和解决问题的时候，将涉及到的数据和数据的操作封装在类中，通过类可以创建对象，以事件或消息来驱动对象执行处理。 应用领域：C 语言主要用于嵌入式领域，驱动开发等与硬件直接打交道的领域，C++ 可以用于应用层开发，用户界面开发等与操作系统打交道的领域。 C++ 既继承了 C 强大的底层操作特性，又被赋予了面向对象机制。它特性繁多，面向对象语言的多继承，对值传递与引用传递的区分以及 const 关键字，等等。 C++ 对 C 的“增强”，表现在以下几个方面：类型检查更为严格。增加了面向对象的机制、泛型编程的机制（Template）、异常处理、运算符重载、标准模板库（STL）、命名空间（避免全局命名冲突）。 1.1.3 Java 和 C++ 的区别二者在语言特性上有很大的区别： 指针：C++ 可以直接操作指针，容易产生内存泄漏以及非法指针引用的问题；Java 并不是没有指针，虚拟机（JVM）内部还是使用了指针，只是编程人员不能直接使用指针，不能通过指针来直接访问内存，并且 Java 增加了内存管理机制。 多重继承：C++ 支持多重继承，允许多个父类派生一个类，虽然功能很强大，但是如果使用的不当会造成很多问题，例如：菱形继承；Java 不支持多重继承，但允许一个类可以继承多个接口，可以实现 C++ 多重继承的功能，但又避免了多重继承带来的许多不便。 数据类型和类：Java 是完全面向对象的语言，所有函数和变量部必须是类的一部分。除了基本数据类型之外，其余的都作为类对象，包括数组。对象将数据和方法结合起来，把它们封装在类中，这样每个对象都可实现自己的特点和行为。而 C++ 允许将函数和变量定义为全局的。 垃圾回收： Java 语言一个显著的特点就是垃圾回收机制，编程人员无需考虑内存管理的问题，可以有效的防止内存泄漏，有效的使用空闲的内存。 Java 所有的对象都是用 new 操作符建立在内存堆栈上，类似于 C++ 中的 new 操作符，但是当要释放该申请的内存空间时，Java 自动进行内存回收操作，C++ 需要程序员自己释放内存空间，并且 Java 中的内存回收是以线程的方式在后台运行的，利用空闲时间。 应用场景： Java 运行在虚拟机上，和开发平台无关，C++ 直接编译成可执行文件，是否跨平台在于用到的编译器的特性是否有多平台的支持。 C++ 可以直接编译成可执行文件，运行效率比 Java 高。 Java 主要用来开发 Web 应用。 C++ 主要用在嵌入式开发、网络、并发编程的方面。 1.1.4 Python 和 C++ 的区别区别： 语言自身：Python 为脚本语言，解释执行，不需要经过编译；C++ 是一种需要编译后才能运行的语言，在特定的机器上编译后运行。 运行效率：C++ 运行效率高，安全稳定。原因：Python 代码和 C++ 最终都会变成 CPU 指令来跑，但一般情况下，比如反转和合并两个字符串，Python 最终转换出来的 CPU 指令会比 C++ 多很多。首先，Python 中涉及的内容比 C++ 多，经过了更多层，Python 中甚至连数字都是 object ；其次，Python 是解释执行的，和物理机 CPU 之间多了解释器这层，而 C++ 是编译执行的，直接就是机器码，编译的时候编译器又可以进行一些优化。 开发效率：Python 开发效率高。原因：Python 一两句代码就能实现的功能，C++ 往往需要更多的代码才能实现。 书写格式和语法不同：Python 的语法格式不同于其 C++ 定义声明才能使用，而且极其灵活，完全面向更上层的开发者。 1.1.5 左值和右值的区别？左值引用和右值引用的区别，如何将左值转换成右值？左值：指表达式结束后依然存在的持久对象。 右值：表达式结束就不再存在的临时对象。 左值和右值的区别：左值持久，右值短暂 右值引用和左值引用的区别： 左值引用不能绑定到要转换的表达式、字面常量或返回右值的表达式。右值引用恰好相反，可以绑定到这类表达式，但不能绑定到一个左值上。右值引用必须绑定到右值的引用，通过 &amp;&amp; 获得。右值引用只能绑定到一个将要销毁的对象上，因此可以自由地移动其资源。std::move 可以将一个左值强制转化为右值，继而可以通过右值引用使用该值，以用于移动语义。 1234567891011121314151617181920#include &lt;iostream&gt;using namespace std;void fun1(int&amp; tmp) { cout &lt;&lt; &quot;fun1(int&amp; tmp):&quot; &lt;&lt; tmp &lt;&lt; endl; } void fun2(int&amp;&amp; tmp) { cout &lt;&lt; &quot;fun2(int&amp;&amp; tmp)&quot; &lt;&lt; tmp &lt;&lt; endl; } int main() { int var = 11; fun1(12); // error: cannot bind non-const lvalue reference of type 'int&amp;' to an rvalue of type 'int' fun1(var); fun2(1); } 1.1.6 std::move() 函数的实现原理std::move() 函数原型： 12345template &lt;typename T&gt;typename remove_reference&lt;T&gt;::type&amp;&amp; move(T&amp;&amp; t){ return static_cast&lt;typename remove_reference&lt;T&gt;::type &amp;&amp;&gt;(t);} 说明：引用折叠原理 右值传递给上述函数的形参 T&amp;&amp; 依然是右值，即 T&amp;&amp; &amp;&amp; 相当于 T&amp;&amp;。左值传递给上述函数的形参 T&amp;&amp; 依然是左值，即 T&amp;&amp; &amp; 相当于 T&amp;。小结：通过引用折叠原理可以知道，move() 函数的形参既可以是左值也可以是右值。 remove_reference 具体实现： 1234567891011121314151617//原始的，最通用的版本template &lt;typename T&gt; struct remove_reference{ typedef T type; //定义 T 的类型别名为 type}; //部分版本特例化，将用于左值引用和右值引用template &lt;class T&gt; struct remove_reference&lt;T&amp;&gt; //左值引用{ typedef T type; } template &lt;class T&gt; struct remove_reference&lt;T&amp;&amp;&gt; //右值引用{ typedef T type; } //举例如下,下列定义的a、b、c三个变量都是int类型int i;remove_refrence&lt;decltype(42)&gt;::type a; //使用原版本，remove_refrence&lt;decltype(i)&gt;::type b; //左值引用特例版本remove_refrence&lt;decltype(std::move(i))&gt;::type b; //右值引用特例版本 举例： 1234567891011121314int var = 10; 转化过程：1. std::move(var) =&gt; std::move(int&amp;&amp; &amp;) =&gt; 折叠后 std::move(int&amp;)2. 此时：T 的类型为 int&amp;，typename remove_reference&lt;T&gt;::type 为 int，这里使用 remove_reference 的左值引用的特例化版本3. 通过 static_cast 将 int&amp; 强制转换为 int&amp;&amp;整个std::move被实例化如下string&amp;&amp; move(int&amp; t) { return static_cast&lt;int&amp;&amp;&gt;(t); } 总结：std::move() 实现原理： 利用引用折叠原理将右值经过 T&amp;&amp; 传递类型保持不变还是右值，而左值经过 T&amp;&amp; 变为普通的左值引用，以保证模板可以传递任意实参，且保持类型不变； 然后通过 remove_refrence 移除引用，得到具体的类型 T； 最后通过 static_cast&lt;&gt; 进行强制类型转换，返回 T&amp;&amp; 右值引用。 1.1.7 什么是指针？指针的大小及用法？指针： 指向另外一种类型的复合类型。 指针的大小： 在 64 位计算机中，指针占 8 个字节空间。 123456789101112#include&lt;iostream&gt;using namespace std;int main(){ int *p = nullptr; cout &lt;&lt; sizeof(p) &lt;&lt; endl; // 8 char *p1 = nullptr; cout &lt;&lt; sizeof(p1) &lt;&lt; endl; // 8 return 0;} 指针的用法： 指向普通对象的指针 12345678910111213#include &lt;iostream&gt;using namespace std;class A{};int main(){ A *p = new A(); return 0;} 指向常量对象的指针：常量指针 12345678910#include &lt;iostream&gt;using namespace std;int main(void){ const int c_var = 10; const int * p = &amp;c_var; cout &lt;&lt; *p &lt;&lt; endl; return 0;} 指向函数的指针：函数指针 1234567891011121314#include &lt;iostream&gt;using namespace std;int add(int a, int b){ return a + b;}int main(void){ int (*fun_p)(int, int); fun_p = add; cout &lt;&lt; fun_p(1, 6) &lt;&lt; endl; return 0;} 指向对象成员的指针，包括指向对象成员函数的指针和指向对象成员变量的指针。特别注意：定义指向成员函数的指针时，要标明指针所属的类。 1234567891011121314151617181920212223242526#include &lt;iostream&gt;using namespace std;class A{public: int var1, var2; int add(){ return var1 + var2; }};int main(){ A ex; ex.var1 = 3; ex.var2 = 4; int *p = &amp;ex.var1; // 指向对象成员变量的指针 cout &lt;&lt; *p &lt;&lt; endl; int (A::*fun_p)(); fun_p = A::add; // 指向对象成员函数的指针 fun_p cout &lt;&lt; (ex.*fun_p)() &lt;&lt; endl; return 0;} this 指针：指向类的当前对象的指针常量。 123456789101112131415161718192021222324252627282930313233343536373839404142#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;class A{public: void set_name(string tmp) { this-&gt;name = tmp; } void set_age(int tmp) { this-&gt;age = age; } void set_sex(int tmp) { this-&gt;sex = tmp; } void show() { cout &lt;&lt; &quot;Name: &quot; &lt;&lt; this-&gt;name &lt;&lt; endl; cout &lt;&lt; &quot;Age: &quot; &lt;&lt; this-&gt;age &lt;&lt; endl; cout &lt;&lt; &quot;Sex: &quot; &lt;&lt; this-&gt;sex &lt;&lt; endl; }private: string name; int age; int sex;};int main(){ A *p = new A(); p-&gt;set_name(&quot;Alice&quot;); p-&gt;set_age(16); p-&gt;set_sex(1); p-&gt;show(); return 0;} 1.1.8 什么是野指针和悬空指针？悬空指针： 若指针指向一块内存空间，当这块内存空间被释放后，该指针依然指向这块内存空间，此时，称该指针为“悬空指针”。举例： 123void *p = malloc(size);free(p); // 此时，p 指向的内存空间已释放， p 就是悬空指针。 野指针： “野指针”是指不确定其指向的指针，未初始化的指针为“野指针”。 12void *p; // 此时 p 是“野指针”。 1.1.9 C++ 11 nullptr 比 NULL 优势 NULL：预处理变量，是一个宏，它的值是 0，定义在头文件 中，即 #define NULL 0。 nullptr：C++ 11 中的关键字，是一种特殊类型的字面值，可以被转换成任意其他类型。 nullptr 的优势： 有类型，类型是 typdef decltype(nullptr) nullptr_t;，使用 nullptr 提高代码的健壮性。 函数重载：因为 NULL 本质上是 0，在函数调用过程中，若出现函数重载并且传递的实参是 NULL，可能会出现，不知和哪一个函数匹配的情况；但是传递实参 nullptr 就不会出现这种情况。 12345678910111213141516171819202122#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;void fun(char const *p){ cout &lt;&lt; &quot;fun(char const *p)&quot; &lt;&lt; endl;}void fun(int tmp){ cout &lt;&lt; &quot;fun(int tmp)&quot; &lt;&lt; endl;}int main(){ fun(nullptr); // fun(char const *p) /* fun(NULL); // error: call of overloaded 'fun(NULL)' is ambiguous */ return 0;} 1.1.10 指针和引用的区别？ 指针所指向的内存空间在程序运行过程中可以改变，而引用所绑定的对象一旦绑定就不能改变。（是否可变） 指针本身在内存中占有内存空间，引用相当于变量的别名，在内存中不占内存空间。（是否占内存） 指针可以为空，但是引用必须绑定对象。（是否可为空） 指针可以有多级，但是引用只能一级。（是否能为多级） 1.1.11 常量指针和指针常量的区别常量指针：常量指针本质上是个指针，只不过这个指针指向的对象是常量。特点：const 的位置在指针声明运算符 * 的左侧。只要 const 位于 * 的左侧，无论它在类型名的左边或右边，都表示指向常量的指针。（可以这样理解，* 左侧表示指针指向的对象，该对象为常量，那么该指针为常量指针。） 12const int * p;int const * p; 注意 1：指针指向的对象不能通过这个指针来修改，也就是说常量指针可以被赋值为变量的地址，之所以叫做常量指针，是限制了通过这个指针修改变量的值。例如： 12345678910#include &lt;iostream&gt;using namespace std;int main(){ const int c_var = 8; const int *p = &amp;c_var; *p = 6; // error: assignment of read-only location '* p' return 0;} 注意 2：虽然常量指针指向的对象不能变化，可是因为常量指针本身是一个变量，因此，可以被重新赋值。例如： 1234567891011#include &lt;iostream&gt;using namespace std;int main(){ const int c_var1 = 8; const int c_var2 = 8; const int *p = &amp;c_var1; p = &amp;c_var2; return 0;} 指针常量：指针常量的本质上是个常量，只不过这个常量的值是一个指针。特点：const 位于指针声明操作符右侧，表明该对象本身是一个常量，* 左侧表示该指针指向的类型，即以 * 为分界线，其左侧表示指针指向的类型，右侧表示指针本身的性质。 12const int var;int * const c_p = &amp;var; 注意 1：指针常量的值是指针，这个值因为是常量，所以指针本身不能改变。 12345678910#include &lt;iostream&gt;using namespace std;int main(){ int var, var1; int * const c_p = &amp;var; c_p = &amp;var1; // error: assignment of read-only variable 'c_p' return 0;} 注意 2：指针指向的对象可以改变。 12345678910#include &lt;iostream&gt;using namespace std;int main(){ int var = 3; int * const c_p = &amp;var; *c_p = 12; return 0;} 1.1.12 函数指针和指针函数的区别指针函数：指针函数本质是一个函数，只不过该函数的返回值是一个指针。相对于普通函数而言，只是返回值是指针。 123456789101112131415161718192021#include &lt;iostream&gt;using namespace std;struct Type{ int var1; int var2;};Type * fun(int tmp1, int tmp2){ Type * t = new Type(); t-&gt;var1 = tmp1; t-&gt;var2 = tmp2; return t;}int main(){ Type *p = fun(5, 6); return 0;} 函数指针：函数指针本质是一个指针变量，只不过这个指针指向一个函数。函数指针即指向函数的指针。 举例： 12345678910111213141516171819202122232425#include &lt;iostream&gt;using namespace std;int fun1(int tmp1, int tmp2){ return tmp1 * tmp2;}int fun2(int tmp1, int tmp2){ return tmp1 / tmp2;}int main(){ int (*fun)(int x, int y); fun = fun1; cout &lt;&lt; fun(15, 5) &lt;&lt; endl; fun = fun2; cout &lt;&lt; fun(15, 5) &lt;&lt; endl; return 0;}/*运行结果：753*/ 1.1.13 强制类型转换有哪几种？static_cast：用于数据的强制类型转换，强制将一种数据类型转换为另一种数据类型。 用于基本数据类型的转换。 用于类层次之间的基类和派生类之间 指针或者引用 的转换（不要求必须包含虚函数，但必须是有相互联系的类），进行上行转换（派生类的指针或引用转换成基类表示）是安全的；进行下行转换（基类的指针或引用转换成派生类表示）由于没有动态类型检查，所以是不安全的，最好用 dynamic_cast 进行下行转换。 可以将空指针转化成目标类型的空指针。 可以将任何类型的表达式转化成 void 类型。 const_cast：强制去掉常量属性，不能用于去掉变量的常量性，只能用于去除指针或引用的常量性，将常量指针转化为非常量指针或者将常量引用转化为非常量引用（注意：表达式的类型和要转化的类型是相同的）。 reinterpret_cast：将一种类型转换为另一种不同的类型。改变指针或引用的类型、将指针或引用转换为一个足够长度的整型、将整型转化为指针或引用类型。 dynamic_cast： 其他三种都是编译时完成的，动态类型转换是在程序运行时处理的，运行时会进行类型检查。 只能用于带有虚函数的基类或派生类的指针或者引用对象的转换，转换成功返回指向类型的指针或引用，转换失败返回 NULL；不能用于基本数据类型的转换。 在向上进行转换时，即派生类类的指针转换成基类类的指针和 static_cast 效果是一样的，（注意：这里只是改变了指针的类型，指针指向的对象的类型并未发生改变）。 12345678910111213141516171819202122232425262728293031#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;class Base{};class Derive : public Base{};int main(){ Base *p1 = new Derive(); Derive *p2 = new Derive(); //向上类型转换 p1 = dynamic_cast&lt;Base *&gt;(p2); if (p1 == NULL) { cout &lt;&lt; &quot;NULL&quot; &lt;&lt; endl; } else { cout &lt;&lt; &quot;NOT NULL&quot; &lt;&lt; endl; //输出 } return 0;} 在下行转换时，基类的指针类型转化为派生类类的指针类型，只有当要转换的指针指向的对象类型和转化以后的对象类型相同时，才会转化成功。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;class Base{public: virtual void fun() { cout &lt;&lt; &quot;Base::fun()&quot; &lt;&lt; endl; }};class Derive : public Base{public: virtual void fun() { cout &lt;&lt; &quot;Derive::fun()&quot; &lt;&lt; endl; }};int main(){ Base *p1 = new Derive(); Base *p2 = new Base(); Derive *p3 = new Derive(); //转换成功 p3 = dynamic_cast&lt;Derive *&gt;(p1); if (p3 == NULL) { cout &lt;&lt; &quot;NULL&quot; &lt;&lt; endl; } else { cout &lt;&lt; &quot;NOT NULL&quot; &lt;&lt; endl; // 输出 } //转换失败 p3 = dynamic_cast&lt;Derive *&gt;(p2); if (p3 == NULL) { cout &lt;&lt; &quot;NULL&quot; &lt;&lt; endl; // 输出 } else { cout &lt;&lt; &quot;NOT NULL&quot; &lt;&lt; endl; } return 0;} 1.1.14 如何判断结构体是否相等？能否用 memcmp 函数判断结构体相等？需要重载操作符 == 判断两个结构体是否相等，不能用函数 memcmp 来判断两个结构体是否相等，因为 memcmp 函数是逐个字节进行比较的，而结构体存在内存空间中保存时存在字节对齐，字节对齐时补的字节内容是随机的，会产生垃圾值，所以无法比较。 利用运算符重载来实现结构体对象的比较： 123456789101112131415161718192021222324252627#include &lt;iostream&gt;using namespace std;struct A{ char c; int val; A(char c_tmp, int tmp) : c(c_tmp), val(tmp) {} friend bool operator==(const A &amp;tmp1, const A &amp;tmp2); // 友元运算符重载函数};bool operator==(const A &amp;tmp1, const A &amp;tmp2){ return (tmp1.c == tmp2.c &amp;&amp; tmp1.val == tmp2.val);}int main(){ A ex1('a', 90), ex2('b', 80); if (ex1 == ex2) cout &lt;&lt; &quot;ex1 == ex2&quot; &lt;&lt; endl; else cout &lt;&lt; &quot;ex1 != ex2&quot; &lt;&lt; endl; // 输出 return 0;} 1.1.15 参数传递时，值传递、引用传递、指针传递的区别？参数传递的三种方式： 值传递：形参是实参的拷贝，函数对形参的所有操作不会影响实参。 指针传递：本质上是值传递，只不过拷贝的是指针的值，拷贝之后，实参和形参是不同的指针，通过指针可以间接的访问指针所指向的对象，从而可以修改它所指对象的值。 引用传递：当形参是引用类型时，我们说它对应的实参被引用传递。 1234567891011121314151617181920212223242526272829303132333435363738#include &lt;iostream&gt;using namespace std;void fun1(int tmp){ // 值传递 cout &lt;&lt; &amp;tmp &lt;&lt; endl;}void fun2(int * tmp){ // 指针传递 cout &lt;&lt; tmp &lt;&lt; endl;}void fun3(int &amp;tmp){ // 引用传递 cout &lt;&lt; &amp;tmp &lt;&lt; endl;}int main(){ int var = 5; cout &lt;&lt; &quot;var 在主函数中的地址：&quot; &lt;&lt; &amp;var &lt;&lt; endl; cout &lt;&lt; &quot;var 值传递时的地址：&quot;; fun1(var); cout &lt;&lt; &quot;var 指针传递时的地址：&quot;; fun2(&amp;var); cout &lt;&lt; &quot;var 引用传递时的地址：&quot;; fun3(var); return 0;}/*运行结果：var 在主函数中的地址：0x23fe4cvar 值传递时的地址：0x23fe20var 指针传递时的地址：0x23fe4cvar 引用传递时的地址：0x23fe4c*/ 1.1.16 什么是模板？如何实现？模板：创建类或者函数的蓝图或者公式，分为函数模板和类模板。实现方式：模板定义以关键字 template 开始，后跟一个模板参数列表。 模板参数列表不能为空； 模板类型参数前必须使用关键字 class 或者 typename，在模板参数列表中这两个关键字含义相同，可互换使用。 1template &lt;typename T, typename U, ...&gt; 函数模板：通过定义一个函数模板，可以避免为每一种类型定义一个新函数。 对于函数模板而言，模板类型参数可以用来指定返回类型或函数的参数类型，以及在函数体内用于变量声明或类型转换。 函数模板实例化：当调用一个模板时，编译器用函数实参来推断模板实参，从而使用实参的类型来确定绑定到模板参数的类型。 12345678910111213141516171819#include&lt;iostream&gt;using namespace std;template &lt;typename T&gt;T add_fun(const T &amp; tmp1, const T &amp; tmp2){ return tmp1 + tmp2;}int main(){ int var1, var2; cin &gt;&gt; var1 &gt;&gt; var2; cout &lt;&lt; add_fun(var1, var2); double var3, var4; cin &gt;&gt; var3 &gt;&gt; var4; cout &lt;&lt; add_fun(var3, var4); return 0;} 类模板：类似函数模板，类模板以关键字 template 开始，后跟模板参数列表。但是，编译器不能为类模板推断模板参数类型，需要在使用该类模板时，在模板名后面的尖括号中指明类型。 123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;using namespace std;template &lt;typename T&gt;class Complex{public: //构造函数 Complex(T a, T b) { this-&gt;a = a; this-&gt;b = b; } //运算符重载 Complex&lt;T&gt; operator+(Complex &amp;c) { Complex&lt;T&gt; tmp(this-&gt;a + c.a, this-&gt;b + c.b); cout &lt;&lt; tmp.a &lt;&lt; &quot; &quot; &lt;&lt; tmp.b &lt;&lt; endl; return tmp; }private: T a; T b;};int main(){ Complex&lt;int&gt; a(10, 20); Complex&lt;int&gt; b(20, 30); Complex&lt;int&gt; c = a + b; return 0;} 1.1.17 函数模板和类模板的区别？ 实例化方式不同：函数模板实例化由编译程序在处理函数调用时自动完成，类模板实例化需要在程序中显示指定。 实例化的结果不同：函数模板实例化后是一个函数，类模板实例化后是一个类。 默认参数：类模板在模板参数列表中可以有默认参数。 特化：函数模板只能全特化；而类模板可以全特化，也可以偏特化。 调用方式不同：函数模板可以隐式调用，也可以显示调用；类模板只能显示调用。 函数模板调用方式举例： 12345678910111213141516171819#include&lt;iostream&gt;using namespace std;template &lt;typename T&gt;T add_fun(const T &amp; tmp1, const T &amp; tmp2){ return tmp1 + tmp2;}int main(){ int var1, var2; cin &gt;&gt; var1 &gt;&gt; var2; cout &lt;&lt; add_fun&lt;int&gt;(var1, var2); // 显示调用 double var3, var4; cin &gt;&gt; var3 &gt;&gt; var4; cout &lt;&lt; add_fun(var3, var4); // 隐式调用 return 0;} 1.1.18 什么是可变参数模板？可变参数模板：接受可变数目参数的模板函数或模板类。将可变数目的参数被称为参数包，包括模板参数包和函数参数包。 模板参数包：表示零个或多个模板参数； 函数参数包：表示零个或多个函数参数。 用省略号来指出一个模板参数或函数参数表示一个包，在模板参数列表中，class… 或 typename… 指出接下来的参数表示零个或多个类型的列表；一个类型名后面跟一个省略号表示零个或多个给定类型的非类型参数的列表。当需要知道包中有多少元素时，可以使用 sizeof… 运算符。 12345678910111213141516171819202122232425262728template &lt;typename T, typename... Args&gt; // Args 是模板参数包void foo(const T &amp;t, const Args&amp;... rest); // 可变参数模板，rest 是函数参数包#include &lt;iostream&gt;using namespace std;template &lt;typename T&gt;void print_fun(const T &amp;t){ cout &lt;&lt; t &lt;&lt; endl; // 最后一个元素}template &lt;typename T, typename... Args&gt;void print_fun(const T &amp;t, const Args &amp;...args){ cout &lt;&lt; t &lt;&lt; &quot; &quot;; print_fun(args...);}int main(){ print_fun(&quot;Hello&quot;, &quot;wolrd&quot;, &quot;!&quot;); return 0;}/*运行结果：Hello worldd !*/ 说明：可变参数函数通常是递归的，第一个版本的 print_fun 负责终止递归并打印初始调用中的最后一个实参。第二个版本的 print_fun 是可变参数版本，打印绑定到 t 的实参，并用来调用自身来打印函数参数包中的剩余值。 1.1.19 什么是模板特化？为什么特化？模板特化的原因：模板并非对任何模板实参都合适、都能实例化，某些情况下，通用模板的定义对特定类型不合适，可能会编译失败，或者得不到正确的结果。因此，当不希望使用模板版本时，可以定义类或者函数模板的一个特例化版本。 模板特化：模板参数在某种特定类型下的具体实现。分为函数模板特化和类模板特化 函数模板特化：将函数模板中的全部类型进行特例化，称为函数模板特化。 类模板特化：将类模板中的部分或全部类型进行特例化，称为类模板特化。 特化分为全特化和偏特化： 全特化：模板中的模板参数全部特例化。 偏特化：模板中的模板参数只确定了一部分，剩余部分需要在编译器编译时确定。 说明：要区分下函数重载与函数模板特化定义函数模板的特化版本，本质上是接管了编译器的工作，为原函数模板定义了一个特殊实例，而不是函数重载，函数模板特化并不影响函数匹配。 实例： 123456789101112131415161718192021222324252627282930313233#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;//函数模板template &lt;class T&gt;bool compare(T t1, T t2){ cout &lt;&lt; &quot;通用版本：&quot;; return t1 == t2;}template &lt;&gt; //函数模板特化bool compare(char *t1, char *t2){ cout &lt;&lt; &quot;特化版本：&quot;; return strcmp(t1, t2) == 0;}int main(int argc, char *argv[]){ char arr1[] = &quot;hello&quot;; char arr2[] = &quot;abc&quot;; cout &lt;&lt; compare(123, 123) &lt;&lt; endl; cout &lt;&lt; compare(arr1, arr2) &lt;&lt; endl; return 0;}/*运行结果：通用版本：1特化版本：0*/ 1.1.20 include “ “ 和 &lt;&gt; 的区别 查找文件的位置：include&lt;文件名&gt; 在标准库头文件所在的目录中查找，如果没有，再到当前源文件所在目录下查找；#include”文件名” 在当前源文件所在目录中进行查找，如果没有；再到系统目录中查找。 使用习惯：对于标准库中的头文件常用 include&lt;文件名&gt;，对于自己定义的头文件，常用 #include”文件名” 1.1.21 switch 的 case 里为何不能定义变量switch 下面的这个花括号表示一块作用域，而不是每一个 case 表示一块作用域。如果在某一 case 中定义了变量，其作用域在这块花括号内，按理说在另一个 case 内可以使用该变量，但是在实际使用时，每一个 case 之间互不影响，是相对封闭的，参考如下实例。下述代码中，在 switch 的 case 中定义的变量，没有实际意义，仅为了解释上述原因。 123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;using namespace std;int main(){ // 局部变量声明 char var = 'D'; switch (var) { case 'A': int cnt = 0; // 定义变量 cout &lt;&lt; &quot;Excellent.&quot; &lt;&lt; endl &lt;&lt; cnt; break; case 'B': case 'C': ++cnt; cout &lt;&lt; &quot;Good.&quot; &lt;&lt; endl &lt;&lt; cnt; break; case 'D': cout &lt;&lt; &quot;Not bad.&quot; &lt;&lt; endl &lt;&lt; cnt; break; case 'F': cout &lt;&lt; &quot;Bad.&quot; &lt;&lt; endl &lt;&lt; cnt; break; default: cout &lt;&lt; &quot;Bad.&quot; &lt;&lt; endl &lt;&lt; cnt; } return 0;} 1.1.22 迭代器的作用？迭代器：一种抽象的设计概念，在设计模式中有迭代器模式，即提供一种方法，使之能够依序寻访某个容器所含的各个元素，而无需暴露该容器的内部表述方式。 作用：在无需知道容器底层原理的情况下，遍历容器中的元素。 123456789101112131415161718#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;int main(){ vector&lt;int&gt; arr = {1, 2, 3, 4, 5, 6, 7, 8, 9, 0}; vector&lt;int&gt;::iterator iter = arr.begin(); // 定义迭代器 for (; iter != arr.end(); ++iter) { cout &lt;&lt; *iter &lt;&lt; &quot; &quot;; } return 0;}/*运行结果：1 2 3 4 5 6 7 8 9 0*/ 1.1.23 泛型编程如何实现？一种语言机制，能够帮助实现一个通用的标准容器库。所谓通用的标准容器库，就是要能够做到，比如用一个List类存放所有可能类型的对象这样的事；泛型编程让你编写完全一般化并可重复使用的算法，其效率与针对某特定数据类型而设计的算法相同。 泛型编程实现的基础：模板。模板是创建类或者函数的蓝图或者说公式，当时用一个 vector 这样的泛型，或者 find 这样的泛型函数时，编译时会转化为特定的类或者函数。 泛型编程涉及到的知识点较广，例如：容器、迭代器、算法等都是泛型编程的实现实例。面试者可选择自己掌握比较扎实的一方面进行展开。 容器：涉及到 STL 中的容器，例如：vector、list、map 等，可选其中熟悉底层原理的容器进行展开讲解。 迭代器：在无需知道容器底层原理的情况下，遍历容器中的元素。 模板：可参考本章节中的模板相关问题。 1.1.24 什么是类型萃取？类型萃取使用模板技术来萃取类型（包含自定义类型和内置类型）的某些特性，用以判断该类型是否含有某些特性，从而在泛型算法中来对该类型进行特殊的处理用来提高效率或者其他。 如STL中copy()的实现，根据容器内部所含对象的不同，选择不同复制方式。又如STL中的算法，根据迭代器种类的不同（单向，双向，随机），可使用不同算法实现来提高效率。 1.2 编译与内存1.2.1 C++ 程序编译过程 编译过程分为四个过程：编译（编译预处理、编译、优化），汇编，链接。 编译预处理：处理以 # 开头的指令； 编译、优化：将源码 .cpp 文件翻译成 .s 汇编代码； 汇编：将汇编代码 .s 翻译成机器指令 .o 文件； 链接：汇编程序生成的目标文件，即 .o 文件，并不会立即执行，因为可能会出现：.cpp 文件中的函数引用了另一个 .cpp 文件中定义的符号或者调用了某个库文件中的函数。那链接的目的就是将这些文件对应的目标文件连接成一个整体，从而生成可执行的程序 .exe 文件。 链接分为两种： 静态链接：代码从其所在的静态链接库中拷贝到最终的可执行程序中，在该程序被执行时，这些代码会被装入到该进程的虚拟地址空间中。 动态链接：代码被放到动态链接库或共享对象的某个目标文件中，链接程序只是在最终的可执行程序中记录了共享对象的名字等一些信息。在程序执行时，动态链接库的全部内容会被映射到运行时相应进行的虚拟地址的空间。 二者的优缺点： 静态链接：浪费空间，每个可执行程序都会有目标文件的一个副本，这样如果目标文件进行了更新操作，就需要重新进行编译链接生成可执行程序（更新困难）；优点就是执行的时候运行速度快，因为可执行程序具备了程序运行的所有内容。 动态链接：节省内存、更新方便，但是动态链接是在程序运行时，每次执行都需要链接，相比静态链接会有一定的性能损失。 1.2.2 C++ 内存管理 C++ 内存分区：栈、堆、全局/静态存储区、常量存储区、代码区。 栈：存放函数的局部变量、函数参数、返回地址等，由编译器自动分配和释放。 堆：动态申请的内存空间，就是由 malloc 分配的内存块，由程序员控制它的分配和释放，如果程序执行结束还没有释放，操作系统会自动回收。 全局区/静态存储区（.bss 段和 .data 段）：存放全局变量和静态变量，程序运行结束操作系统自动释放，在 C 语言中，未初始化的放在 .bss 段中，初始化的放在 .data 段中，C++ 中不再区分了。 常量存储区（.data 段）：存放的是常量，不允许修改，程序运行结束自动释放。 代码区（.text 段）：存放代码，不允许修改，但可以执行。编译后的二进制文件存放在这里。 123456789101112131415161718192021#include &lt;iostream&gt;using namespace std;/*说明：C++ 中不再区分初始化和未初始化的全局变量、静态变量的存储区，如果非要区分下述程序标注在了括号中*/int g_var = 0; // g_var 在全局区（.data 段）char *gp_var; // gp_var 在全局区（.bss 段）int main(){ int var; // var 在栈区 char *p_var; // p_var 在栈区 char arr[] = &quot;abc&quot;; // arr 为数组变量，存储在栈区；&quot;abc&quot;为字符串常量，存储在常量区 char *p_var1 = &quot;123456&quot;; // p_var1 在栈区；&quot;123456&quot;为字符串常量，存储在常量区 static int s_var = 0; // s_var 为静态变量，存在静态存储区（.data 段） p_var = (char *)malloc(10); // 分配得来的 10 个字节的区域在堆区 free(p_var); return 0;} 1.2.3 栈和堆的区别 申请方式：栈是系统自动分配，堆是程序员主动申请。 申请后系统响应：分配栈空间，如果剩余空间大于申请空间则分配成功，否则分配失败栈溢出；申请堆空间，堆在内存中呈现的方式类似于链表（记录空闲地址空间的链表），在链表上寻找第一个大于申请空间的节点分配给程序，将该节点从链表中删除，大多数系统中该块空间的首地址存放的是本次分配空间的大小，便于释放，将该块空间上的剩余空间再次连接在空闲链表上。 栈在内存中是连续的一块空间（向低地址扩展）最大容量是系统预定好的，堆在内存中的空间（向高地址扩展）是不连续的。 申请效率：栈是有系统自动分配，申请效率高，但程序员无法控制；堆是由程序员主动申请，效率低，使用起来方便但是容易产生碎片。 存放的内容：栈中存放的是局部变量，函数的参数；堆中存放的内容由程序员控制。 1.2.4 全局变量、局部变量、静态全局变量、静态局部变量的区别C++ 变量根据定义的位置的不同的生命周期，具有不同的作用域，作用域可分为 6 种：全局作用域，局部作用域，语句作用域，类作用域，命名空间作用域和文件作用域。 从作用域看： 全局变量：具有全局作用域。全局变量只需在一个源文件中定义，就可以作用于所有的源文件。当然，其他不包含全局变量定义的源文件需要用 extern 关键字再次声明这个全局变量。（外部链接性、静态持续变量） 静态全局变量：具有文件作用域。它与全局变量的区别在于如果程序包含多个文件的话，它作用于定义它的文件里，不能作用到其它文件里，即被 static 关键字修饰过的变量具有文件作用域。这样即使两个不同的源文件都定义了相同名字的静态全局变量，它们也是不同的变量。（内部链接性、静态持续变量） 局部变量：具有局部作用域。它是自动对象（auto），在程序运行期间不是一直存在，而是只在函数执行期间存在，函数的一次调用执行结束后，变量被撤销，其所占用的内存也被收回。（自动存储持续性的变量） 静态局部变量：具有局部作用域。它只被初始化一次，自从第一次被初始化直到程序运行结束都一直存在，它和全局变量的区别在于全局变量对所有的函数都是可见的，而静态局部变量只对定义自己的函数体始终可见。（无链接性、静态持续变量） 从分配内存空间看： 静态存储区：全局变量，静态局部变量，静态全局变量。 栈：局部变量。 说明： 静态变量和栈变量（存储在栈中的变量）、堆变量（存储在堆中的变量）的区别：静态变量会被放在程序的静态数据存储区（.data 段）中（静态变量会自动初始化），这样可以在下一次调用的时候还可以保持原来的赋值。而栈变量或堆变量不能保证在下一次调用的时候依然保持原来的值。 静态变量和全局变量的区别：静态变量用 static 告知编译器，自己仅仅在变量的作用范围内可见。 1.2.5 全局变量定义在头文件中有什么问题？如果在头文件中定义全局变量，当该头文件被多个文件 include 时，该头文件中的全局变量就会被定义多次，导致重复定义，因此不能在头文件中定义全局变量。 #ifndef只防止重复include同一头文件，不同的文件include同一头文件是可以的；如果这个头文件里定义了全局变量，每个include该头文件的文件都会生成各自的同名全局变量，导致重复定义。 1.2.6 如何限制类的对象只能在堆上创建？如何限制对象只能在栈上创建？C++ 中的类的对象的建立分为两种：静态建立、动态建立。 静态建立：由编译器为对象在栈空间上分配内存，直接调用类的构造函数创建对象。例如：A a; 动态建立：使用 new 关键字在堆空间上创建对象，底层首先调用 operator new() 函数，在堆空间上寻找合适的内存并分配；然后，调用类的构造函数创建对象。例如：A *p = new A(); 限制对象只能建立在堆上： 最直观的思想：避免直接调用类的构造函数，因为对象静态建立时，会调用类的构造函数创建对象。但是直接将类的构造函数设为私有并不可行，因为当构造函数设置为私有后，不能在类的外部调用构造函数来构造对象，只能用 new 来建立对象。但是由于 new 创建对象时，底层也会调用类的构造函数，将构造函数设置为私有后，那就无法在类的外部使用 new 创建对象了。因此，这种方法不可行。 方法一：将析构函数设置为私有。原因：静态对象建立在栈上，是由编译器分配和释放内存空间，编译器为对象分配内存空间时，会对类的非静态函数进行检查，即编译器会检查析构函数的访问性。当析构函数设为私有时，编译器创建的对象就无法通过访问析构函数来释放对象的内存空间，因此，编译器不会在栈上为对象分配内存。 1234567891011121314class A{public: A() {} void destory() { delete this; }private: ~A() { }}; 该方法存在的问题： 用 new 创建的对象，通常会使用 delete 释放该对象的内存空间，但此时类的外部无法调用析构函数，因此类内必须定义一个 destory() 函数，用来释放 new 创建的对象。 无法解决继承问题，因为如果这个类作为基类，析构函数要设置成 virtual，然后在派生类中重写该函数，来实现多态。但此时，析构函数是私有的，派生类中无法访问。 方法二：构造函数设置为 protected，并提供一个 public 的静态函数来完成构造，而不是在类的外部使用 new 构造；将析构函数设置为 protected。原因：类似于单例模式，也保证了在派生类中能够访问析构函数。通过调用 create() 函数在堆上创建对象。 12345678910111213141516class A{protected: A() {} ~A() {}public: static A *create() { return new A(); } void destory() { delete this; }}; 限制对象只能建立在栈上： 解决方法：将 operator new() 设置为私有。原因：当对象建立在堆上时，是采用 new 的方式进行建立，其底层会调用 operator new() 函数，因此只要对该函数加以限制，就能够防止对象建立在堆上。 123456789class A{private: void *operator new(size_t t) {} // 注意函数的第一个参数和返回值都是固定的 void operator delete(void *ptr) {} // 重载了 new 就需要重载 deletepublic: A() {} ~A() {}}; 1.2.7 什么是内存对齐？内存对齐的原则？为什么要进行内存对齐，有什么优点？内存对齐：编译器将程序中的每个“数据单元”安排在字的整数倍的地址指向的内存之中内存对齐的原则： 结构体变量的首地址能够被其最宽基本类型成员大小与对齐基数中的较小者所整除； 结构体每个成员相对于结构体首地址的偏移量 （offset） 都是该成员大小与对齐基数中的较小者的整数倍，如有需要编译器会在成员之间加上填充字节 （internal padding）； 结构体的总大小为结构体最宽基本类型成员大小与对齐基数中的较小者的整数倍，如有需要编译器会在最末一个成员之后加上填充字节 （trailing padding）。 实例： 1234567891011121314151617181920212223242526272829303132/*说明：程序是在 64 位编译器下测试的*/#include &lt;iostream&gt;using namespace std;struct A{ short var; // 2 字节 int var1; // 8 字节 （内存对齐原则：填充 2 个字节） 2 (short) + 2 (填充) + 4 (int)= 8 long var2; // 12 字节 8 + 4 (long) = 12 char var3; // 16 字节 （内存对齐原则：填充 3 个字节）12 + 1 (char) + 3 (填充) = 16 string s; // 48 字节 16 + 32 (string) = 48};int main(){ short var; int var1; long var2; char var3; string s; A ex1; cout &lt;&lt; sizeof(var) &lt;&lt; endl; // 2 short cout &lt;&lt; sizeof(var1) &lt;&lt; endl; // 4 int cout &lt;&lt; sizeof(var2) &lt;&lt; endl; // 4 long cout &lt;&lt; sizeof(var3) &lt;&lt; endl; // 1 char cout &lt;&lt; sizeof(s) &lt;&lt; endl; // 32 string cout &lt;&lt; sizeof(ex1) &lt;&lt; endl; // 48 struct return 0;} 进行内存对齐的原因：（主要是硬件设备方面的问题） 某些硬件设备只能存取对齐数据，存取非对齐的数据可能会引发异常； 某些硬件设备不能保证在存取非对齐数据的时候的操作是原子操作； 相比于存取对齐的数据，存取非对齐的数据需要花费更多的时间； 某些处理器虽然支持非对齐数据的访问，但会引发对齐陷阱（alignment trap）； 某些硬件设备只支持简单数据指令非对齐存取，不支持复杂数据指令的非对齐存取。 内存对齐的优点： 便于在不同的平台之间进行移植，因为有些硬件平台不能够支持任意地址的数据访问，只能在某些地址处取某些特定的数据，否则会抛出异常； 提高内存的访问效率，因为 CPU 在读取内存时，是一块一块的读取。 1.2.8 类大小的计算说明：类的大小是指类的实例化对象的大小，用 sizeof 对类型名操作时，结果是该类型的对象的大小。 计算原则： 遵循结构体的对齐原则。 与普通成员变量有关，与成员函数和静态成员无关。即普通成员函数，静态成员函数，静态数据成员，静态常量数据成员均对类的大小无影响。因为静态数据成员被类的对象共享，并不属于哪个具体的对象。 虚函数对类的大小有影响，是因为虚函数表指针的影响。 虚继承对类的大小有影响，是因为虚基表指针带来的影响。 空类的大小是一个特殊情况，空类的大小为 1，当用 new 来创建一个空类的对象时，为了保证不同对象的地址不同，空类也占用存储空间。 实例：简单情况和空类情况 123456789101112131415161718192021222324252627282930/*说明：程序是在 64 位编译器下测试的*/#include &lt;iostream&gt;using namespace std;class A{private: static int s_var; // 不影响类的大小 const int c_var; // 4 字节 int var; // 8 字节 4 + 4 (int) = 8 char var1; // 12 字节 8 + 1 (char) + 3 (填充) = 12public: A(int temp) : c_var(temp) {} // 不影响类的大小 ~A() {} // 不影响类的大小};class B{};int main(){ A ex1(4); B ex2; cout &lt;&lt; sizeof(ex1) &lt;&lt; endl; // 12 字节 cout &lt;&lt; sizeof(ex2) &lt;&lt; endl; // 1 字节 return 0;} 带有虚函数的情况：（注意：虚函数的个数并不影响所占内存的大小，因为类对象的内存中只保存了指向虚函数表的指针。） 1234567891011121314151617181920212223242526272829303132/*说明：程序是在 64 位编译器下测试的*/#include &lt;iostream&gt;using namespace std;class A{private: static int s_var; // 不影响类的大小 const int c_var; // 4 字节 int var; // 8 字节 4 + 4 (int) = 8 char var1; // 12 字节 8 + 1 (char) + 3 (填充) = 12public: A(int temp) : c_var(temp) {} // 不影响类的大小 ~A() {} // 不影响类的大小 virtual void f() { cout &lt;&lt; &quot;A::f&quot; &lt;&lt; endl; } virtual void g() { cout &lt;&lt; &quot;A::g&quot; &lt;&lt; endl; } virtual void h() { cout &lt;&lt; &quot;A::h&quot; &lt;&lt; endl; } // 24 字节 12 + 4 (填充) + 8 (指向虚函数的指针) = 24};int main(){ A ex1(4); A *p; cout &lt;&lt; sizeof(p) &lt;&lt; endl; // 8 字节 注意：指针所占的空间和指针指向的数据类型无关 cout &lt;&lt; sizeof(ex1) &lt;&lt; endl; // 24 字节 return 0;} 1.2.9 什么是内存泄露内存泄漏：由于疏忽或错误导致的程序未能释放已经不再使用的内存。 进一步解释： 并非指内存从物理上消失，而是指程序在运行过程中，由于疏忽或错误而失去了对该内存的控制，从而造成了内存的浪费。 常指堆内存泄漏，因为堆是动态分配的，而且是用户来控制的，如果使用不当，会产生内存泄漏。 使用 malloc、calloc、realloc、new 等分配内存时，使用完后要调用相应的 free 或 delete 释放内存，否则这块内存就会造成内存泄漏。 指针重新赋值 123char *p = (char *)malloc(10);char *p1 = (char *)malloc(10);p = np; 开始时，指针 p 和 p1 分别指向一块内存空间，但指针 p 被重新赋值，导致 p 初始时指向的那块内存空间无法找到，从而发生了内存泄漏。 1.2.10 怎么防止内存泄漏？内存泄漏检测工具的原理？防止内存泄漏的方法： 内部封装：将内存的分配和释放封装到类中，在构造的时候申请内存，析构的时候释放内存。 123456789101112131415161718192021222324252627282930313233343536373839404142#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;class A{private: char *p; unsigned int p_size;public: A(unsigned int n = 1) // 构造函数中分配内存空间 { p = new char[n]; p_size = n; }; ~A() // 析构函数中释放内存空间 { if (p != NULL) { delete[] p; // 删除字符数组 p = NULL; // 防止出现野指针 } }; char *GetPointer() { return p; };};void fun(){ A ex(100); char *p = ex.GetPointer(); strcpy(p, &quot;Test&quot;); cout &lt;&lt; p &lt;&lt; endl;}int main(){ fun(); return 0;} 说明：但这样做并不是最佳的做法，在类的对象复制时，程序会出现同一块内存空间释放两次的情况，请看如下程序： 12345678void fun1(){ A ex(100); A ex1 = ex; char *p = ex.GetPointer(); strcpy(p, &quot;Test&quot;); cout &lt;&lt; p &lt;&lt; endl;} 简单解释：对于 fun1 这个函数中定义的两个类的对象而言，在离开该函数的作用域时，会两次调用析构函数来释放空间，但是这两个对象指向的是同一块内存空间，所以导致同一块内存空间被释放两次，可以通过增加计数机制来避免这种情况，只有当计数变量为 0 的时候才会释放该块内存空间，看如下程序： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576#include &lt;iostream&gt; #include &lt;cstring&gt; using namespace std; class A { private: char *p; unsigned int p_size; int *p_count; // 计数变量 public: A(unsigned int n = 1) // 在构造函数中申请内存 { p = new char[n]; p_size = n; p_count = new int; *p_count = 1; cout &lt;&lt; &quot;count is : &quot; &lt;&lt; *p_count &lt;&lt; endl; }; A(const A &amp;temp) { p = temp.p; p_size = temp.p_size; p_count = temp.p_count; (*p_count)++; // 复制时，计数变量 +1 cout &lt;&lt; &quot;count is : &quot; &lt;&lt; *p_count &lt;&lt; endl; } ~A() { (*p_count)--; // 析构时，计数变量 -1 cout &lt;&lt; &quot;count is : &quot; &lt;&lt; *p_count &lt;&lt; endl; if (*p_count == 0) // 只有当计数变量为 0 的时候才会释放该块内存空间 { cout &lt;&lt; &quot;buf is deleted&quot; &lt;&lt; endl; if (p != NULL) { delete[] p; // 删除字符数组 p = NULL; // 防止出现野指针 if (p_count != NULL) { delete p_count; p_count = NULL; } } } }; char *GetPointer() { return p; }; }; void fun() { A ex(100); char *p = ex.GetPointer(); strcpy(p, &quot;Test&quot;); cout &lt;&lt; p &lt;&lt; endl; A ex1 = ex; // 此时计数变量会 +1 cout &lt;&lt; &quot;ex1.p = &quot; &lt;&lt; ex1.GetPointer() &lt;&lt; endl; } int main() { fun(); return 0; }count is : 1Testcount is : 2ex1.p = Testcount is : 1count is : 0buf is deleted 解释下：程序运行结果的倒数 2、3 行是调用两次析构函数时进行的操作，在第二次调用析构函数时，进行内存空间的释放，从而会有倒数第 1 行的输出结果。 智能指针智能指针是 C++ 中已经对内存泄漏封装好了一个工具，可以直接拿来使用。 内存泄漏检测工具的实现原理： 内存检测工具有很多，这里重点介绍下 valgrind 。 valgrind 是一套 Linux 下，开放源代码（GPL V2）的仿真调试工具的集合，包括以下工具： Memcheck：内存检查器（valgrind 应用最广泛的工具），能够发现开发中绝大多数内存错误的使用情况，比如：使用未初始化的内存，使用已经释放了的内存，内存访问越界等。 Callgrind：检查程序中函数调用过程中出现的问题。 Cachegrind：检查程序中缓存使用出现的问题。 Helgrind：检查多线程程序中出现的竞争问题。Massif：检查程序中堆栈使用中出现的问题。 Extension：可以利用 core 提供的功能，自己编写特定的内存调试工具。 Memcheck 能够检测出内存问题，关键在于其建立了两个全局表： Valid-Value 表：对于进程的整个地址空间中的每一个字节（byte），都有与之对应的 8 个 bits ；对于 CPU 的每个寄存器，也有一个与之对应的 bit 向量。这些 bits 负责记录该字节或者寄存器值是否具有有效的、已初始化的值。 Valid-Address 表：对于进程整个地址空间中的每一个字节（byte），还有与之对应的 1 个 bit，负责记录该地址是否能够被读写。 检测原理： 当要读写内存中某个字节时，首先检查这个字节对应的 Valid-Address 表中对应的 bit。如果该 bit 显示该位置是无效位置，Memcheck 则报告读写错误。 内核（core）类似于一个虚拟的 CPU 环境，这样当内存中的某个字节被加载到真实的 CPU 中时，该字节在 Valid-Value 表对应的 bits 也被加载到虚拟的 CPU 环境中。一旦寄存器中的值，被用来产生内存地址，或者该值能够影响程序输出，则 Memcheck 会检查 Valid-Value 表对应的 bits，如果该值尚未初始化，则会报告使用未初始化内存错误。 1.2.11 智能指针有哪几种？智能指针的实现原理？智能指针是为了解决动态内存分配时带来的内存泄漏以及多次释放同一块内存空间而提出的。C++11 中封装在了 头文件中。 C++11 中智能指针包括以下三种： 共享指针（shared_ptr）：资源可以被多个指针共享，使用计数机制表明资源被几个指针共享。通过 use_count() 查看资源的所有者的个数，可以通过 unique_ptr、weak_ptr 来构造，调用 release() 释放资源的所有权，计数减一，当计数减为 0 时，会自动释放内存空间，从而避免了内存泄漏。 独占指针（unique_ptr）：独享所有权的智能指针，资源只能被一个指针占有，该指针不能拷贝构造和赋值。但可以进行移动构造和移动赋值构造（调用 move() 函数），即一个 unique_ptr 对象赋值给另一个 unique_ptr 对象，可以通过该方法进行赋值，目的是实现所有权的转移。 弱指针（weak_ptr）：指向 share_ptr 指向的对象，能够解决由shared_ptr带来的循环引用问题。 智能指针的实现原理： 计数原理。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081#include &lt;iostream&gt;#include &lt;memory&gt;template &lt;typename T&gt;class SmartPtr{private : T *_ptr; size_t *_count;public: SmartPtr(T *ptr = nullptr) : _ptr(ptr) { if (_ptr) { _count = new size_t(1); } else { _count = new size_t(0); } } ~SmartPtr() { (*this-&gt;_count)--; if (*this-&gt;_count == 0) { delete this-&gt;_ptr; delete this-&gt;_count; } } SmartPtr(const SmartPtr &amp;ptr) // 拷贝构造：计数 +1 { if (this != &amp;ptr) { this-&gt;_ptr = ptr._ptr; this-&gt;_count = ptr._count; (*this-&gt;_count)++; } } SmartPtr &amp;operator=(const SmartPtr &amp;ptr) // 赋值运算符重载 { if (this-&gt;_ptr == ptr._ptr) { return *this; } if (this-&gt;_ptr) // 将当前的 ptr 指向的原来的空间的计数 -1 { (*this-&gt;_count)--; if (this-&gt;_count == 0) { delete this-&gt;_ptr; delete this-&gt;_count; } } this-&gt;_ptr = ptr._ptr; this-&gt;_count = ptr._count; (*this-&gt;_count)++; // 此时 ptr 指向了新赋值的空间，该空间的计数 +1 return *this; } T &amp;operator*() { assert(this-&gt;_ptr == nullptr); return *(this-&gt;_ptr); } T *operator-&gt;() { assert(this-&gt;_ptr == nullptr); return this-&gt;_ptr; } size_t use_count() { return *this-&gt;count; }}; 1.2.12 使用智能指针会出现什么问题？怎么解决？智能指针可能出现的问题：循环引用，比如在双向链表中。在如下例子中定义了两个类 Parent、Child，在两个类中分别定义另一个类的对象的共享指针，由于在程序结束后，两个指针相互指向对方的内存空间，导致内存无法释放。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#include &lt;iostream&gt;#include &lt;memory&gt;using namespace std;class Child;class Parent;class Parent {private: shared_ptr&lt;Child&gt; ChildPtr;public: void setChild(shared_ptr&lt;Child&gt; child) { this-&gt;ChildPtr = child; } void doSomething() { if (this-&gt;ChildPtr.use_count()) { } } ~Parent() { }};class Child {private: shared_ptr&lt;Parent&gt; ParentPtr;public: void setPartent(shared_ptr&lt;Parent&gt; parent) { this-&gt;ParentPtr = parent; } void doSomething() { if (this-&gt;ParentPtr.use_count()) { } } ~Child() { }};int main() { weak_ptr&lt;Parent&gt; wpp; weak_ptr&lt;Child&gt; wpc; { shared_ptr&lt;Parent&gt; p(new Parent); shared_ptr&lt;Child&gt; c(new Child); p-&gt;setChild(c); c-&gt;setPartent(p); wpp = p; wpc = c; cout &lt;&lt; p.use_count() &lt;&lt; endl; // 2 cout &lt;&lt; c.use_count() &lt;&lt; endl; // 2 } cout &lt;&lt; wpp.use_count() &lt;&lt; endl; // 1 cout &lt;&lt; wpc.use_count() &lt;&lt; endl; // 1 return 0;} 强引用和弱引用一个强引用当被引用的对象活着的话，这个引用也存在（就是说，当至少有一个强引用，那么这个对象就不能被释放）。share_ptr就是强引用。相对而言，弱引用当引用的对象活着的时候不一定存在。仅仅是当它存在的时候的一个引用。弱引用并不修改该对象的引用计数，这意味这弱引用它并不对对象的内存进行管理，在功能上类似于普通指针，然而一个比较大的区别是，弱引用能检测到所管理的对象是否已经被释放，从而避免访问非法内存。 循环引用的解决方法： weak_ptr, weak_ptr的出现就是为了辅助shared_ptr的工作，弥补shared_ptr的不足，解决shared_ptr造成的循环引用问题，而weak_ptr的这种解决方法也就是弱引用。 循环引用：该被调用的析构函数没有被调用，从而出现了内存泄漏。 weak_ptr 对被 shared_ptr 管理的对象存在 非拥有性（弱）引用，在访问所引用的对象前必须先转化为 shared_ptr； weak_ptr 用来打断 shared_ptr 所管理对象的循环引用问题，若这种环被孤立（没有指向环中的外部共享指针），shared_ptr 引用计数无法抵达 0，内存被泄露；令环中的指针之一为弱指针可以避免该情况； weak_ptr 用来表达临时所有权的概念，当某个对象只有存在时才需要被访问，而且随时可能被他人删除，可以用 weak_ptr 跟踪该对象；需要获得所有权时将其转化为 shared_ptr，此时如果原来的 shared_ptr 被销毁，则该对象的生命期被延长至这个临时的 shared_ptr 同样被销毁。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#include &lt;iostream&gt;#include &lt;memory&gt;using namespace std;class Child;class Parent;class Parent {private: //shared_ptr&lt;Child&gt; ChildPtr; weak_ptr&lt;Child&gt; ChildPtr;public: void setChild(shared_ptr&lt;Child&gt; child) { this-&gt;ChildPtr = child; } void doSomething() { //new shared_ptr if (this-&gt;ChildPtr.lock()) { } } ~Parent() { }};class Child {private: shared_ptr&lt;Parent&gt; ParentPtr;public: void setPartent(shared_ptr&lt;Parent&gt; parent) { this-&gt;ParentPtr = parent; } void doSomething() { if (this-&gt;ParentPtr.use_count()) { } } ~Child() { }};int main() { weak_ptr&lt;Parent&gt; wpp; weak_ptr&lt;Child&gt; wpc; { shared_ptr&lt;Parent&gt; p(new Parent); shared_ptr&lt;Child&gt; c(new Child); p-&gt;setChild(c); c-&gt;setPartent(p); wpp = p; wpc = c; cout &lt;&lt; p.use_count() &lt;&lt; endl; // 2 cout &lt;&lt; c.use_count() &lt;&lt; endl; // 1 } cout &lt;&lt; wpp.use_count() &lt;&lt; endl; // 0 cout &lt;&lt; wpc.use_count() &lt;&lt; endl; // 0 return 0;} 1.3 关键字与库函数1.3.1 sizeof 和 strlen 的区别 strlen 是头文件 中的函数，sizeof 是 C++ 中的运算符。 strlen 测量的是字符串的实际长度（其源代码如下），以 \\0 结束。而 sizeof 测量的是字符数组的分配大小。 strlen 源代码: 123456789101112131415161718192021size_t strlen(const char *str) { size_t length = 0; while (*str++) ++length; return length;}#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;int main(){ char arr[10] = &quot;hello&quot;; cout &lt;&lt; strlen(arr) &lt;&lt; endl; // 5 cout &lt;&lt; sizeof(arr) &lt;&lt; endl; // 10 return 0;} 若字符数组 arr 作为函数的形参，sizeof(arr) 中 arr 被当作字符指针来处理，strlen(arr) 中 arr 依然是字符数组，从下述程序的运行结果中就可以看出。 12345678910111213141516171819202122#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;void size_of(char arr[]){ cout &lt;&lt; sizeof(arr) &lt;&lt; endl; // warning: 'sizeof' on array function parameter 'arr' will return size of 'char*' . cout &lt;&lt; strlen(arr) &lt;&lt; endl; }int main(){ char arr[20] = &quot;hello&quot;; size_of(arr); return 0;}/*输出结果：85*/ strlen 本身是库函数，因此在程序运行过程中，计算长度；而 sizeof 在编译时，计算长度； sizeof 的参数可以是类型，也可以是变量；strlen 的参数必须是 char* 类型的变量。 1.3.2 lambda 表达式（匿名函数）的具体应用和使用场景1234[capture list] (parameter list) -&gt; return type{ function body} capture list：捕获列表，指 lambda 表达式所在函数中定义的局部变量的列表，通常为空，但如果函数体中用到了 lambda 表达式所在函数的局部变量，必须捕获该变量，即将此变量写在捕获列表中。捕获方式分为：引用捕获方式 [&amp;]、值捕获方式 [=]。return type、parameter list、function body：分别表示返回值类型、参数列表、函数体，和普通函数一样。 lambda 表达式常搭配排序算法使用。 123456789101112131415161718#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;using namespace std;int main(){ vector&lt;int&gt; arr = {3, 4, 76, 12, 54, 90, 34}; sort(arr.begin(), arr.end(), [](int a, int b) { return a &gt; b; }); // 降序排序 for (auto a : arr) { cout &lt;&lt; a &lt;&lt; &quot; &quot;; } return 0;}/*运行结果：90 76 54 34 12 4 3*/ 1.3.3 explicit 的作用（如何避免编译器进行隐式类型转换）作用：用来声明类构造函数是显示调用的，而非隐式调用，可以阻止调用构造函数时进行隐式转换。只可用于修饰单参构造函数，因为无参构造函数和多参构造函数本身就是显示调用的，再加上 explicit 关键字也没有什么意义。 隐式转换： 123456789101112131415161718#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;class A{public: int var; A(int tmp) { var = tmp; }};int main(){ A ex = 10; // 发生了隐式转换 return 0;} 上述代码中，A ex = 10; 在编译时，进行了隐式转换，将 10 转换成 A 类型的对象，然后将该对象赋值给 ex，等同于如下操作： 为了避免隐式转换，可用 explicit 关键字进行声明： 1234567891011121314151617181920#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;class A{public: int var; explicit A(int tmp) { var = tmp; cout &lt;&lt; var &lt;&lt; endl; }};int main(){ A ex(100); A ex1 = 10; // error: conversion from 'int' to non-scalar type 'A' requested return 0;} 1.3.4 static 的作用 保持变量内容持久：static 作用于局部变量，改变了局部变量的生存周期，使得该变量存在于定义后直到程序运行结束的这段时间。 123456789101112131415#include &lt;iostream&gt;using namespace std;int fun(){ static int var = 1; // var 只在第一次进入这个函数的时初始化 var += 1; return var;} int main(){ for(int i = 0; i &lt; 10; ++i) cout &lt;&lt; fun() &lt;&lt; &quot; &quot;; // 2 3 4 5 6 7 8 9 10 11 return 0;} 隐藏：static 作用于全局变量和函数，改变了全局变量和函数的作用域，使得全局变量和函数只能在定义它的文件中使用，在源文件中不具有全局可见性。（注：普通全局变量和函数具有全局可见性，即其他的源文件也可以使用。） static 作用于类的成员变量和类的成员函数，使得类变量或者类成员函数和类有关，也就是说可以不定义类的对象就可以通过类访问这些静态成员。注意：类的静态成员函数中只能访问静态成员变量或者静态成员函数，不能将静态成员函数定义成虚函数。 123456789101112131415161718192021222324252627282930#include&lt;iostream&gt;using namespace std;class A{private: int var; static int s_var; // 静态成员变量public: void show() { cout &lt;&lt; s_var++ &lt;&lt; endl; } static void s_show() { cout &lt;&lt; s_var &lt;&lt; endl; // cout &lt;&lt; var &lt;&lt; endl; // error: invalid use of member 'A::a' in static member function. 静态成员函数不能调用非静态成员变量。无法使用 this.var // show(); // error: cannot call member function 'void A::show()' without object. 静态成员函数不能调用非静态成员函数。无法使用 this.show() }};int A::s_var = 1; // 静态成员变量在类外进行初始化赋值，默认初始化为 0int main(){ // cout &lt;&lt; A::sa &lt;&lt; endl; // error: 'int A::sa' is private within this context A ex; ex.show(); A::s_show();} 1.3.5 ★ static 在类中使用的注意事项（定义、初始化和使用）static 静态成员变量： 静态成员变量是在类内进行声明，在类外进行定义和初始化，在类外进行定义和初始化的时候不要出现 static 关键字和private、public、protected 访问规则。 静态成员变量相当于类域中的全局变量，被类的所有对象所共享，包括派生类的对象。 静态成员变量可以作为成员函数的参数，而普通成员变量不可以。 123456789101112131415#include &lt;iostream&gt;using namespace std;class A{public: static int s_var; int var; void fun1(int i = s_var); // 正确，静态成员变量可以作为成员函数的参数 void fun2(int i = var); // error: invalid use of non-static data member 'A::var'};int main(){ return 0;} 静态数据成员的类型可以是所属类的类型，而普通数据成员的类型只能是该类类型的指针或引用。 12345678910111213141516#include &lt;iostream&gt;using namespace std;class A{public: static A s_var; // 正确，静态数据成员 A var; // error: field 'var' has incomplete type 'A' A *p; // 正确，指针 A &amp;var1; // 正确，引用};int main(){ return 0;} static 静态成员函数： 静态成员函数不能调用非静态成员变量或者非静态成员函数，因为静态成员函数没有 this 指针。静态成员函数做为类作用域的全局函数。 静态成员函数不能声明成虚函数（virtual）、const 函数和 volatile 函数。 1.3.6 static 全局变量和普通全局变量的异同相同点： 存储方式：普通全局变量和 static 全局变量都是静态存储方式。 不同点： 作用域：普通全局变量的作用域是整个源程序，当一个源程序由多个源文件组成时，普通全局变量在各个源文件中都是有效的；静态全局变量则限制了其作用域，即只在定义该变量的源文件内有效，在同一源程序的其它源文件中不能使用它。由于静态全局变量的作用域限于一个源文件内，只能为该源文件内的函数公用，因此可以避免在其他源文件中引起错误。 初始化：静态全局变量只初始化一次，防止在其他文件中使用。？？？ 1.3.7 ★ const 作用及用法作用： const 修饰成员变量，定义成 const 常量，相较于宏常量，可进行类型检查，节省内存空间，提高了效率。 const 修饰函数参数，使得传递过来的函数参数的值不能改变。 const 修饰成员函数，使得成员函数不能修改任何类型的成员变量（mutable 修饰的变量除外），也不能调用非 const 成员函数，因为非 const 成员函数可能会修改成员变量。 在类中的用法： const 成员变量： const 成员变量只能在类内声明、定义，在构造函数初始化列表中初始化。 const 成员变量只在某个对象的生存周期内是常量，对于整个类而言却是可变的，因为类可以创建多个对象，不同类的 const 成员变量的值是不同的。因此不能在类的声明中初始化 const 成员变量，类的对象还没有创建，编译器不知道他的值。 const 成员函数： 不能修改成员变量的值，除非有 mutable 修饰；只能访问成员变量。 不能调用非常量成员函数，以防修改成员变量的值。 123456789101112131415161718192021222324#include &lt;iostream&gt;using namespace std;class A{public: int var; A(int tmp) : var(tmp) {} void c_fun(int tmp) const // const 成员函数 { var = tmp; // error: assignment of member 'A::var' in read-only object. 在 const 成员函数中，不能修改任何类成员变量。 fun(tmp); // error: passing 'const A' as 'this' argument discards qualifiers. const 成员函数不能调用非 const 成员函数，因为非 const 成员函数可能会修改成员变量。 } void fun(int tmp) { var = tmp; }};int main(){ return 0;} 1.3.8 define 和 const 的区别区别： 编译阶段：define 是在编译预处理阶段进行替换，const 是在编译阶段确定其值。 安全性：define 定义的宏常量没有数据类型，只是进行简单的替换，不会进行类型安全的检查；const 定义的常量是有类型的，是要进行判断的，可以避免一些低级的错误。 内存占用：define 定义的宏常量，在程序中使用多少次就会进行多少次替换，内存中有多个备份，占用的是代码段空间；const 定义的常量占用静态存储区的空间，程序运行过程中只有一份。 调试：define 定义的宏常量不能调试，因为在预编译阶段就已经进行替换了；const 定义的常量可以进行调试。 const 的优点： 有数据类型，在定义式可进行安全性检查。 可调式。 占用较少的空间。 1.3.9 define 和 typedef 的区别 原理：#define 作为预处理指令，在编译预处理时进行替换操作，不作正确性检查，只有在编译已被展开的源程序时才会发现可能的错误并报错。typedef 是关键字，在编译时处理，有类型检查功能，用来给一个已经存在的类型一个别名，但不能在一个函数定义里面使用 typedef 。 功能：typedef 用来定义类型的别名，方便使用。#define 不仅可以为类型取别名，还可以定义常量、变量、编译开关等。 作用域：#define 没有作用域的限制，只要是之前预定义过的宏，在以后的程序中都可以使用，而 typedef 有自己的作用域。 指针的操作：typedef 和 #define 在处理指针时不完全一样 1234567891011121314151617#include &lt;iostream&gt;#define INTPTR1 int *typedef int * INTPTR2;using namespace std;int main(){ INTPTR1 p1, p2; // p1: int *; p2: int INTPTR2 p3, p4; // p3: int *; p4: int * int var = 1; const INTPTR1 p5 = &amp;var; // 相当于 const int * p5; 常量指针，即不可以通过 p5 去修改 p5 指向的内容，但是 p5 可以指向其他内容。 const INTPTR2 p6 = &amp;var; // 相当于 int * const p6; 指针常量，不可使 p6 再指向其他内容。 return 0;} 1.3.10 用宏实现比较大小，以及两个数中的最小值1234567891011121314151617#include &lt;iostream&gt;#define MAX(X, Y) ((X)&gt;(Y)?(X):(Y))#define MIN(X, Y) ((X)&lt;(Y)?(X):(Y))using namespace std;int main (){ int var1 = 10, var2 = 100; cout &lt;&lt; MAX(var1, var2) &lt;&lt; endl; cout &lt;&lt; MIN(var1, var2) &lt;&lt; endl; return 0;}/*程序运行结果：10010*/ 1.3.11 inline 作用、使用方法和原理作用：inline 是一个关键字，可以用于定义内联函数。内联函数，像普通函数一样被调用，但是在调用时并不通过函数调用的机制而是直接在调用点处展开，这样可以大大减少由函数调用带来的开销，从而提高程序的运行效率。 使用方法： 类内定义成员函数默认是内联函数在类内定义成员函数，可以不用在函数头部加 inline 关键字，因为编译器会自动将类内定义的函数（构造函数、析构函数、普通成员函数等）声明为内联函数，代码如下： 123456789101112131415161718#include &lt;iostream&gt;using namespace std;class A{public: int var; A(int tmp){ var = tmp; } void fun(){ cout &lt;&lt; var &lt;&lt; endl; }};int main(){ return 0;} 类外定义成员函数，若想定义为内联函数，需用关键字声明当在类内声明函数，在类外定义函数时，如果想将该函数定义为内联函数，则可以在类内声明时不加 inline 关键字，而在类外定义函数时加上 inline 关键字。 1234567891011121314151617181920#include &lt;iostream&gt;using namespace std;class A{public: int var; A(int tmp){ var = tmp; } void fun();};inline void A::fun(){ cout &lt;&lt; var &lt;&lt; endl;}int main(){ return 0;} 另外，可以在声明函数和定义函数的同时加上 inline；也可以只在函数声明时加 inline，而定义函数时不加 inline。只要确保在调用该函数之前把 inline 的信息告知编译器即可。 原理： 内联函数不是在调用时发生控制转移关系，而是在编译阶段将函数体嵌入到每一个调用该函数的语句块中，编译器会将程序中出现内联函数的调用表达式用内联函数的函数体来替换。 普通函数是将程序执行转移到被调用函数所存放的内存地址，当函数执行完后，返回到执行此函数前的地方。转移操作需要保护现场，被调函数执行完后，再恢复现场，该过程需要较大的资源开销。 1.3.12 宏定义（define）和内联函数（inline）的区别 内联函数是在编译时展开，而宏在编译预处理时展开；在编译的时候，内联函数直接被嵌入到目标代码中去，而宏只是一个简单的文本替换。 内联函数是真正的函数，和普通函数调用的方法一样，在调用点处直接展开，避免了函数的参数压栈操作，减少了调用的开销。而宏定义编写较为复杂，常需要增加一些括号来避免歧义。 宏定义只进行文本替换，不会对参数的类型、语句能否正常编译等进行检查。而内联函数是真正的函数，会对参数的类型、函数体内的语句编写是否正确等进行检查。 1234567891011121314151617181920212223#include &lt;iostream&gt;#define MAX(a, b) ((a) &gt; (b) ? (a) : (b))using namespace std;inline int fun_max(int a, int b){ return a &gt; b ? a : b;}int main(){ int var = 1; cout &lt;&lt; MAX(var, 5) &lt;&lt; endl; cout &lt;&lt; fun_max(var, 0) &lt;&lt; endl; return 0;}/*程序运行结果：51*/ 1.3.13 new 和 malloc 如何判断是否申请到内存？malloc ：成功申请到内存，返回指向该内存的指针；分配失败，返回 NULL 指针。new ：内存分配成功，返回该对象类型的指针；分配失败，抛出 bac_alloc 异常。 1.3.14 delete 实现原理？delete 和 delete[] 的区别？delete 的实现原理： 首先执行该对象所属类的析构函数； 进而通过调用 operator delete() 的标准库函数来释放所占的内存空间。 delete 和 delete [] 的区别： delete 用来释放单个对象所占的空间，只会调用一次析构函数； delete [] 用来释放数组空间，会对数组中的每个成员都调用一次析构函数。 1.3.15 new 和 malloc 的区别，delete 和 free 的区别在使用的时候 new、delete 搭配使用，malloc、free 搭配使用。 malloc、free 是库函数，而new、delete 是关键字。new 申请空间时，无需指定分配空间的大小，编译器会根据类型自行计算；malloc 在申请空间时，需要确定所申请空间的大小。 new 申请空间时，返回的类型是对象的指针类型，无需强制类型转换，是类型安全的操作符；malloc 申请空间时，返回的是 void* 类型，需要进行强制类型的转换，转换为对象类型的指针。 new 分配失败时，会抛出 bad_alloc 异常，malloc 分配失败时返回空指针。 对于自定义的类型，new 首先调用 operator new() 函数申请空间（底层通过 malloc 实现），然后调用构造函数进行初始化，最后返回自定义类型的指针；delete 首先调用析构函数，然后调用 operator delete() 释放空间（底层通过 free 实现）。malloc、free 无法进行自定义类型的对象的构造和析构。 new 操作符从自由存储区上为对象动态分配内存，而 malloc 函数从堆上动态分配内存。（自由存储区不等于堆） 堆区和自由存储区的区别与联系：（1）malloc申请的内存在堆上，使用free释放。new申请的内存在自由存储区，用delete释放（2）堆（heap）是c语言和操作系统的术语。堆是操作系统所维护的一块特殊内存，它提供了动态分配的功能，当程序运行时调用malloc()时就会从中分配，调用free可把内存交换。而自由存储区是C++中通过new和delete动态分配和释放对象的抽象概念，通过new来申请的内存区域可称为自由存储区。基本上，所有的C++编译器默认用堆来实现自由存储区，也即是缺省的全局运算符new和delete也许会按照malloc和free的方式来实现，这时由new运算符分配的对象，说它在堆上也对，说它在自由存储区也对。记住：（1）堆是c语言和操作系统的术语，是操作系统维护的一块内存。自由存储是C++中通过new和delete动态分配和释放对象的抽象概念。（2）new所申请的内存区域在C++中称为自由存储区，编译器用malloc和free实现new和delete操作符时，new申请的内存可以说是在堆上。（3）堆和自由内存区有相同之处，但并不等价。 1.3.16 malloc 的原理？malloc 的底层实现？malloc() 的原理: 当开辟的空间小于 128K 时，调用 brk() 函数，通过移动 _enddata 来实现； 当开辟空间大于 128K 时，调用 mmap() 函数，通过在虚拟地址空间中开辟一块内存空间来实现。 brk() 函数实现原理：向高地址的方向移动指向数据段的高地址的指针 _enddata。 mmap() 内存映射原理： 进程启动映射过程，并在虚拟地址空间中为映射创建虚拟映射区域； 调用内核空间的系统调用函数 mmap()，实现文件物理地址和进程虚拟地址的一一映射关系； 进程发起对这片映射空间的访问，引发缺页异常，实现文件内容到物理内存（主存）的拷贝。 1.3.17 C 和 C++ struct 的区别？ 在 C 语言中 struct 是用户自定义数据类型；在 C++ 中 struct 是抽象数据类型，支持成员函数的定义。 C 语言中 struct 没有访问权限的设置，是一些变量的集合体，不能定义成员函数；C++ 中 struct 可以和类一样，有访问权限，并可以定义成员函数。 C 语言中 struct 定义的自定义数据类型，在定义该类型的变量时，需要加上 struct 关键字，例如：struct A var;，定义 A 类型的变量；而 C++ 中，不用加该关键字，例如：A var; C++ 是在 C 语言的基础上发展起来的，为了与 C 语言兼容，C++ 中保留了 struct。 1.3.18 struct 和 union 的区别说明：union 是联合体，struct 是结构体。区别： 联合体和结构体都是由若干个数据类型不同的数据成员组成。使用时，联合体只有一个有效的成员；而结构体所有的成员都有效。 对联合体的不同成员赋值，将会对覆盖其他成员的值，而对于结构体的对不同成员赋值时，相互不影响。 联合体的大小为其内部所有变量的最大值，按照最大类型的倍数进行分配大小；结构体分配内存的大小遵循内存对齐原则。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#include &lt;iostream&gt;using namespace std;typedef union{ char c[10]; char cc1; // char 1 字节，按该类型的倍数分配大小} u11;typedef union{ char c[10]; int i; // int 4 字节，按该类型的倍数分配大小} u22;typedef union{ char c[10]; double d; // double 8 字节，按该类型的倍数分配大小} u33;typedef struct s1{ char c; // 1 字节 double d; // 1（char）+ 7（内存对齐）+ 8（double）= 16 字节} s11;typedef struct s2{ char c; // 1 字节 char cc; // 1（char）+ 1（char）= 2 字节 double d; // 2 + 6（内存对齐）+ 8（double）= 16 字节} s22;typedef struct s3{ char c; // 1 字节 double d; // 1（char）+ 7（内存对齐）+ 8（double）= 16 字节 char cc; // 16 + 1（char）+ 7（内存对齐）= 24 字节} s33;int main(){ cout &lt;&lt; sizeof(u11) &lt;&lt; endl; // 10 cout &lt;&lt; sizeof(u22) &lt;&lt; endl; // 12 cout &lt;&lt; sizeof(u33) &lt;&lt; endl; // 16 cout &lt;&lt; sizeof(s11) &lt;&lt; endl; // 16 cout &lt;&lt; sizeof(s22) &lt;&lt; endl; // 16 cout &lt;&lt; sizeof(s33) &lt;&lt; endl; // 24 cout &lt;&lt; sizeof(int) &lt;&lt; endl; // 4 cout &lt;&lt; sizeof(double) &lt;&lt; endl; // 8 return 0;} 1.3.19 class 和 struct 的异同 struct 和 class 都可以自定义数据类型，也支持继承操作。 struct 中默认的访问级别是 public，默认的继承级别也是 public；class 中默认的访问级别是 private，默认的继承级别也是 private。 当 class 继承 struct 或者 struct 继承 class 时，默认的继承级别取决于 class 或 struct 本身， class（private 继承），struct（public 继承），即取决于派生类的默认继承级别。 class 可以用于定义模板参数，struct 不能用于定义模板参数。 1234567891011121314151617181920212223242526272829303132333435363738struct A{}；class B : A{}; // private 继承 struct C : B{}； // public 继承 #include&lt;iostream&gt;using namespace std;class A{public: void funA(){ cout &lt;&lt; &quot;class A&quot; &lt;&lt; endl; }};struct B: A{ // 由于 B 是 struct，A 的默认继承级别为 publicpublic: void funB(){ cout &lt;&lt; &quot;class B&quot; &lt;&lt; endl; }};class C: B{ // 由于 C 是 class，B 的默认继承级别为 private，所以无法访问基类 B 中的 printB 函数};int main(){ A ex1; ex1.funA(); // class A B ex2; ex2.funA(); // class A ex2.funB(); // class B C ex3; ex3.funB(); // error: 'B' is not an accessible base of 'C'. return 0;} 1.3.20 volatile 的作用？是否具有原子性，对编译器有什么影响？ volatile 的作用：当对象的值可能在程序的控制或检测之外被改变时，应该将该对象声明为 volatile，告知编译器不应对这样的对象进行优化。 volatile不具有原子性。 volatile 对编译器的影响：使用该关键字后，编译器不会对相应的对象进行优化，即不会将变量从内存缓存到寄存器中，防止多个线程有可能使用内存中的变量，有可能使用寄存器中的变量，从而导致程序错误。 1.3.21 什么情况下一定要用 volatile， 能否和 const 一起使用？使用 volatile 关键字的场景： 当多个线程都会用到某一变量，并且该变量的值有可能发生改变时，需要用 volatile 关键字对该变量进行修饰； 中断服务程序中访问的变量或并行设备的硬件寄存器的变量，最好用 volatile 关键字修饰。 volatile 关键字和 const 关键字可以同时使用，某种类型可以既是 volatile 又是 const ，同时具有二者的属性。 1.3.22 extern C 的作用？当 C++ 程序 需要调用 C 语言编写的函数，C++ 使用链接指示，即 extern &quot;C&quot; 指出任意非 C++ 函数所用的语言。 C++ 和 C语言编译函数签名方式不一样， extern关键字可以让两者保持统一，这样才能找到对应的函数.。 1234// 可能出现在 C++ 头文件&lt;cstring&gt;中的链接指示extern &quot;C&quot;{ int strcmp(const char*, const char*);} 1.3.23 sizeof(1==1) 在 C 和 C++ 中分别是什么结果？C语言sizeof（1 == 1） === sizeof（1）按照整数处理，所以是4字节，这里也有可能是8字节（看操作系统）C++因为有bool 类型sizeof（1 == 1） == sizeof（true） 按照bool类型处理，所以是1个字节 1.3.24 ★ memcpy和memmove 函数的底层原理？123456789101112131415161718192021222324252627282930313233343536// 不保证拷贝正确性void *memcpy (void *dest, const void *src, size_t len){ char *d = dest; char *s = src; if(d == s) return; while (len--){ *d++ = *s++; } return dest;}// 保证拷贝正确性void *memmove (void *dest, const void *src, size_t len){ char *d = dest; char *s = src; if(d == s) return; if (d &lt; s){ while (len--){ *d++ = *s++; } } else{// 从后往前拷贝 char *lasts = s + (len-1); char *lastd = d + (len-1); while (len--){ *lastd-- = *lasts--; } } return dest;} 1.3.25 strcpy 函数有什么缺陷？strcpy 函数的缺陷：strcpy 函数不检查目的缓冲区的大小边界，而是将源字符串逐一的全部赋值给目的字符串地址起始的一块连续的内存空间，同时加上字符串终止符，会导致其他变量被覆盖。 12345678910111213141516171819202122#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;int main(){ int var = 0x11112222; char arr[10]; cout &lt;&lt; &quot;Address : var &quot; &lt;&lt; &amp;var &lt;&lt; endl; cout &lt;&lt; &quot;Address : arr &quot; &lt;&lt; &amp;arr &lt;&lt; endl; strcpy(arr, &quot;hello world!&quot;); cout &lt;&lt; &quot;var:&quot; &lt;&lt; hex &lt;&lt; var &lt;&lt; endl; // 将变量 var 以 16 进制输出 cout &lt;&lt; &quot;arr:&quot; &lt;&lt; arr &lt;&lt; endl; return 0;}/*Address : var 0x23fe4cAddress : arr 0x23fe42var:11002164arr:hello world!*/ 说明：从上述代码中可以看出，变量 var 的后六位被字符串 “hello world!” 的 “d!\\0” 这三个字符改变，这三个字符对应的 ascii 码的十六进制为：\\0(0x00)，!(0x21)，d(0x64)。原因：变量 arr 只分配的 10 个内存空间，通过上述程序中的地址可以看出 arr 和 var 在内存中是连续存放的，但是在调用 strcpy 函数进行拷贝时，源字符串 “hello world!” 所占的内存空间为 13，因此在拷贝的过程中会占用 var 的内存空间，导致 var的后六位被覆盖。 1.3.26 auto 类型推导的原理编译器根据初始值来推算变量的类型，要求用 auto 定义变量时必须有初始值。编译器推断出来的 auto 类型有时和初始值类型并不完全一样，编译器会适当改变结果类型使其更符合初始化规则。 1.4 面向对象1.4.1 什么是面向对象？面向对象的三大特性面向对象：对象是指具体的某一个事物，这些事物的抽象就是类，类中包含数据（成员变量）和动作（成员方法）。 面向对象的三大特性： 封装：将具体的实现过程和数据封装成一个函数，只能通过接口进行访问，降低耦合性。 继承：子类继承父类的特征和行为，子类有父类的非 private 方法或成员变量，子类可以对父类的方法进行重写，增强了类之间的耦合性，但是当父类中的成员变量、成员函数或者类本身被 final 关键字修饰时，修饰的类不能继承，修饰的成员不能重写或修改。 多态：多态就是不同继承类的对象，对同一消息做出不同的响应，基类的指针指向或绑定到派生类的对象，使得基类指针呈现不同的表现方式。 1.4.2 重载、重写、隐藏的区别重载：是指同一可访问区内被声明几个具有不同参数列（参数的类型、个数、顺序）的同名函数，根据参数列表确定调用哪个函数，重载不关心函数返回类型。 123456789class A{public: void fun(int tmp); void fun(float tmp); // 重载 参数类型不同（相对于上一个函数） void fun(int tmp, float tmp1); // 重载 参数个数不同（相对于上一个函数） void fun(float tmp, int tmp1); // 重载 参数顺序不同（相对于上一个函数） int fun(int tmp); // error: 'int A::fun(int)' cannot be overloaded 错误：注意重载不关心函数返回类型}; 重写(覆盖)：是指派生类中存在重新定义的函数。函数名、参数列表、返回值类型都必须同基类中被重写的函数一致，只有函数体不同。派生类调用时会调用派生类的重写函数，不会调用被重写函数。重写的基类中被重写的函数必须有 virtual 修饰。 1234567891011121314151617181920#include &lt;iostream&gt;using namespace std;class Base{public: virtual void fun(int tmp) { cout &lt;&lt; &quot;Base::fun(int tmp) : &quot; &lt;&lt; tmp &lt;&lt; endl; }};class Derived : public Base{public: virtual void fun(int tmp) { cout &lt;&lt; &quot;Derived::fun(int tmp) : &quot; &lt;&lt; tmp &lt;&lt; endl; } // 重写基类中的 fun 函数};int main(){ Base *p = new Derived(); p-&gt;fun(3); // Derived::fun(int) : 3 return 0;} 隐藏：是指派生类的函数屏蔽了与其同名的基类函数，主要只要同名函数，不管参数列表是否相同，基类函数都会被隐藏。 12345678910111213141516171819202122#include &lt;iostream&gt;using namespace std;class Base{public: void fun(int tmp, float tmp1) { cout &lt;&lt; &quot;Base::fun(int tmp, float tmp1)&quot; &lt;&lt; endl; }};class Derive : public Base{public: void fun(int tmp) { cout &lt;&lt; &quot;Derive::fun(int tmp)&quot; &lt;&lt; endl; } // 隐藏基类中的同名函数};int main(){ Derive ex; ex.fun(1); // Derive::fun(int tmp) ex.fun(1, 0.01); // error: candidate expects 1 argument, 2 provided return 0;} 说明：上述代码中 ex.fun(1, 0.01); 出现错误，说明派生类中将基类的同名函数隐藏了。若是想调用基类中的同名函数，可以加上类型名指明 ex.Base::fun(1, 0.01);，这样就可以调用基类中的同名函数。 重写和重载的区别： 范围区别：对于类中函数的重载或者重写而言，重载发生在同一个类的内部，重写发生在不同的类之间（子类和父类之间）。 参数区别：重载的函数需要与原函数有相同的函数名、不同的参数列表，不关注函数的返回值类型；重写的函数的函数名、参数列表和返回值类型都需要和原函数相同，父类中被重写的函数需要有 virtual 修饰。virtual 关键字：重写的函数基类中必须有 virtual关键字的修饰，重载的函数可以有 virtual 关键字的修饰也可以没有。 隐藏和重写，重载的区别： 范围区别：隐藏与重载范围不同，隐藏发生在不同类中。 参数区别：隐藏函数和被隐藏函数参数列表可以相同，也可以不同，但函数名一定相同；当参数不同时，无论基类中的函数是否被 virtual 修饰，基类函数都是被隐藏，而不是重写。 1.4.3 什么是多态？多态如何实现？多态：多态就是不同继承类的对象，对同一消息做出不同的响应，基类的指针指向或绑定到派生类的对象，使得基类指针呈现不同的表现方式。在基类的函数前加上 virtual 关键字，在派生类中重写该函数，运行时将会根据对象的实际类型来调用相应的函数。如果对象类型是派生类，就调用派生类的函数；如果对象类型是基类，就调用基类的函数。实现方法：多态是通过虚函数实现的，虚函数的地址保存在虚函数表中，虚函数表的地址保存在含有虚函数的类的实例对象的内存空间中。 实现过程： 在类中用 virtual 关键字声明的函数叫做虚函数； 存在虚函数的类都有一个虚函数表，当创建一个该类的对象时，该对象有一个指向虚函数表的虚表指针（虚函数表和类对应的，虚表指针是和对象对应）； 当基类指针指向派生类对象，基类指针调用虚函数时，基类指针指向派生类的虚表指针，由于该虚表指针指向派生类虚函数表，通过遍历虚表，寻找相应的虚函数。 当基类的指针指向派生类的对象时，通过派生类的对象的虚表指针找到虚函数表（派生类的对象虚函数表），进而找到相应的虚函数 Derive::f() 进行调用。 123456789101112131415161718192021222324252627#include &lt;iostream&gt;using namespace std;class Base{public: virtual void fun() { cout &lt;&lt; &quot;Base::fun()&quot; &lt;&lt; endl; } virtual void fun1() { cout &lt;&lt; &quot;Base::fun1()&quot; &lt;&lt; endl; } virtual void fun2() { cout &lt;&lt; &quot;Base::fun2()&quot; &lt;&lt; endl; }};class Derive : public Base{public: void fun() { cout &lt;&lt; &quot;Derive::fun()&quot; &lt;&lt; endl; } virtual void D_fun1() { cout &lt;&lt; &quot;Derive::D_fun1()&quot; &lt;&lt; endl; } virtual void D_fun2() { cout &lt;&lt; &quot;Derive::D_fun2()&quot; &lt;&lt; endl; }};int main(){ Base *p = new Derive(); p-&gt;fun(); // Derive::fun() 调用派生类中的虚函数 return 0;} 1.4.4 什么是虚函数？什么是纯虚函数？两者有何区别虚函数：被 virtual 关键字修饰的成员函数，就是虚函数。 12345678910111213141516171819202122232425#include &lt;iostream&gt;using namespace std;class A{public: virtual void v_fun() // 虚函数 { cout &lt;&lt; &quot;A::v_fun()&quot; &lt;&lt; endl; }};class B : public A{public: void v_fun() { cout &lt;&lt; &quot;B::v_fun()&quot; &lt;&lt; endl; }};int main(){ A *p = new B(); p-&gt;v_fun(); // B::v_fun() return 0;} 纯虚函数： 纯虚函数在类中声明时，加上 =0； 含有纯虚函数的类称为抽象类（只要含有纯虚函数这个类就是抽象类），类中只有接口，没有具体的实现方法； 继承纯虚函数的派生类，如果没有完全实现基类纯虚函数，依然是抽象类，不能实例化对象。 说明： 抽象类对象不能作为函数的参数，不能创建对象，不能作为函数返回类型； 可以声明抽象类指针，可以声明抽象类的引用； 子类必须继承父类的纯虚函数，并全部实现后，才能创建子类的对象。 区别： 虚函数和纯虚函数可以出现在同一个类中，该类称为抽象基类。（含有纯虚函数的类称为抽象基类） 使用方式不同：虚函数可以直接使用，纯虚函数必须在派生类中实现后才能使用； 定义形式不同：虚函数在定义时在普通函数的基础上加上 virtual 关键字，纯虚函数定义时除了加上virtual 关键字还需要加上 =0; 虚函数必须实现，否则编译器会报错； 对于实现纯虚函数的派生类，该纯虚函数在派生类中被称为虚函数，虚函数和纯虚函数都可以在派生类中重写； 析构函数最好定义为虚函数，特别是对于含有继承关系的类；析构函数可以定义为纯虚函数，此时，其所在的类为抽象基类，不能创建实例化对象。 1.4.5 虚函数的实现机制实现机制：虚函数通过虚函数表来实现。虚函数的地址保存在虚函数表中，在类的对象所在的内存空间中，保存了指向虚函数表的指针（称为“虚表指针”），通过虚表指针可以找到类对应的虚函数表。虚函数表解决了基类和派生类的继承问题和类中成员函数的覆盖问题，当用基类的指针来操作一个派生类的时候，这张虚函数表就指明了实际应该调用的函数。 虚函数表相关知识点： 虚函数表存放的内容：类的虚函数的地址。 虚函数表建立的时间：编译阶段，即程序的编译过程中会将虚函数的地址放在虚函数表中。 虚表指针保存的位置：虚表指针存放在对象的内存空间中最前面的位置，这是为了保证正确取到虚函数的偏移量。 注：虚函数表和类绑定，虚表指针和对象绑定。即类的不同的对象的虚函数表是一样的，但是每个对象都有自己的虚表指针，来指向类的虚函数表。 ★编译器处理虚函数表： 编译器将虚函数表的指针放在类的实例对象的内存空间中，该对象调用该类的虚函数时，通过指针找到虚函数表，根据虚函数表中存放的虚函数的地址找到对应的虚函数。 如果派生类没有重新定义基类的虚函数 A，则派生类的虚函数表中保存的是基类的虚函数 A 的地址，也就是说基类和派生类的虚函数 A 的地址是一样的。 如果派生类重写了基类的某个虚函数 B，则派生的虚函数表中保存的是重写后的虚函数 B 的地址，也就是说虚函数 B 有两个版本，分别存放在基类和派生类的虚函数表中。 如果派生类重新定义了新的虚函数 C，派生类的虚函数表保存新的虚函数 C 的地址。 1.4.6 单继承的虚函数表（无虚函数覆盖）基类和派生类的继承关系： 基类的虚函数表： 派生类的虚函数表： 1.4.7 单继承的虚函数表（有虚函数覆盖）派生类的虚函数表： 1.4.8 多继承的虚函数表（无虚函数覆盖）基类和派生类的继承关系： 派生类的虚函数表： 1.4.9 多继承的虚函数表（有虚函数覆盖）基类和派生类的继承关系： 派生类的虚函数表： 1.4.10 构造函数、析构函数是否需要定义成虚函数？为什么？构造函数一般不定义为虚函数，原因： 从存储空间的角度考虑：构造函数是在实例化对象的时候进行调用，如果此时将构造函数定义成虚函数，需要通过访问该对象所在的内存空间才能进行虚函数的调用（因为需要通过指向虚函数表的指针调用虚函数表，虽然虚函数表在编译时就有了，但是没有虚函数的指针，虚函数的指针只有在创建了对象才有），但是此时该对象还未创建，便无法进行虚函数的调用。所以构造函数不能定义成虚函数。 从使用的角度考虑：虚函数是基类的指针指向派生类的对象时，通过该指针实现对派生类的虚函数的调用，构造函数是在创建对象时自动调用的。 从实现上考虑：虚函数表是在创建对象之后才有的，因此不能定义成虚函数。 从类型上考虑：在创建对象时需要明确其类型。 析构函数一般定义成虚函数，原因：析构函数定义成虚函数是为了防止内存泄漏，因为当基类的指针或者引用指向或绑定到派生类的对象时，如果未将基类的析构函数定义成虚函数，会调用基类的析构函数，那么只能将基类的成员所占的空间释放掉，派生类中特有的就会无法释放内存空间导致内存泄漏。 1.4.11 如何避免拷贝？最直观的想法是：将类的拷贝构造函数和赋值构造函数声明为私有 private，但对于类的成员函数和友元函数依然可以调用，达不到完全禁止类的对象被拷贝的目的，而且程序会出现错误，因为未对函数进行定义。 解决方法：声明一个基类，具体做法如下。 定义一个基类，将其中的拷贝构造函数和赋值构造函数声明为私有 private 派生类以私有 private 的方式继承基类 12345678910111213class Uncopyable{public: Uncopyable() {} ~Uncopyable() {}private: Uncopyable(const Uncopyable &amp;); // 拷贝构造函数 Uncopyable &amp;operator=(const Uncopyable &amp;); // 赋值构造函数};class A : private Uncopyable // 注意继承方式{ }; 简单解释： 能够保证，在派生类 A 的成员函数和友元函数中无法进行拷贝操作，因为无法调用基类 Uncopyable 的拷贝构造函数或赋值构造函数。同样，在类的外部也无法进行拷贝操作。 1.4.12 为什么用成员初始化列表会快一些？/如何减少构造函数开销？说明：数据类型可分为内置类型和用户自定义类型（类类型），对于用户自定义类型，利用成员初始化列表效率高。 原因：用户自定义类型如果使用类初始化列表，直接调用该成员变量对应的构造函数即完成初始化；如果在构造函数中初始化，因为 C++ 规定，对象的成员变量的初始化动作发生在进入构造函数本体之前，那么在执行构造函数的函数体之前首先调用默认的构造函数为成员变量设初值，在进入函数体之后，调用该成员变量对应的构造函数。因此，使用列表初始化会减少调用默认的构造函数的过程，效率高。**(使用构造函数初始化成员变量：产生临时对象；成员初始化列表：不产生临时对象)** 1.4.13 简述C++的类访问控制private, public, protected 访问标号的访问范围： private：只能由1.该类中的函数、2.其友元函数访问。不能被任何其他访问，该类的对象也不能访问。 protected：可以被1.该类中的函数、2.子类的函数、以及3.其友元函数访问。但不能被该类的对象访问。 public：可以被1.该类中的函数、2.子类的函数、3.其友元函数访问，也可以由 4.该类的对象访问。 注：友元函数包括3种：设为友元的普通的非成员函数；设为友元的其他类的成员函数；设为友元类中的所有成员函数。 类的继承后方法属性变化： 1.4.14 多重继承时会出现什么状况？如何解决？命名冲突和数据冗余问题。 123456789101112131415161718192021222324252627282930313233343536373839404142#include &lt;iostream&gt;using namespace std;// 间接基类class Base1{public: int var1;};// 直接基类class Base2 : public Base1{public: int var2;};// 直接基类class Base3 : public Base1{public: int var3;};// 派生类class Derive : public Base2, public Base3{public: void set_var1(int tmp) { var1 = tmp; } // error: reference to 'var1' is ambiguous. 命名冲突 void set_var2(int tmp) { var2 = tmp; } void set_var3(int tmp) { var3 = tmp; } void set_var4(int tmp) { var4 = tmp; }private: int var4;};int main(){ Derive d; return 0;} 上述程序的继承关系如下：（菱形继承） 上述代码中存的问题：对于派生类 Derive 上述代码中存在直接继承关系和间接继承关系。 直接继承：Base2 、Base3 间接继承：Base1 对于派生类中继承的的成员变量 var1 ，从继承关系来看，实际上保存了两份，一份是来自基类 Base2，一份来自基类 Base3。因此，出现了命名冲突。 解决方法 1： 声明出现冲突的成员变量来源于哪个类 123456789101112131415161718192021222324252627282930313233343536373839404142#include &lt;iostream&gt;using namespace std;// 间接基类class Base1{public: int var1;};// 直接基类class Base2 : public Base1{public: int var2;};// 直接基类class Base3 : public Base1{public: int var3;};// 派生类 class Derive : public Base2, public Base3{public: void set_var1(int tmp) { Base2::var1 = tmp; } // 这里声明成员变量来源于类 Base2，当然也可以声明来源于类 Base3 void set_var2(int tmp) { var2 = tmp; } void set_var3(int tmp) { var3 = tmp; } void set_var4(int tmp) { var4 = tmp; }private: int var4;};int main(){ Derive d; return 0;} 解决方法 2： 虚继承 使用虚继承的目的：保证存在命名冲突的成员变量在派生类中只保留一份，即使间接基类中的成员在派生类中只保留一份。在菱形继承关系中，间接基类称为虚基类，直接基类和间接基类之间的继承关系称为虚继承。 实现方式：在继承方式前面加上 virtual 关键字。 123456789101112131415161718192021222324252627282930313233343536373839404142#include &lt;iostream&gt;using namespace std;// 间接基类，即虚基类class Base1{public: int var1;};// 直接基类 class Base2 : virtual public Base1 // 虚继承{public: int var2;};// 直接基类 class Base3 : virtual public Base1 // 虚继承{public: int var3;};// 派生类class Derive : public Base2, public Base3{public: void set_var1(int tmp) { var1 = tmp; } void set_var2(int tmp) { var2 = tmp; } void set_var3(int tmp) { var3 = tmp; } void set_var4(int tmp) { var4 = tmp; }private: int var4;};int main(){ Derive d; return 0;} 类之间的继承关系： 1.4.15 空类占多少字节？C++ 编译器会给一个空类自动生成哪些函数？空类声明时编译器不会生成任何成员函数： 对于空类，声明编译器不会生成任何的成员函数，只会生成 1 个字节的占位符。 123456789101112#include &lt;iostream&gt;using namespace std;class A{};int main(){ cout &lt;&lt; &quot;sizeof(A):&quot; &lt;&lt; sizeof(A) &lt;&lt; endl; // sizeof(A):1 return 0;} 空类定义时编译器会生成 6 个成员函数： 当空类 A 定义对象时，sizeof(A) 仍是为 1，但编译器会生成 6 个成员函数：缺省的构造函数、拷贝构造函数、析构函数、赋值运算符、两个取址运算符。 123456789101112131415161718192021222324#include &lt;iostream&gt;using namespace std;/*class A{}; 该空类的等价写法如下：*/class A{public: A(){}; // 缺省构造函数 A(const A &amp;tmp){}; // 拷贝构造函数 ~A(){}; // 析构函数 A &amp;operator=(const A &amp;tmp){}; // 赋值运算符 A *operator&amp;() { return this; }; // 取址运算符 const A *operator&amp;() const { return this; }; // 取址运算符（const 版本）};int main(){ A *p = new A(); cout &lt;&lt; &quot;sizeof(A):&quot; &lt;&lt; sizeof(A) &lt;&lt; endl; // sizeof(A):1 delete p; return 0;} 1.4.16 为什么拷贝构造函数必须为引用？原因：避免拷贝构造函数无限制的递归，最终导致栈溢出。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#include &lt;iostream&gt;using namespace std;class A{private: int val;public: A(int tmp) : val(tmp) // 带参数构造函数 { cout &lt;&lt; &quot;A(int tmp)&quot; &lt;&lt; endl; } A(const A &amp;tmp) // 拷贝构造函数 { cout &lt;&lt; &quot;A(const A &amp;tmp)&quot; &lt;&lt; endl; val = tmp.val; } A &amp;operator=(const A &amp;tmp) // 赋值函数（赋值运算符重载） { cout &lt;&lt; &quot;A &amp;operator=(const A &amp;tmp)&quot; &lt;&lt; endl; val = tmp.val; return *this; } void fun(A tmp) { }};int main(){ A ex1(1); A ex2(2); A ex3 = ex1; ex2 = ex1; ex2.fun(ex1); return 0;}/*运行结果：A(int tmp)A(int tmp)A(const A &amp;tmp)A &amp;operator=(const A &amp;tmp)A(const A &amp;tmp)*/ 说明 1：ex2 = ex1; 和 A ex3 = ex1; 为什么调用的函数不一样？对象 ex2 已经实例化了，不需要构造，此时只是将 ex1 赋值给 ex2，只会调用赋值函数；但是 ex3 还没有实例化，因此调用的是拷贝构造函数，构造出 ex3，而不是赋值函数，这里涉及到构造函数的隐式调用。 说明 2：如果拷贝构造函数中形参不是引用类型，A ex3 = ex1;会出现什么问题？构造 ex3，实质上是 ex3.A(ex1);，假如拷贝构造函数参数不是引用类型，那么将使得 ex3.A(ex1); 相当于 ex1 作为函数 A(const A tmp)的形参，在参数传递时相当于 A tmp = ex1，因为 tmp 没有被初始化，所以在 A tmp = ex1 中继续调用拷贝构造函数，接下来的是构造 tmp，也就是 tmp.A(ex1) ，必然又会有 ex1 作为函数 A(const A tmp); 的形参，在参数传递时相当于即 A tmp = ex1，那么又会触发拷贝构造函数，就这下永远的递归下去。 说明 3：为什么 ex2.fun(ex1); 会调用拷贝构造函数？ex1 作为参数传递给 fun 函数， 即 A tmp = ex1;，这个过程会调用拷贝构造函数进行初始化。(临时对象) 1.4.17 C++ 类对象的初始化顺序构造函数调用顺序： 按照派生类继承基类的顺序，即派生列表中声明的顺序，依次调用基类的构造函数； 按照派生类中成员变量的声名顺序，依次调用派生类中成员变量所属类的构造函数； 执行派生类自身的构造函数。 综上可以得出，类对象的初始化顺序：基类构造函数–&gt;派生类成员变量的构造函数–&gt;自身构造函数注： 基类构造函数的调用顺序与派生类的派生列表中的顺序有关； 成员变量的初始化顺序与声明顺序有关； 析构顺序和构造顺序相反。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;iostream&gt;using namespace std;class A{public: A() { cout &lt;&lt; &quot;A()&quot; &lt;&lt; endl; } ~A() { cout &lt;&lt; &quot;~A()&quot; &lt;&lt; endl; }};class B{public: B() { cout &lt;&lt; &quot;B()&quot; &lt;&lt; endl; } ~B() { cout &lt;&lt; &quot;~B()&quot; &lt;&lt; endl; }};class Test : public A, public B // 派生列表{public: Test() { cout &lt;&lt; &quot;Test()&quot; &lt;&lt; endl; } ~Test() { cout &lt;&lt; &quot;~Test()&quot; &lt;&lt; endl; }private: B ex1; A ex2;};int main(){ Test ex; return 0;}/*运行结果：A()B()B()A()Test()~Test()~A()~B()~B()~A()*/ 程序运行结果分析： 首先调用基类 A 和 B 的构造函数，按照派生列表 public A, public B 的顺序构造； 然后调用派生类 Test 的成员变量 ex1 和 ex2 的构造函数，按照派生类中成员变量声明的顺序构造； 最后调用派生类的构造函数； 接下来调用析构函数，和构造函数调用的顺序相反。 1.4.18 如何禁止一个类被实例化？方法一： 在类中定义一个纯虚函数，使该类成为抽象基类，因为不能创建抽象基类的实例化对象； 方法二： 将类的构造函数声明为私有 private 1.4.19 实例化一个对象需要哪几个阶段 分配空间创建类对象首先要为该对象分配内存空间。不同的对象，为其分配空间的时机未必相同。全局对象、静态对象、分配在栈区域内的对象，在编译阶段进行内存分配；存储在堆空间的对象，是在运行阶段进行内存分配。 初始化首先明确一点：初始化不同于赋值。初始化发生在赋值之前，初始化随对象的创建而进行，而赋值是在对象创建好后，为其赋上相应的值。这一点可以联想下上一个问题中提到：初始化列表先于构造函数体内的代码执行，初始化列表执行的是数据成员的初始化过程，这个可以从成员对象的构造函数被调用看的出来。 赋值对象初始化完成后，可以对其进行赋值。对于一个类的对象，其成员变量的赋值过程发生在类的构造函数的函数体中。当执行完该函数体，也就意味着类对象的实例化过程完成了。（总结：构造函数实现了对象的初始化和赋值两个过程，对象的初始化是通过初始化列表来完成，而对象的赋值则才是通过构造函数的函数体来实现。） 注：对于拥有虚函数的类的对象，还需要给虚表指针赋值。 没有继承关系的类，分配完内存后，首先给虚表指针赋值，然后再列表初始化以及执行构造函数的函数体，即上述中的初始化和赋值操作。 有继承关系的类，分配内存之后，首先进行基类的构造过程，然后给该派生类的虚表指针赋值，最后再列表初始化以及执行构造函数的函数体，即上述中的初始化和赋值操作。 1.4.20 友元函数的作用及使用场景作用：友元提供了不同类的成员函数之间、类的成员函数与一般函数之间进行数据共享的机制。通过友元，一个不同函数或另一个类中的成员函数可以访问类中的私有成员和保护成员。 使用场景： 普通函数定义为友元函数，使普通函数能够访问类的私有成员。 1234567891011121314151617181920212223242526272829#include &lt;iostream&gt;using namespace std;class A{ friend ostream &amp;operator&lt;&lt;(ostream &amp;_cout, const A &amp;tmp); // 声明为类的友元函数public: A(int tmp) : var(tmp) { }private: int var;};ostream &amp;operator&lt;&lt;(ostream &amp;_cout, const A &amp;tmp){ _cout &lt;&lt; tmp.var; return _cout;}int main(){ A ex(4); cout &lt;&lt; ex &lt;&lt; endl; // 4 return 0;} 友元类：类之间共享数据。 123456789101112131415161718192021222324252627282930313233343536373839#include &lt;iostream&gt;using namespace std;class A{ friend class B;public: A() : var(10){} A(int tmp) : var(tmp) {} void fun() { cout &lt;&lt; &quot;fun():&quot; &lt;&lt; var &lt;&lt; endl; }private: int var;};class B{public: B() {} void fun() { cout &lt;&lt; &quot;fun():&quot; &lt;&lt; ex.var &lt;&lt; endl; // 访问类 A 中的私有成员 }private: A ex;};int main(){ B ex; ex.fun(); // fun():10 return 0;} 1.4.21 静态绑定和动态绑定是怎么实现的？静态类型和动态类型： 静态类型：变量在声明时的类型，是在编译阶段确定的。静态类型不能更改。 动态类型：目前所指对象的类型，是在运行阶段确定的。动态类型可以更改。 静态绑定和动态绑定： 静态绑定是指程序在 编译阶段 确定对象的类型（静态类型）。 动态绑定是指程序在 运行阶段 确定对象的类型（动态类型）。 静态绑定和动态绑定的区别： 发生的时期不同：如上。 对象的静态类型不能更改，动态类型可以更改。 注：对于类的成员函数，只有虚函数是动态绑定，其他都是静态绑定。 12345678910111213141516171819202122232425262728#include &lt;iostream&gt;using namespace std;class Base{public: virtual void fun() { cout &lt;&lt; &quot;Base::fun()&quot; &lt;&lt; endl; }};class Derive : public Base{public: void fun() { cout &lt;&lt; &quot;Derive::fun()&quot;; }};int main(){ Base *p = new Derive(); // p 的静态类型是 Base*，动态类型是 Derive* p-&gt;fun(); // fun 是虚函数，运行阶段进行动态绑定 return 0;}/*运行结果：Derive::fun()*/ 1.4.22 深拷贝和浅拷贝的区别如果一个类拥有资源，该类的对象进行复制时，如果资源重新分配，就是深拷贝，否则就是浅拷贝。 深拷贝：该对象和原对象占用不同的内存空间，既拷贝存储在栈空间中的内容，又拷贝存储在堆空间中的内容。 浅拷贝：该对象和原对象占用同一块内存空间，仅拷贝类中位于栈空间中的内容。 当类的成员变量中有指针变量时，最好使用深拷贝。因为当两个对象指向同一块内存空间，如果使用浅拷贝，当其中一个对象的删除后，该块内存空间就会被释放，另外一个对象指向的就是垃圾内存。 浅拷贝实例 123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;using namespace std;class Test{private: int *p;public: Test(int tmp) { this-&gt;p = new int(tmp); cout &lt;&lt; &quot;Test(int tmp)&quot; &lt;&lt; endl; } ~Test() { if (p != NULL) { delete p; } cout &lt;&lt; &quot;~Test()&quot; &lt;&lt; endl; }};int main(){ Test ex1(10); Test ex2 = ex1; return 0;}/*运行结果：Test(int tmp)~Test()*/ 说明：上述代码中，类对象 ex1、ex2 实际上是指向同一块内存空间，对象析构时，ex2 先将内存释放了一次，之后 析构对象 ex1 时又将这块已经被释放过的内存再释放一次。对同一块内存空间释放了两次，会导致程序崩溃。 深拷贝实例： 12345678910111213141516171819202122232425262728293031323334353637383940414243#include &lt;iostream&gt;using namespace std;class Test{private: int *p;public: Test(int tmp) { p = new int(tmp); cout &lt;&lt; &quot;Test(int tmp)&quot; &lt;&lt; endl; } ~Test() { if (p != NULL) { delete p; } cout &lt;&lt; &quot;~Test()&quot; &lt;&lt; endl; } Test(const Test &amp;tmp) // 定义拷贝构造函数 { p = new int(*tmp.p); cout &lt;&lt; &quot;Test(const Test &amp;tmp)&quot; &lt;&lt; endl; }};int main(){ Test ex1(10); Test ex2 = ex1; return 0;}/*Test(int tmp)Test(const Test &amp;tmp)~Test()~Test()*/ 1.4.23 编译时多态和运行时多态的区别编译时多态：在程序编译过程中出现，发生在模板和函数重载中（泛型编程）。运行时多态：在程序运行过程中出现，发生在继承体系中，是指通过基类的指针或引用访问派生类中的虚函数。 编译时多态和运行时多态的区别： 时期不同：编译时多态发生在程序编译过程中，运行时多态发生在程序的运行过程中； 实现方式不同：编译时多态运用泛型编程来实现，运行时多态借助虚函数来实现。 1.4.24 实现一个类成员函数，要求不允许修改类的成员变量？如果想达到一个类的成员函数不能修改类的成员变量，只需用 const 关键字来修饰该函数即可。该问题本质是考察 const 关键字修饰成员函数的作用，只不过以实例的方式来考察，面试者应熟练掌握 const 关键字的作用。 123456789101112131415161718192021222324#include &lt;iostream&gt;using namespace std;class A{public: int var1, var2; A() { var1 = 10; var2 = 20; } void fun() const // 不能在 const 修饰的成员函数中修改成员变量的值，除非该成员变量用 mutable 修饰 { var1 = 100; // error: assignment of member 'A::var1' in read-only object }};int main(){ A ex1; return 0;} 1.4.25 如何让类不能被继承？解决方法一：借助 final 关键字，用该关键字修饰的类不能被继承。 1234567891011121314151617#include &lt;iostream&gt;using namespace std;class Base final{};class Derive: public Base{ // error: cannot derive from 'final' base 'Base' in derived type 'Derive'};int main(){ Derive ex; return 0;} 解决方法二：借助友元、虚继承和私有构造函数来实现 123456789101112131415161718192021222324252627282930#include &lt;iostream&gt;using namespace std;template &lt;typename T&gt;class Base{ friend T;private: Base(){ cout &lt;&lt; &quot;base&quot; &lt;&lt; endl; } ~Base(){}};class B:virtual public Base&lt;B&gt;{ //一定注意 必须是虚继承public: B(){ cout &lt;&lt; &quot;B&quot; &lt;&lt; endl; }};class C:public B{public: C(){} // error: 'Base&lt;T&gt;::Base() [with T = B]' is private within this context};int main(){ B b; return 0;} 说明：在上述代码中 B 类是不能被继承的类。 具体原因： 虽然 Base 类构造函数和析构函数被声明为私有 private，在 B 类中，由于 B 是 Base 的友元，因此可以访问 Base 类构造函数，从而正常创建 B 类的对象； B 类继承 Base 类采用虚继承的方式，创建 C 类的对象时，C 类的构造函数要负责 Base 类的构造，但是 Base 类的构造函数私有化了，C 类没有权限访问。因此，无法创建 C 类的对象， B 类是不能被继承的类。 注意：在继承体系中，友元关系不能被继承，虽然 C 类继承了 B 类，B 类是 Base 类的友元，但是 C 类和 Base 类没有友元关系。 2 STL2.1 基础2.1.1 什么是STL标准模板库，增强代码复用性，降低数据结构与算法的耦合关系（容器和算法的分离），提升各自的独立性、弹性和交互性，依据泛型编程的思维架构。 2.1.2 简述STL的六大组件及功能 空间配置器(allocator)：负责STL相关数据结构的空间配置与管理。本质是一个实现了动态空间配置、空间管理、空间释放的class template，STL容器、迭代器的模板参数中都含有它。 迭代器(iterator)：在不暴露容器内部数据结构的情况下，提供遍历容器内元素的方法，是容器和算法的胶合剂，所谓的泛型指针。本质上是一种将operator*、operator-&gt;、operator++、operator–等指针操作重载的class template。所有STL容器都附带专属的迭代器。原生指针是偏特化的迭代器。 容器(container)：存放数据的数据结构。本质上是一种class template。 算法(algorithm)：本质是是一种function template。 仿函数/函数对象(functor)：函数对象，本质上是一种重载了operator()的class或class template。函数指针可视为狭义的仿函数。 配接器(adapter)：修改已经存在的接口令其展现新的风貌，也是一种设计模式，可以修饰容器、仿函数或迭代器的接口。 2.2 空间配置器2.2.1 容器如何获取空间配置器每一个容器都已经指定其缺省的空间配置器为alloc： 12template&lt;class T, class Alloc = alloc&gt;class vector{...}; 2.2.2 空间配置器如何进行构造和析构操作construct()和destroy()被设计为全局函数。 construct()接收指针和初值，将初值设定到指针所指的空间上（调用对象的构造函数）。 destroy()先萃取迭代器所指对象的型别，判断该对象是否具有trivial-destructor，如果是则什么也不做；否则调用对象的析构函数。 2.2.3 空间配置器的内存配置与释放策略是什么采用双层配置器。 当配置区块足够大，使用第一级配置器，allocate()直接使用malloc()，deallocate()直接使用free()。 当配置区块太小，为防止内存碎片，使用第二级配置器，维护16个自由链表，负责16种小型区块的次配置能力（类似于Linux伙伴系统算法）。维护内存池来填充自由链表。若内存不足，则调用第一级配置器。 2.3 迭代器2.3.1 什么是迭代器模式提供一种方法，使之能依序巡防某个聚合物（容器）所含的各个元素，而又无需暴露该聚合物的内部表达方式。 2.3.2 为什么需要萃取(traits技法)出迭代器的相应型别在算法种运用迭代器时，需要用到其相应型别，这样才能在不同情况下提供最大效率。 如：针对随机访问的迭代器和单向访问的迭代器，实现某种算法的步骤可能不同。 2.3.3 迭代器有哪些内嵌的相应型别所有迭代器都应该定义下列型别。可以直接继承STL提供的std::iterator。 value type：迭代器所指对象的型别T difference type：表示两个迭代器之间的距离。如原生指针之间的距离就可以是整型 reference type：T&amp; pointer type: T* iterator_category：根据移动特性和施行操作，被分为五类 Input Iter: 只读 Output Iter: 只写 Forward Iter: 单向 Bidirectional Iter: 可双向移动。如某些算法可利用这个特性进行逆向巡防。 Random Access Iter: 随机访问，涵盖所有指针算数能力。 2.4 容器 2.4.1 STL容器的分类序列式：vector, list, deque, stack, queue, heap, priority_queue 关联式：RB-tree, set, multiset, map, multimap, hashtable, hash_set, hash_multiset, hash_map, hash_multimap 2.4.2 vector与array有哪些区别 array是静态空间，一旦配置就不能改变。若需要扩大，需要自己配置新空间，复制元素到新空间，最后释放原空间。 vector是动态空间，使用array实现，内部机制会自行进行空间配置。 2.4.3 vector的数据结构 线性连续空间，迭代器start和finish分别指向分配的连续空间中目前已被使用的范围，end_of_storage指向包括备用空间在内的整块连续空间的尾端。因此vector的capacity往往大于size。 vector的迭代器其实是原生指针。 2.4.4 简述vector的内存管理策略初始化时分配一定空间。 新元素插入尾端时： 若还有备用空间，则构造元素，finish++ 若没有备用空间，则进行扩容操作：重新分配（不是原空间）两倍大小的较大空间，将原内容拷贝过来，释放原空间。 因此，若空间重新配置，则指向原vector的迭代器会失效。 2.4.5 list的数据结构节点结构： list结构： 是一个环状双向链表，iter.begin()指向第一个非空节点，iter.end()指向链表尾端的空白节点。 2.4.6 简述deque和vector的区别 vector是单向开口的连续线性空间，deque是双向开口的连续线性空间。 deque允许常数时间内对头端进行插入删除，而vector头部插入删除效率低 deque没有容量的概念，它是动态地以分段连续空间组合而成，因此扩容时不需要 ‘重新配置空间复制再释放’ 这样的操作。 2.4.7 简述deque的实现原理 deque使用map作为主控。map是一小段连续空间，每个元素node都指向另一段连续线性空间（缓冲区512bytes）。缓冲区是deque的存储主体。 start迭代器的cur、first均指向所有缓冲区的第一个元素，last指向第一个缓冲区的末尾。node指向map中的已使用的第一个节点，该节点指向第一个缓冲区。 finish迭代器的cur指向当前deque的最后一个元素，first指向最后一个缓冲区的第一个元素，last指向最后一个缓冲区的末尾，node指向分配最后一个缓冲区的map节点。 2.4.8 如何在deque中随机获取元素先计算出元素所在缓冲区，然后计算元素在该缓冲区的偏移量。 2.4.9 简述deque的内存管理策略deque使用两个空间配置器，一个用来配置map节点，一个用来配置缓冲区。 初始化时，分配至少8个map节点，为最中央的node分配一段缓冲区作为可用空间。 当元素插入时： 被插入的缓冲区有大于1个的可用空间，直接放置元素，更新start或finish 被插入的缓冲区只有1个可用空间，为当前node的前/后一个node分配新的缓冲区，插入元素 若map都已经没有可用空间时，配置更大的map，拷贝原map内容，释放原map 当元素删除时： 若导致缓冲区为空，则释放相应缓冲区。但保证至少有1个缓冲区。 2.4.10 简述deque、stack、queue的关系deque作为缺省情况下的stack和queue的底部结构，stack、queue是容器配接器，都没有迭代器。 2.4.11 简述heap的实现原理 以vector作为底部结构，一个隐式表述的完全二叉树。元素被取出时总是按照一定的次序。没有迭代器。STL默认供应max-heap。 make_heap()：将一段现有的数据转化成一个heap push_heap()：将元素插入到堆中合适的位置（先插入到尾端，然后上溯） pop_heap()：将最大的元素放置到尾端，然后调整堆（令欲调整的节点下溯到最深深度，然后执行一次上溯令其上升到合适位置），此时最后一个元素为最大值，而前面的元素依然是一个max-heap sort_heap()：持续对堆使用pop_heap()最终可以得到升序的序列。 2.4.12 简述priority_queue的实现原理内部元素按照权值排列的队列。缺省情况下的priority_queue利用一个max-heap完成，总是弹出键值最大的元素（pop_heap()）。是一个配接器。 2.4.13 什么是关联式容器，有哪几类每个元素都有一个**键值(key)**和一个实值(value)，键值可以就是实值。当元素被插入到容器中时，容器内部结构（平衡二叉树或哈希表）按照key的大小以某种特定规则将这个元素放置到合适位置。 分类：set集合和map映射表 2.4.14 简述set的特点及实现原理set中元素的键值就是实值，实值就是键值。set中不允许有相同键值, multiset允许。所有元素都会根据键值自动被排序。set的迭代器不能改变元素。（否则会破坏排序） 实现原理：以红黑树作为底层机制，是一种配接器。 具有双向迭代器。 2.4.15 ★ 简述map的特点及实现原理map的所有元素都是pair，同时拥有键值和实值，第一元素是键值，不允许有相同键值, multimap允许。所有元素都会根据键值自动排序。不可以通过迭代器修改键值，但是可以修改键值对应的实值。 实现原理：以红黑树作为底层机制，是一种配接器。 具有双向迭代器。 2.4.16 简述哈希表的特点hashtable（散列表），在插入、删除、搜寻等操作上具有常数平均时间，不需要依赖输入元素的随机性。 利用散列函数，将元素映射到数组的特定位置。 2.4.17 ★ 什么是碰撞问题，如何解决碰撞问题：使用散列函数时，可能有不同的元素被映射到同一位置，产生冲突。 解决方法： 线性探测：若原插入位置不可用，则循序往下一一寻找。primary clustering问题会造成性能下降。 二次探测：不一一寻找，而是在第i次探测时，探测第H+i^2个位置。secondary clustering问题造成性能下降。 开链：在每个表格元素中维护一个list，在list上执行元素操作。list较短时，效率很高。 2.4.18 ★ 简述hashtable的实现原理以开链法实现hashtable： 图中buckets结构指向链表头，链表中存放hashtable的元素。buckets聚合体以vector作为底层机制，利于动态扩充。 具有单向迭代器。 2.4.19 简述hashtable的内存管理策略hashtable预定义了一组素数，初始化时选择最近的那个素数作为表格大小。 插入元素时： 若插入后元素个数不大于表格大小，则计算出索引后直接插入到链表中。若检测到重复键值，则不插入。 否则，需要重建表格（说明hashtable元素最大个数与表格大小相同），执行重新分配，复制，释放操作。 2.4.20 hashtable的键值可以任意取吗下列类型：char*, short, int, long，可以直接被处理。如果是其它类型，需要用户自定义散列函数，如string。 2.4.21 简述hash_set(unordered_set)的特点及实现原理hash_set中的元素与set类似，但没有自动排序功能，支持快速查找元素，hash_multiset支持重复键值。 实现原理：以hashtable作为底层机制。 2.4.22 ★ 简述hash_map(unordered_map)的特点及实现原理hash_map中的元素与map类似，但没有自动排序功能，支持快速查找元素，hash_multimap支持重复键值。 实现原理：以hashtable作为底层机制。 2.4.23 对比STL的各种容器 2.5 算法2.5.1 简述什么是算法的泛型化将算法独立于其处理的数据结构：把操作对象的型别抽象化，把操作对象的表示法和区间目标的移动行为抽象化。 迭代器便充当了此处的操作对象，它把数据结构和算法连接在一起。 2.5.2 简述sort()算法的实现原理12template&lt;class RandomAccessIterator, class Compare&gt;inline void sort(RandomAccessIterator first, RandomAccessIterator last, Compare comp); 接收两个随机存取迭代器（vector和deque），将区间内的元素按仿函数comp定义的规则排序。 数据量很大时，采用快速排序（分段递归）。数据量较小时，采用插入排序 2.6 仿函数2.6.1 什么是仿函数，有什么作用新名称：函数对象，可以像函数一样被调用。 作用：主要用于搭配STL算法使用，将某种操作（加减、比大小等）作为一个参数传递给算法，类似于函数指针。 为什么不直接使用函数指针？函数指针不能满足STL对抽象性的要求，也无法与STL其它组件搭配，产生更灵活的变化。 2.6.2 如何定义一个仿函数定义一个对象，然后重载函数调用运算符operator()。 2.6.3 有哪些常见的仿函数1234567891011121314151617181920// 算术类plus&lt;T&gt;;minus&lt;T&gt;;multiplies&lt;T&gt;;divides&lt;T&gt;;modulus&lt;T&gt;;negate&lt;T&gt;;// 关系运算类equal_to&lt;T&gt;;not_equal_to&lt;T&gt;;greater&lt;T&gt;;greater_equal&lt;T&gt;;less&lt;T&gt;;less_equal&lt;T&gt;;// 逻辑类logical_and&lt;T&gt;;logical_or&lt;T&gt;;logical_not&lt;T&gt;; 2.7 配接器（未整理完~） 3 对象模型（未整理完~） 4 设计模式4.1 基础4.1.1 有哪些设计模式设计模式分为三类： 创造型模式：单例模式、工厂模式、建造者模式、原型模式 结构型模式：适配器模式、组合模式、装饰模式、桥接模式、外观模式、享元模式、代理模式 行为型模式：迭代器模式、观察者模式、策略模式、责任链模式、命令模式、解释器模式、中介者模式、备忘录模式、状态模式、模板方法模式、访问者模式 4.1.2 设计模式的设计原则设计模式有 6 大设计原则： 单一职责原则：就一个类而言，应该仅有一个引起它变化的原因。 开放封闭原则：软件实体可以扩展，但是不可修改。即面对需求，对程序的改动可以通过增加代码来完成，但是不能改动现有的代码。 里氏代换原则：一个软件实体如果使用的是一个基类，那么一定适用于其派生类。即在软件中，把基类替换成派生类，程序的行为没有变化。 依赖倒转原则：抽象不应该依赖细节，细节应该依赖抽象。即针对接口编程，不要对实现编程。 迪米特原则：如果两个类不直接通信，那么这两个类就不应当发生直接的相互作用。如果一个类需要调用另一个类的某个方法的话，可以通过第三个类转发这个调用。 接口隔离原则：每个接口中不存在派生类用不到却必须实现的方法，如果不然，就要将接口拆分，使用多个隔离的接口。 4.2 单例模式4.2.1 什么是单例模式，什么时候应用保证类的实例化对象仅有一个，并且提供一个访问他的全局访问点。 应用场景： 表示文件系统的类，一个操作系统一定是只有一个文件系统，因此文件系统的类的实例有且仅有一个。 打印机打印程序的实例，一台计算机可以连接好几台打印机，但是计算机上的打印程序只有一个，就可以通过单例模式来避免两个打印作业同时输出到打印机。 4.2.2 实现思路单例模式可以通过全局或者静态变量的形式实现，这样比较简单，但是这样会影响封装性，难以保证别的代码不会对全局变量造成影响。 默认的构造函数、拷贝构造函数、赋值构造函数声明为私有的，这样禁止在类的外部创建该对象； 全局访问点也要定义成 静态类型的成员函数，没有参数，返回该类的指针类型。因为使用实例化对象的时候是通过类直接调用该函数，并不是先创建一个该类的对象，通过对象调用。 4.2.3 不安全的实现方式（懒汉）考虑当两个线程同时调用 getInstance 方法，并且同时检测到 instance 是 NULL，两个线程会同时实例化对象，不符合单例模式的要求。 12345678910111213141516// 懒汉模式：直到第一次用到类的实例时才去实例化，上面是懒汉实现。class Singleton{private: static Singleton * instance; Singleton(){} Singleton(const Singleton&amp; tmp){} Singleton&amp; operator=(const Singleton&amp; tmp){}public: static Singleton* getInstance(){ if(instance == NULL){ instance = new Singleton(); } return instance; }};Singleton* Singleton::instance = NULL; 4.2.4 线程安全的实现方式（懒汉）方法：加锁存在的问题：每次判断实例对象是否为空，都要被锁定，如果是多线程的话，就会造成大量线程阻塞。 123456789101112131415161718192021class Singleton{private: static pthread_mutex_t mutex; static Singleton * instance; Singleton(){ pthread_mutex_init(&amp;mutex, NULL); } Singleton(const Singleton&amp; tmp){} Singleton&amp; operator=(const Singleton&amp; tmp){}public: static Singleton* getInstance(){ pthread_mutex_lock(&amp;mutex); if(instance == NULL){ instance = new Singleton(); } pthread_mutex_unlock(&amp;mutex); return instance; }};Singleton* Singleton::instance = NULL;pthread_mutex_t Singleton::mutex; 方法：内部静态变量，在全局访问点 getInstance 中定义静态实例。 123456789101112131415class Singleton{private: static pthread_mutex_t mutex; Singleton(){ pthread_mutex_init(&amp;mutex, NULL); } Singleton(const Singleton&amp; temp){} Singleton&amp; operator=(const Singleton&amp; temp){}public: static Singleton* getInstance(){ static Singleton instance; return &amp;instance; }};pthread_mutex_t Singleton::mutex; 4.2.5 饿汉模式实现（本身即线程安全）1234567891011121314// 饿汉模式：类定义的时候就实例化。class Singleton{private: static Singleton* instance; Singleton(const Singleton&amp; temp){} Singleton&amp; operator=(const Singleton&amp; temp){}protected: Singleton(){} public: static Singleton* getInstance(){ return instance; }};Singleton* Singleton::instance = new Singleton(); 4.3 工厂模式工厂模式：包括简单工厂模式、抽象工厂模式、工厂方法模式 简单工厂模式：主要用于创建对象。用一个工厂来根据输入的条件产生不同的类，然后根据不同类的虚函数得到不同的结果。 工厂方法模式：修正了简单工厂模式中不遵守开放封闭原则。把选择判断移到了客户端去实现，如果想添加新功能就不用修改原来的类，直接修改客户端即可。 抽象工厂模式：定义了一个创建一系列相关或相互依赖的接口，而无需指定他们的具体类。 4.3.1 什么是简单工厂模式，什么时候应用主要用于创建对象。用一个工厂来根据输入的条件产生不同的类，然后根据不同类的虚函数得到不同的结果。 应用场景： 适用于针对不同情况创建不同类时，只需传入工厂类的参数即可，无需了解具体实现方法。例如：计算器中对于同样的输入，执行不同的操作：加、减、乘、除。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;// Here is the product classclass Operation{public: int var1, var2; virtual double GetResult() { double res = 0; return res; }};class Add_Operation : public Operation{public: virtual double GetResult() { return var1 + var2; }};class Sub_Operation : public Operation{public: virtual double GetResult() { return var1 - var2; }};class Mul_Operation : public Operation{public: virtual double GetResult() { return var1 * var2; }};class Div_Operation : public Operation{public: virtual double GetResult() { return var1 / var2; }};// Here is the Factory classclass Factory{public: static Operation *CreateProduct(char op) { switch (op) { case '+': return new Add_Operation(); case '-': return new Sub_Operation(); case '*': return new Mul_Operation(); case '/': return new Div_Operation(); default: return new Add_Operation(); } }};int main(){ int a, b; cin &gt;&gt; a &gt;&gt; b; Operation *p = Factory::CreateProduct('+'); p-&gt;var1 = a; p-&gt;var2 = b; cout &lt;&lt; p-&gt;GetResult() &lt;&lt; endl; p = Factory::CreateProduct('*'); p-&gt;var1 = a; p-&gt;var2 = b; cout &lt;&lt; p-&gt;GetResult() &lt;&lt; endl; return 0;} 4.3.2 什么是工厂方法模式，什么时候应用修正了简单工厂模式中不遵守开放封闭原则。把选择判断移到了客户端去实现，如果想添加新功能就不用修改原来的类，直接修改客户端即可。 应用场景： 一个类不知道它所需要的对象的类：在工厂方法模式中，客户端不需要知道具体产品类的类名，只需要知道所对应的工厂即可，具体的产品对象由具体工厂类创建；客户端需要知道创建具体产品的工厂类。 一个类通过其派生类来指定创建哪个对象：在工厂方法模式中，对于抽象工厂类只需要提供一个创建产品的接口，而由其派生类来确定具体要创建的对象，利用面向对象的多态性和里氏代换原则，在程序运行时，派生类对象将覆盖父类对象，从而使得系统更容易扩展。 将创建对象的任务委托给多个工厂派生类中的某一个，客户端在使用时可以无须关心是哪一个工厂派生类创建产品派生类，需要时再动态指定，可将具体工厂类的类名存储在配置文件或数据库中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;// Here is the product classclass Operation{public: int var1, var2; virtual double GetResult() { double res = 0; return res; }};class Add_Operation : public Operation{public: virtual double GetResult() { return var1 + var2; }};class Sub_Operation : public Operation{public: virtual double GetResult() { return var1 - var2; }};class Mul_Operation : public Operation{public: virtual double GetResult() { return var1 * var2; }};class Div_Operation : public Operation{public: virtual double GetResult() { return var1 / var2; }};class Factory{public: virtual Operation *CreateProduct() = 0;};class Add_Factory : public Factory{public: Operation *CreateProduct() { return new Add_Operation(); }};class Sub_Factory : public Factory{public: Operation *CreateProduct() { return new Sub_Operation(); }};class Mul_Factory : public Factory{public: Operation *CreateProduct() { return new Mul_Operation(); }};class Div_Factory : public Factory{public: Operation *CreateProduct() { return new Div_Operation(); }};int main(){ int a, b; cin &gt;&gt; a &gt;&gt; b; Add_Factory *p_fac = new Add_Factory(); Operation *p_pro = p_fac-&gt;CreateProduct(); p_pro-&gt;var1 = a; p_pro-&gt;var2 = b; cout &lt;&lt; p_pro-&gt;GetResult() &lt;&lt; endl; Mul_Factory *p_fac1 = new Mul_Factory(); Operation *p_pro1 = p_fac1-&gt;CreateProduct(); p_pro1-&gt;var1 = a; p_pro1-&gt;var2 = b; cout &lt;&lt; p_pro1-&gt;GetResult() &lt;&lt; endl; return 0;} 4.3.3 什么是抽象工厂模式，什么时候应用定义了一个创建一系列相关或相互依赖的接口，而无需指定他们的具体类。 应用场景： 一个系统不应当依赖于产品类实例如何被创建、组合和表达的细节，这对于所有类型的工厂模式都是重要的。 系统中有多于一个的产品族，而每次只使用其中某一产品族。 属于同一个产品族的产品将在一起使用，这一约束必须在系统的设计中体现出来。 产品等级结构稳定，设计完成之后，不会向系统中增加新的产品等级结构或者删除已有的产品等级结构。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;// Here is the product classclass Operation_Pos{public: int var1, var2; virtual double GetResult() { double res = 0; return res; }};class Add_Operation_Pos : public Operation_Pos{public: virtual double GetResult() { return var1 + var2; }};class Sub_Operation_Pos : public Operation_Pos{public: virtual double GetResult() { return var1 - var2; }};class Mul_Operation_Pos : public Operation_Pos{public: virtual double GetResult() { return var1 * var2; }};class Div_Operation_Pos : public Operation_Pos{public: virtual double GetResult() { return var1 / var2; }};/*********************************************************************************/class Operation_Neg{public: int var1, var2; virtual double GetResult() { double res = 0; return res; }};class Add_Operation_Neg : public Operation_Neg{public: virtual double GetResult() { return -(var1 + var2); }};class Sub_Operation_Neg : public Operation_Neg{public: virtual double GetResult() { return -(var1 - var2); }};class Mul_Operation_Neg : public Operation_Neg{public: virtual double GetResult() { return -(var1 * var2); }};class Div_Operation_Neg : public Operation_Neg{public: virtual double GetResult() { return -(var1 / var2); }};/*****************************************************************************************************/// Here is the Factory classclass Factory{public: virtual Operation_Pos *CreateProduct_Pos() = 0; virtual Operation_Neg *CreateProduct_Neg() = 0;};class Add_Factory : public Factory{public: Operation_Pos *CreateProduct_Pos() { return new Add_Operation_Pos(); } Operation_Neg *CreateProduct_Neg() { return new Add_Operation_Neg(); }};class Sub_Factory : public Factory{public: Operation_Pos *CreateProduct_Pos() { return new Sub_Operation_Pos(); } Operation_Neg *CreateProduct_Neg() { return new Sub_Operation_Neg(); }};class Mul_Factory : public Factory{public: Operation_Pos *CreateProduct_Pos() { return new Mul_Operation_Pos(); } Operation_Neg *CreateProduct_Neg() { return new Mul_Operation_Neg(); }};class Div_Factory : public Factory{public: Operation_Pos *CreateProduct_Pos() { return new Div_Operation_Pos(); } Operation_Neg *CreateProduct_Neg() { return new Div_Operation_Neg(); }};int main(){ int a, b; cin &gt;&gt; a &gt;&gt; b; Add_Factory *p_fac = new Add_Factory(); Operation_Pos *p_pro = p_fac-&gt;CreateProduct_Pos(); p_pro-&gt;var1 = a; p_pro-&gt;var2 = b; cout &lt;&lt; p_pro-&gt;GetResult() &lt;&lt; endl; Add_Factory *p_fac1 = new Add_Factory(); Operation_Neg *p_pro1 = p_fac1-&gt;CreateProduct_Neg(); p_pro1-&gt;var1 = a; p_pro1-&gt;var2 = b; cout &lt;&lt; p_pro1-&gt;GetResult() &lt;&lt; endl; return 0;} 4.4 观察者模式4.4.1 什么是观察者模式，什么时候应用观察者模式：定义一种一（被观察类）对多（观察类）的关系，让多个观察对象同时监听一个被观察对象，被观察对象状态发生变化时，会通知所有的观察对象，使他们能够更新自己的状态。 观察者模式中存在两种角色： 观察者：内部包含被观察者对象，当被观察者对象的状态发生变化时，更新自己的状态。（接收通知更新状态） 被观察者：内部包含了所有观察者对象，当状态发生变化时通知所有的观察者更新自己的状态。（发送通知） 应用场景： 当一个对象的改变需要同时改变其他对象，且不知道具体有多少对象有待改变时，应该考虑使用观察者模式； 一个抽象模型有两个方面，其中一方面依赖于另一方面，这时可以用观察者模式将这两者封装在独立的对象中使它们各自独立地改变和复用。 4.4.2 观察者模式的实现方式123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;list&gt;using namespace std;class Subject;//观察者 基类 （内部实例化了被观察者的对象sub）class Observer{protected: string name; Subject *sub;public: Observer(string name, Subject *sub) { this-&gt;name = name; this-&gt;sub = sub; } virtual void update() = 0;};class StockObserver : public Observer{public: StockObserver(string name, Subject *sub) : Observer(name, sub) { } void update();};class NBAObserver : public Observer{public: NBAObserver(string name, Subject *sub) : Observer(name, sub) { } void update();};//被观察者 基类 （内部存放了所有的观察者对象，以便状态发生变化时，给观察者发通知）class Subject{protected: list&lt;Observer *&gt; observers;public: string action; //被观察者对象的状态 virtual void attach(Observer *) = 0; virtual void detach(Observer *) = 0; virtual void notify() = 0;};class Secretary : public Subject{ void attach(Observer *observer) { observers.push_back(observer); } void detach(Observer *observer) { list&lt;Observer *&gt;::iterator iter = observers.begin(); while (iter != observers.end()) { if ((*iter) == observer) { observers.erase(iter); return; } ++iter; } } void notify() { list&lt;Observer *&gt;::iterator iter = observers.begin(); while (iter != observers.end()) { (*iter)-&gt;update(); ++iter; } }};void StockObserver::update(){ cout &lt;&lt; name &lt;&lt; &quot; 收到消息：&quot; &lt;&lt; sub-&gt;action &lt;&lt; endl; if (sub-&gt;action == &quot;梁所长来了!&quot;) { cout &lt;&lt; &quot;我马上关闭股票，装做很认真工作的样子！&quot; &lt;&lt; endl; }}void NBAObserver::update(){ cout &lt;&lt; name &lt;&lt; &quot; 收到消息：&quot; &lt;&lt; sub-&gt;action &lt;&lt; endl; if (sub-&gt;action == &quot;梁所长来了!&quot;) { cout &lt;&lt; &quot;我马上关闭NBA，装做很认真工作的样子！&quot; &lt;&lt; endl; }}int main(){ Subject *dwq = new Secretary(); Observer *xs = new NBAObserver(&quot;xiaoshuai&quot;, dwq); Observer *zy = new NBAObserver(&quot;zouyue&quot;, dwq); Observer *lm = new StockObserver(&quot;limin&quot;, dwq); dwq-&gt;attach(xs); dwq-&gt;attach(zy); dwq-&gt;attach(lm); dwq-&gt;action = &quot;去吃饭了！&quot;; dwq-&gt;notify(); cout &lt;&lt; endl; dwq-&gt;action = &quot;梁所长来了!&quot;; dwq-&gt;notify(); return 0;} （未整理完~） Reference: 《C++ Primer Plus》 《深度探索C++对象模型》- Stanley B. Lippman 《STL源码解析》 - 侯捷 C++突击","link":"/2021/04/26/2021-04-26-interview-C++/"},{"title":"chap 0-1 算法基础-Start with Fibonacci","text":"1. Fibonacci数列Fibonacci是15世纪意大利著名的数学家，虽然大多数人不太清楚他的具体贡献，却都对Fibonacci数列耳熟能详： $$0,1,1,2,3,5,8,13,21,34$$ 我们设Fibonacci数列的第$n$项的值为$F_n$，则数列的每一项可以由以下递推式生成： $$\\begin{equation}F_n=\\begin{cases} F_{n-1}+F_{n-2}, &amp; n&gt;1 \\\\ 1, &amp; n=1 \\\\ 0, &amp; n=0\\end{cases}\\end{equation}$$ 假设$F_n\\geq 2^{cn}$成立，通过数学归纳法可以推出，$2^c\\leq \\frac{1+\\sqrt{5}}{2}$，即$F_n\\geq 2^{0.694n}$。通过数学方法也可以推出： $$F_n=\\frac{1}{\\sqrt{5}}(\\frac{1+\\sqrt{5}}{2})^{n}-\\frac{1}{\\sqrt{5}}(\\frac{1-\\sqrt{5}}{2})^{n} \\approx 2^{0.694n}$$ 使用计算机求解时，如何设计出一个计算$F_n$的算法？ 2. fib1-指数时间(exponential)最容易想到的算法就是直接利用上述的递推式定义，写成递归形式： 123456// 假设所有数值范围均在int最大范围内int fib1(int n) { if (n == 0) return 0; if (n == 1) return 1; return fib1(n - 1) + fib1(n - 2);} 每当设计完一个算法时，都需要问自己三个问题： 算法是否正确？ 给定输入大小$n$，算法需要花费多少时间完成？ 是否存在更好的其他算法？ 对于fib1，很容易验证算法是正确的，但如何确定该算法的运行时间？最简单的方法是，利用各编程语言自带的计时指令，可以输出每次程序运行的时间： 1234567891011121314151617181920212223242526// 本地PC运行结果，不同电脑的运行结果可能不同fib1_testInput n: 10Output: 55time = 1ms======================================fib1_testInput n: 20Output: 6765time = 1ms======================================fib1_testInput n: 30Output: 832040time = 61ms======================================fib1_testInput n: 35Output: 9227465time = 564ms======================================fib1_testInput n: 40Output: 102334155time = 6241ms====================================== 但是我们不可能每次都通过实验的方法去预估时间，而是应该提前进行算法分析。算法就是一个程序，那么如何分析一个程序执行花费的时间呢？ 先粗略分析，定义$T(n)$表示执行算法$fib1(n)$所需要的computer steps的数量。这里的computer steps可以理解为计算机执行的宏观操作，比如在$fib1(n)$中，$n$足够大时，除了递归，还存在2次分支判断操作和1次加法操作。我们可以由此计算出$T(n)$： $$\\begin{equation}T(n)=\\begin{cases}&amp; 1 &amp; n=0 \\\\ &amp; 2 &amp; n=1 \\\\ &amp; T(n-1)+T(n-2)+3 &amp; n&gt;1\\end{cases}\\end{equation}$$ 对比$F_n$的表达式，易得：$T(n)\\geq F_n$，可知$T(n)$将关于$n$以指数级(exponential)递增。 有了执行算法需要的computer steps的数量，和执行每个step所花费的平均时间，就可以预估出算法的执行时间。以计算$F_{200}$为例，需要$T(200)\\geq F_{200}\\geq 2^{138}$个steps。若某台超级计算机每秒平均执行$4\\times 10^{14}$个steps，则运行完该算法需要至少$2^{94}$秒。 3. fib2-多项式时间(polynomial)解决了前两个问题，下面考虑第三个问题，是否存在更好的算法？显然，在上述例子中，在有生之年计算机将无法计算出$F_{200}$。通过分析，不难发现，fib1中存在大量的重复计算： 12345678910 F(n) _____________|_____________ | | F(n-1) F(n-2) _______|_______ ________|________ | | | | F(n-2) F(n-3) F(n-3) F(n-4) ____|____ _____|____ ____|____ _____|____ | | | | | | | |F(n-3) F(n-4) F(n-4) F(n-5) F(n-4) F(n-5) F(n-5) F(n-6) 我们可以将每个计算好的$F$的值存储起来，便于下一次直接使用： 123456789101112int fib2(int n) { if (n == 0) return 0; int f0 = 0; int f1 = 1; int tmp; for (int i = 1; i &lt; n; ++i) { tmp = f1; f1 = f1 + f0; f0 = tmp; } return f1;} 不难看出，$T(n)$将关于$n$线性递增。通过这一优化，step的数量从指数级降低为多项式级(polynomial)。 即使现在的结果还不错，我们仍然要问：是否存在更好的算法？确实存在，此处先打住。 4. 深入分析上述粗略分析忽略的一个重要问题是每个computer step的执行时间并不是相同的。每个处理器的指令集里含有多种类型的指令，如访存、算术运算、分支跳转等，每个step均可以分解为若干指令。每个指令的执行时间也并不是完全相同的。 举个简单的例子，对于加法这个操作，由于加法器本身的性质，加数的bit数越大，加法耗费的时间也越长。可以证明，两个$n-bit$的数相加的时间与$n$成正比，$F_n$大约为 $0.694n$ bits，因此在算法$fib2$中，也可以说$T(n)$关于$n^2$线性递增。 是不是感觉越来越复杂？我们从一开始非常粗略地分析，又落入到了现在过于细致地分析的陷阱里。是否有一种合适的方法来分析算法执行的时间？下面将详细介绍Big-$O$ notation。 Quick Link: 算法笔记整理","link":"/2021/12/20/2021-12-20-algorithms-notes-chap0-1-start-with-fibonacci/"},{"title":"chap 1-1 数论算法-加减法","text":"1. 浅谈基数(base)和$\\log$这章主要研究的对象是数字，首要的问题是，如何表示数字？众所周知，目前我们日常使用的都是十进制表示法（可能因为有十个手指头吧），计算机内部使用的都是二进制表示法。这里的“十”、“二”就是基数(base)。 假设现在用$b(b\\geq 2)$-进制表示法。第一个问题，表示一个正整数$N\\geq 0$需要至少多少位？我们知道，$k$位数字最大是$b^k-1$，那么可以推导出我们至少需要$\\lceil \\log_b (N+1) \\rceil$位。 同一个数$N$分别用$b$-进制和$a$-进制表示，它们的位数有啥关系呢？推导一下： $$\\lceil \\log_a (N+1) \\rceil=\\lceil \\log_b (N+1) \\log_a b \\rceil \\leq \\lceil \\log_b (N+1) \\rceil \\lceil\\log_a b \\rceil$$ 可以得到一个有趣的推论：对于同一个数，用二进制法表示的位数最多是十进制法表示的位数的$\\lceil\\log_2 10 \\rceil=4$倍。在实现大整数的进制转换时，可以利用这个推论提前分配空间。使用Big-$O$ Notation时，上述推论也同时说明了不管基数为多少，我们都可以直接使用$O(\\log N)$来表示复杂度。 $O(\\log N)$可以说是计算机学科的常客了，比如$N$节点完全二叉树的深度、二分法等等，都很容易想到$log N$。然而下面这个结论一眼看不出来： $$有限项调和级数：\\sum_{i=1}^n \\frac{1}{i}=\\Theta(\\log n)$$ $Proof:$ $$\\begin{equation}\\begin{aligned}\\sum_{i=1}^n \\frac{1}{i} &amp; = 1 + \\frac{1}{2} + \\frac{1}{3} + \\frac{1}{4} + \\cdots \\\\ &amp; \\leq 1 + \\frac{1}{2} + \\frac{1}{2} + \\frac{1}{4} + \\frac{1}{4} + \\frac{1}{4} + \\frac{1}{4} + \\cdots \\\\ &amp;= 1 + 1 + 1 + \\cdots \\\\ &amp;= O(\\log n)\\end{aligned}\\end{equation}$$ $$\\begin{equation}\\begin{aligned}\\sum_{i=1}^n \\frac{1}{i} &amp; = 1 + \\frac{1}{2} + \\frac{1}{3} + \\frac{1}{4} + \\cdots \\\\ &amp; \\geq 1 + \\frac{1}{2} + \\frac{1}{4} + \\frac{1}{4} + \\frac{1}{8} + \\frac{1}{8} + \\frac{1}{8} + \\frac{1}{8} + \\cdots \\\\ &amp;= 1 + \\frac{1}{2} + \\frac{1}{2} + \\frac{1}{2} + \\cdots \\\\ &amp;= O(\\log n)\\end{aligned}\\end{equation}$$ 排序算法中，$O(N\\log N)$也算是常客了。然而下面这个结论一眼也看不出来： $$\\log(n!)=\\Theta(n\\log n)$$ $Proof:$ $$(\\frac{n}{2})^{\\frac{n}{2}} \\leq n! \\leq n^n$$ $$\\frac{n}{2}\\log \\frac{n}{2} \\leq log(n!) \\leq n\\log n$$ $$\\frac{n}{2}\\log n - \\frac{n}{2} \\leq log(n!) \\leq n\\log n$$ 有些扯远了，我们现在回到本章的主题。 2. 加法的性质看到这，你可能觉得奇怪，加法不是小学起就学过，还能有啥性质呢？其实，加法竖式计算以及数字电路中加法器的设计就不知不觉使用了如下的性质： 假设一个整数，以 $b(b\\geq 2)$作为基数(base)，即 $b$-进制。那么任意三个1位整数的和至多只会有2位。 举例：9+9+9=27, 001+001+001=011… $Proof:$ 1位整数，最大值为$b-1$；任意三个1位整数之和最大值为$3b-3$；2位整数，最大值为$(b-1)\\cdot b^1+(b-1)\\cdot b^0=b^2-1$；由于$b^2-1-(3b-3)=(b-1)(b-2)\\geq 0$，故上述性质成立。▮ 有了这个性质，我们很容易就可以想到如何进行$b$-进制加法：将两个数右端对齐，从右至左依次对每一位求和，进位记为$carry$。性质表明，求和结果加上$carry$至多为2位，$carry$至多为1位。举例： 12345carry: 1 1 1 1 1 1 0 1 (13) + 1 1 1 1 (15) ------------- 1 1 1 0 0 (28) 3. $n-bit$加法实现与分析上述方法其实就是行波进位加法器的设计思想（参见数字电路设计），原理如下： 其中，$A_k$代表第1个加数的第$k$位的值，$B_k$代表第2个加数的第$k$位的值，$S_k$代表两数之和的第$k$位的值，$C$代表进位(carry)。 下面用代码模拟加法器的运行步骤，实现如下的二进制$n-bit$加法： 12345678910111213141516171819202122232425262728293031323334class Binary {public: int* arr; // inverse order：0x1101 (13) =&gt; [1, 0, 1, 1], length=4 int length; int MAX_LEN; Binary operator+(const Binary&amp; num) { int* a = arr; int a_len = length; int* b = num.arr; int b_len = num.length; Binary addition = Binary(); while (addition.MAX_LEN &lt; max(a_len, b_len) + 2) addition.double_size(); int* c = addition.arr; int carry = 0; int i; for (i = 0; i &lt; max(a_len, b_len); ++i) { int res = (i&lt;a_len?a[i]:0) + (i&lt;b_len?b[i]:0) + carry; carry = 0; if (res &gt; 1) { carry = 1; res -= 2; } c[i] = res; } if (carry == 1) { c[i] = 1; i++; } addition.length = i; return addition; }} 再次考虑那三个问题，首先算法是否正确，下面为测试结果，没有明显错误： 123456789101112131415161718192021222324252627addition_testInput the first binary integer a: 1101Decimal value of a: 13Input the second binary integer b: 1111Decimal value of b: 15Output: 11100Decimal output: 28time = 1ms======================================addition_testInput the first binary integer a: 111011Decimal value of a: 59Input the second binary integer b: 10Decimal value of b: 2Output: 111101Decimal output: 61time = 1ms======================================addition_testInput the first binary integer a: 1010010101111010110Decimal value of a: 338902Input the second binary integer b: 1010111110111110101011Decimal value of b: 2879403Output: 1100010001101110000001Decimal output: 3218305time = 2ms====================================== 第二个问题，算法复杂度如何？显然是$O(n)$。 注意在本章中，我们考虑的算法复杂度都是细化到$bit$层级的，即复杂度是输入$n-bit$数字的$n$的函数。原因有二：首先，如果运算的数字变得非常大时（本章后面的算法），大数的运算原理和这里基本相同（可以了解一下Java中BigInteger的实现）；其次，有助于我们理解计算机的硬件是如何实现运算的。 第三个问题：是否有更快的算法？投机取巧一下，读取和输入都至少各要$n$次操作，所以$O(n)$已经是最优。 4. 减法减法的原理和加法基本相同，不再赘述： 123456789101112131415161718192021222324252627// Assume a&gt;=bBinary operator-(const Binary&amp; num) { int* a = arr; int a_len = length; int* b = num.arr; int b_len = num.length; Binary subtraction = Binary(); while (subtraction.MAX_LEN &lt; max(a_len, b_len) + 2) subtraction.double_size(); int* c = subtraction.arr; int carry = 0; int i; for (i = 0; i &lt; max(a_len, b_len); ++i) { int minuend = i &lt; a_len ? a[i] : 0; int subtrahend = (i &lt; b_len ? b[i] : 0) + carry; carry = 0; if (minuend &lt; subtrahend) { carry = 1; minuend += 2; } int res = minuend - subtrahend; c[i] = res; } while (i-1 &gt; 0 &amp;&amp; c[i-1] == 0) i--; subtraction.length = i; return subtraction;} Quick Link: 算法笔记整理","link":"/2021/12/22/2021-12-22-algorithms-notes-chap1-1-addition-substraction/"},{"title":"chap 0-2 算法基础-渐进表示法","text":"1. 渐进表示法使用basic computer steps来描述算法耗时确实已经是一个很好的简化了，它排除了处理器、缓存策略等差异造成的影响。我们可以在此基础上继续简化。 假设$T(n)=3n^2+6n+2$，我们干脆直接省略掉表达式中的低阶项($6n+2$)。可以想象，当$n$非常大时，这些低阶项对总体的影响可以忽略不计了。再进一步，$n^2$前面的系数3也直接省略吧(Thanks to Moore Law)，我们直接说：该算法花费的时间为$O(n^3)$ （big oh of $n^3$） 下面给出Big-$O$ Notation的定义（渐近表示法），一般用于分析算法的复杂度： $f(n)$和 $g(n)$分别为两个算法消耗的时间，输入项大小为$n$。 若存在一个常数 $c&gt;0$，使 $f(n)\\leq c\\cdot g(n)$，则称 $f=O(g)$，即 $f$的增长速度不比 $g$快。 $f=O(g)$可以当作是 $f\\leq g$，只不过这里比较的是增长速度。 假设$f_1(n)=n^2$，$f_2(n)=2n+10$，$f_3(n)=n+1$， 则$f_2=O(f_1)$，因为$f_2\\leq 12f_1$；$f_1\\neq O(f_2)$，因为找不到$c$使$f_1\\leq c\\cdot f_2$。 同理，$f_2=O(f_3),f_3=O(f_2)$。 按照Big-$O$ Notation的定义，我们可以继续定义Big-$\\Omega$ Notation和Big-$\\Theta$ Notation： $f=\\Omega(g)$ &lt;=&gt; $g=O(f)$ $f=\\Theta(g)$ &lt;=&gt; $f=O(g)$且 $f=\\Omega(g)$ 上述例子中，$f_2=\\Theta(f_3)$，$f_1=\\Omega(f_3)$。 化简为Big-$O$ Notation的常用技巧： 省略系数：如$3n^2$ =&gt; $n^2$ $n^a$增速大于$n^b$（$a&gt;b$）：$n^2+n$ =&gt; $O(n^2)$ 指数项增速大于多项式：$2^n+n^9$ =&gt; $O(2^n)$ 多项式增速大于对数项：$n+(\\log n)^5$ =&gt; $O(n)$ 2. Revisit Fibonacci使用Big-$O$ Notation来分析前面的两个算法： $fib1$的时间复杂度为：$O(2^n)$，若考虑数字的bit数，复杂度为$O(n\\cdot 2^n)$ $fib2$的时间复杂度为：$O(n)$，若考虑数字的bit数，复杂度为$O(n^2)$ 2.1 矩阵快速幂之前提到过，存在更好的方法来计算$F_n$，原理是利用矩阵(matrix)： $$\\begin{equation}\\begin{bmatrix}F_1 \\\\ F_2\\end{bmatrix}=\\begin{bmatrix} 0 &amp; 1 \\\\ 1 &amp; 1\\end{bmatrix}\\begin{bmatrix}F_0 \\\\ F_1\\end{bmatrix}\\end{equation}$$ $$\\begin{equation}\\begin{bmatrix}F_2 \\\\ F_3\\end{bmatrix}=\\begin{bmatrix} 0 &amp; 1 \\\\ 1 &amp; 1\\end{bmatrix}\\begin{bmatrix}F_1 \\\\ F_2\\end{bmatrix}=\\begin{bmatrix} 0 &amp; 1 \\\\ 1 &amp; 1\\end{bmatrix}^2\\begin{bmatrix}F_0 \\\\ F_1\\end{bmatrix}\\end{equation}$$ $$…$$ $$\\begin{equation}\\begin{bmatrix}F_{n} \\\\ F_{n+1}\\end{bmatrix}=\\begin{bmatrix} 0 &amp; 1 \\\\ 1 &amp; 1\\end{bmatrix}^n\\begin{bmatrix}F_0 \\\\ F_1\\end{bmatrix}\\end{equation}$$ 所以只需要计算出一个固定矩阵的$n$次方就可以得出结果。代码如下： 123456789101112131415161718Matrix&lt;int&gt; matrix_pow(Matrix&lt;int&gt;&amp; m, int n) { if (n == 1) return m; Matrix&lt;int&gt; res = matrix_pow(m, n / 2); if (n % 2 == 1) return m * res * res; return res * res;}int fib3(int n) { if (n == 0) return 0; if (n == 1) return 1; Matrix&lt;int&gt; m = Matrix&lt;int&gt;(2, 2); m(1, 1) = 0; m(1, 2) = 1; m(2, 1) = 1; m(2, 2) = 1; m = matrix_pow(m, n); return m(1, 2);} 分析$fib3$，每进行一次矩阵乘法需要使用4次实数加法和8次实数乘法，由于实数乘法耗时大于实数加法，下面将只考虑乘法。假设有矩阵$X$，采用代码中matrix_pow的分治策略（后面章节会详细分析）： $$\\begin{equation}X^n=\\begin{cases}&amp;(X^{\\lfloor \\frac{n}{2} \\rfloor})^2, &amp; n为偶数 \\\\ &amp;X \\cdot (X^{\\lfloor \\frac{n}{2} \\rfloor})^2, &amp; n为奇数\\end{cases}\\end{equation}$$ 易得计算出$X^n$将需要至少$\\log n$次矩阵乘法，即$O(\\log n)$次实数乘法。如果不考虑数字的bit数，那么该算法的复杂度就是$O(\\log n)$。 下面分析数字bit位数的变化。每一次矩阵平方，bit位数将翻倍；若只乘以$X$，bit位数最多加一位，可忽略不计。由此可以推算出经过$\\log n$次运算后，$F_n$的长度将为$2^{\\log n}=O(n)-bits$，那么对于两个$n-bit$的实数，每次乘法所需要的步数$M(n)$是多少呢？大家可以猜测一下，使用一般方法应该是$M(n)=O(n^2)$。 综上所述，该算法的总复杂度似乎是$O(M(n)\\log n)$。但是，我们注意到，每分治一次，数字的bit位数其实变为原来的一半，总复杂度应该要比上述式子更小。假设总的steps为$T(n)$，则可以列出下面的式子： $$T(n)=T(\\frac{n}{2})+O(M(\\frac{n}{2}))$$ 我们做出一个乐观的预测：$M(n)=O(n^c),1 &lt; c &lt; 2$。那么上述式子可以化简为： $$T(n)=M(\\frac{n}{2})+M(\\frac{n}{4})+\\cdots +M(1)\\leq n^c\\sum^{i}\\frac{1}{2^{ic}}=O(n^c)=O(M(n))$$ 由此可得，该算法的复杂度就是$O(M(n))$。只要两个$n-bit$实数乘法复杂度小于$O(n^2)$，$fib3$就会比$fib2$更快！那么有可能实现吗？再次打住，后面再详细说。 2.2 公式法上一章提过，可以用数学推导出来的公式直接计算$F_n$： $$F_n=\\frac{1}{\\sqrt{5}}(\\frac{1+\\sqrt{5}}{2})^{n}-\\frac{1}{\\sqrt{5}}(\\frac{1-\\sqrt{5}}{2})^{n}$$ 看着简单，但其实行不通，因为所有数字都是无理数，无理数的$n$次方，会丢失精度。 有趣的是，仔细观察$fib3$中的矩阵： $$\\begin{equation}X=\\begin{bmatrix} 0 &amp; 1 \\\\ 1 &amp; 1\\end{bmatrix}\\end{equation}$$ 可以求解出它的特征值为： $$\\lambda_1=\\frac{1+\\sqrt{5}}{2}, \\lambda_2=\\frac{1-\\sqrt{5}}{2}$$ 而矩阵的特征值具有如下性质： $$X\\xi=\\lambda \\xi$$ $$X^2\\xi=\\lambda^2 \\xi$$ $$…$$ $$X^n\\xi=\\lambda^n \\xi$$ 是不是与$F_n$的公式有千丝万缕的联系？其实，$fib3$本质上就是求解了无理数的$n$次方，只不过是换了一种表达形式罢了。 Quick Link: 算法笔记整理","link":"/2021/12/20/2021-12-20-algorithms-notes-chap0-2-big-O-notation/"},{"title":"chap 1-3 数论算法-模运算","text":"1. 模运算我们知道，计算机处理器进行内置的算术运算时，数字大小都是有限制的（32 bits or 64 bits），这已经可以满足绝大多数计算需求了。但如果不断地对一个数做加法或乘法运算，它将变得非常大，最终将会溢出(overflow)。如何解决这个问题？可以从日常生活中得到启发：日复一日，年复一年… 第二天又是新的24小时，第二年又是新的十二个月… 于是，为了把数字限制在一定的区间(range)内，模运算应运而生： $x \\mod N$表示 $x/N$ 的余数，即：若 $x=qN+r(0\\leq r &lt; N)$，则 $x\\mod N=r$。 建立了新的模运算体系，有必要重新研究一下一些基本运算。 最重要的运算，判断两数是否相等：$1\\neq 25$，但是 $1 \\mod 24=25\\mod 24$（一天24小时），在这种情况下1和25是等价的。于是我们定义模运算下的相等： 如果 $x$ 和 $y$ 的差值为 $N$ 的整数倍数，那么称 $x$和 $y$ 对模 $N$ 同余，即 $x\\equiv y(\\mod N)$ &lt;=&gt; $N整除x-y$。 $x$ 和 $y$ 对模 $N$ 同余的含义就是：$x\\mod N = y\\mod N$。 形象理解模运算：把数字限制在区间{$0,1,2,\\cdots,N-1$}里，只要跃出区间，就再映射回去。 抽象理解模运算：把全体数字分成 $N$ 类，属于{$i+kN: k\\in Z, 0\\leq i\\leq N-1$}区间中的数都被视为 $i$。 2. 模运算的性质既然模运算的作用是限制数字大小，那么在计算的过程中是否可以先进行模运算，然后再做加减乘除？下面的几个基本性质为我们提供了便利。 代换律：若 $x\\equiv x’(\\mod N)$且 $y\\equiv y’(\\mod N)$，则 $x+y\\equiv x’+y’(\\mod N)$，$xy\\equiv x’y’(\\mod N)$ $Proof:$ $(x+y)-(x’-y’)=(x-x’)+(y-y’)$ 可被$N$整除；$xy-x’y’=x(y-y’)+y(x-x’)$ 可被 $N$ 整除。▮ 结合律：$x+(y+z) \\equiv (x+y)+z (\\mod N)$ 交换律：$xy \\equiv yx (\\mod N)$ 分配律：$x(y+z) \\equiv xy+yz (\\mod N)$ 若干推论： $(x+y)\\mod N=((x\\mod N) + (y\\mod N))\\mod N$ $(x-y)\\mod N=((x\\mod N) - (y\\mod N))\\mod N$ $x\\cdot y\\mod N=((x\\mod N)\\cdot(y\\mod N))\\mod N$ $x^y\\mod N=(x\\mod N)^y\\mod N$ 上面的性质告诉我们：在做加、减、乘、乘方的带模的混合运算时，可以在任何阶段对数字取模 $N$ 来减小中间结果。 举例：$2^{345}\\equiv 32^{69} \\equiv 1^{69} \\equiv 1 (\\mod 31)$, $2^{2^{2006}}\\equiv 4^{2^{2005}}\\equiv 1^{2^{2005}}\\equiv 1 (\\mod 3)$。 还有一些常用的性质： 若 $a\\equiv b (\\mod N)$且$M$整除$N$，则 $a\\equiv b(\\mod M)$。 $Proof$：设$a-b=k_1N$，由于$M$整除$N$，设$N=k_2M$，故$a-b=(k_1k_2)M$，即$a\\equiv b(\\mod M)$。▮ 若 $ac\\equiv bc(\\mod N)$且 $c,N$互质，则 $a\\equiv b(\\mod N)$。 $Proof$：$ac\\equiv bc(\\mod N)$等价于$(a-b)c\\equiv 0(\\mod N)$，表明$(a-b)c$整除$N$，由于$c,N$互质，所以$a-b$整除$N$，即$a\\equiv b(\\mod N)$。▮ 3. + - × 的模运算在模运算体系中计算 $x+y\\mod N$ 的复杂度是多少？$x, y$一定在 $0$ 到 $N-1$ 的区间中，它们的和一定在 $0$ 到 $2(N-1)$ 的区间中。若和超过 $N-1$，则需将结果减去 $N$。总复杂度应该为 $O(n)$，其中 $n=\\lceil \\log N \\rceil$。减法也是同理。 在模运算体系中计算 $xy\\mod N$ 的复杂度是多少？$x, y$ 一定在 $0$ 到 $N-1$ 的区间中，它们的积一定在 $0$ 到 $(N-1)^2$ 的区间中，至多有 $2n$ bits（$\\log (N-1)^2 \\leq 2n$）。若积超过 $N-1$，则需将结果除以 $N$，获取余数。总复杂度应该为 $O(n^2)$，其中 $n=\\lceil \\log N \\rceil$。 在模运算体系中如何计算除法结果？由于除法不具有加法和乘法的模运算性质，所以计算方法要复杂得多，后面再细讲。先提前透露一下复杂度，可以在 $O(n^3)$ 内完成。 4. 指数的模运算除了基本的四则运算，幂运算同样会使数字增长到很大，模运算如何解决这个问题？ 假设有正整数 $x$ 和 $y$，我们需要计算出 $x^y\\mod N$。仿照 $n-bit$ 乘法的实现，我们可以写出以下递归表达式： $$\\begin{equation}x^y=\\begin{cases}(x^{\\lfloor\\frac{y}{2}\\rfloor})^2, &amp; y为偶数 \\\\ x\\cdot (x^{\\lfloor\\frac{y}{2}\\rfloor})^2, &amp; y为奇数\\end{cases}\\end{equation}$$ 根据模运算的性质，在这里对任何中间结果取模再运算，与最后真实的结果是同余的： $$x^y\\equiv (x^{\\lfloor\\frac{y}{2}\\rfloor}\\mod N)\\cdot (x^{\\lfloor\\frac{y}{2}\\rfloor}\\mod N) (\\mod N)$$ $$x^y\\equiv (x\\mod N)\\cdot(x^{\\lfloor\\frac{y}{2}\\rfloor}\\mod N)\\cdot (x^{\\lfloor\\frac{y}{2}\\rfloor}\\mod N) (\\mod N)$$ 故可以用以下代码实现带模的幂运算（快速幂）： 1234567// N = 1337int modexp(int x, int y, int N) { if (y == 0) return 1; int z = modexp(x, y / 2, N); if (y % 2 == 0) return (z * z) % N; else return (x * z * z) % N;} 测试结果： 123456789101112131415161718modexp_test (N = 1337)Input integer x: 5Input integer y: 3Output: 125time = 0ms======================================modexp_test (N = 1337)Input integer x: 2Input integer y: 64Output: 408time = 0ms======================================modexp_test (N = 1337)Input integer x: 12345678Input integer y: 87654321Output: 911time = 1ms====================================== 上述代码在 $N=1337$ 时结果正确。但是如果 $N$ 足够大，运行结果仍然可能溢出：z*z或x*z*z有可能超出int的范围，可以利用模运算的性质中的推论进行进一步优化。在实际应用中，这段代码已经可以满足绝大多数计算需求了。 优化如下： 123456789101112131415// 乘法导致了modexp溢出，故这里使用快速乘取模，将结果进一步限制住int modmul(int x, int y, int N) { if (y == 0) return 0; int yy = modmul(x % N, y / 2, N); if (y % 2 == 0) return (2 * (yy % N)) % N; else return (x % N + (2 * (yy % N)) % N) % N;}// N &lt; (2^31 - 1) / 2int modexp(int x, int y, int N) { if (y == 0) return 1; int z = modexp(x % N, y / 2, N); if (y % 2 == 0) return modmul(z, z, N); else return modmul(x % N, modexp(x % N, y - 1, N), N);} 测试结果： 123456789101112modexp_test (N = 1000000007)Input integer x: 2Input integer y: 1000Output: 688423210time = 1ms======================================modexp_test (N = 1000000007)Input integer x: 100000001Input integer y: 123456789Output: 187658035time = 68ms====================================== 下面分析一下算法复杂度，设 $n$ 为 $x, y, N$ 中最大数的位数，最多进行 $n$ 次递归调用，每次需要做 $n-bit$ 乘法，故总复杂度为 $O(n^3)$。 Quick Link: 算法笔记整理","link":"/2021/12/23/2021-12-23-algorithms-notes-chap1-3-modular-arithmetic/"},{"title":"chap 1-4 数论算法-欧几里得算法","text":"1. 辗转相除法(Euclid’s algorithm)有了模运算，我们可以利用它解决不少关于数字的问题。其中，最为著名的问题当属求解两个数的最大公因数(gcd, greatest common divisor)。最容易想到的方法就是，先对两数分别做质因数分解（factoring），然后将它们相同的质因子相乘得到结果。如：$1035=3^3\\cdot 5\\cdot 23,759=3\\cdot 11\\cdot 23,gcd(1035,759)=3\\cdot 23=69$。不幸的是： 目前还没有足够高效的分解质因数的算法。 当数字非常大时，算法在有生之年内都不会运行完。有无更好的求解gcd的算法？2000年前其实就有了，叫做辗转相除法/欧几里得算法(Euclid’s algorithm)： 1234int euclid(int a, int b) { if (b == 0) return a; return euclid(b, a % b);} 测试结果： 123456789101112131415161718euclid_testInput the first integer a: 18Input the second integer b: 12gcd of a and b is: 6time = 2ms======================================euclid_testInput the first integer a: 56Input the second integer b: 128gcd of a and b is: 8time = 1ms======================================euclid_testInput the first integer a: 37Input the second integer b: 91gcd of a and b is: 1time = 1ms====================================== 证明上述代码的正确性，就是证明： 若 $a,b$都是正整数，且 $a\\geq b$，则 $gcd(a,b)=gcd(b,a\\mod b)$。（欧几里得法则） $Proof$: 设$d=gcd(a,b)$，则$a=k_1d,b=k_2d$，其中$k_1,k_2$互质。$a-b=(k_1-k_2)d$，$k_2$必定与$k_1-k_2$互质，易得$gcd(b,a-b)=gcd(a,b)$。重复这一步骤，就得到了：$gcd(a,b)=gcd(b,a\\mod b)$。假如$a&lt;b$，那么进行一次递归后，$a,b$将会互换位置，所以不需要比较大小。▮ 下面分析时间复杂度，就是要搞清楚每次$a\\mod b$到底使$a$减小了多少。可以证明出： 若 $a\\geq b$，则 $a\\mod b &lt; \\frac{a}{2}$。 $Proof$: 若$b\\leq\\frac{a}{2}$，则$a\\mod b &lt; b\\leq\\frac{a}{2}$；若$b&gt;\\frac{a}{2}$，则$a\\mod b=a-b&lt;\\frac{a}{2}$。▮ 由此可以推断：任意两次递归调用，$a,b$的值就会变为原来的一半（减小一位），假设初始的$a,b$都是$n$ bits，那么该算法需要进行$2n$次递归调用。每次调用进行取模操作（即$n-bit$除法），故总复杂度为$O(n^3)$。 2. 扩展欧几里得算法给定两个正整数$a,b$，我们可以运行Euclid’s algorithtm去计算它们的gcd。现在反过来，给定一个正整数$d$，如何验证$d$是否等于$gcd(a,b)$？下面的定理为我们提供了简便的方法： 若 $d$整除 $a$和 $b$，且存在整数 $x$和 $y$使 $d=ax+by$，则 $d=gcd(a,b)$。 $Proof$: $d$整除 $a$和 $b$，可以推出$d\\leq gcd(a,b)$；$d=ax+by$，可以推出$gcd(a,b)$整除$d$，表明$d\\geq gcd(a,b)$；综上，$d=gcd(a,b)$。▮ 普通的Euclid algorithm只能求出$d$，有没有方法同时把$x$和$y$也给求出来？扩展欧几里得算法可以做到： 12345function extended_euclid(a, b){ if b = 0: return (1, 0, a) (x', y', d) = extended_euclid(b, a mod b) return (y', x'-(a/b)y', d)} $Proof$: 乍一看有点乱，我们一步步分析。总体框架和普通欧几里得算法一致，把(a, b)变为(b, a mod b)；递归到最后一层时，返回a，也就是最终的d。到这里为止，与普通的欧几里得算法一模一样。 在最后一层递归时，易得$d=a\\cdot 1 + b\\cdot 0$，显然应该返回$x’=1,y’=0$。现在应该分析的就是，深层递归返回的$(x’,y’):gcd(b, a\\mod b)=bx’+(a\\mod b)y’$，与本层递归应该返回的$(x,y):gcd(a,b)=ax+by$，之间有何关系？下面是推导： $$d=gcd(a,b)=gcd(b,a\\mod b)=bx’+(a\\mod b)y’=bx’+(a-\\lfloor a/b\\rfloor b)y’=ay’+b(x’-\\lfloor a/b\\rfloor y’)$$ $$x=y’,y=x’-\\lfloor a/b\\rfloor y’$$ 综上，上述算法是正确的。▮ 举例说明上述算法的步骤，计算$gcd(48,27)$，先计算出$d$： $$gcd(48,27):\\underline{48}=1\\cdot\\underline{27}+21$$ $$gcd(27,21):\\underline{27}=1\\cdot\\underline{21}+6$$ $$gcd(21,6):\\underline{21}=3\\cdot\\underline{6}+3$$ $$gcd(6,3):\\underline{6}=2\\cdot\\underline{3}+0$$ $$gcd(3,0):d=3$$ 下面开始自下而上计算$x,y$： $$gcd(3,0):d=3=1\\cdot\\underline{3}+0,(x,y)=(1,0)$$ $$gcd(6,3):0=\\underline{6}-2\\cdot\\underline{3}=&gt;d=3=1\\cdot\\underline{6}-1\\cdot\\underline{3},(x,y)=(1,-1)$$ $$gcd(21,6):3=\\underline{21}-3\\cdot\\underline{6}=&gt;d=3=-1\\cdot\\underline{21}+4\\cdot\\underline{6},(x,y)=(-1,4)$$ $$gcd(27,21):6=\\underline{27}-1\\cdot\\underline{21}=&gt;d=3=4\\cdot\\underline{27}-5\\cdot\\underline{21},(x,y)=(4,-5)$$ $$gcd(48,27):21=\\underline{48}-1\\cdot\\underline{27}=&gt;d=3=-5\\cdot\\underline{48}+9\\cdot\\underline{27},(x,y)=(-5,9)$$ 最终得出$(x,y,d)=(-5,9,3)$。 该算法的复杂度与普通欧几里得算法一致，都是$O(n^3)$。 具体的代码实现： 12345678910void extended_euclid(int&amp; x, int&amp; y, int&amp; d, int a, int b) { if (b == 0) { x = 1; y = 0; d = a; return; } int xx; int yy; extended_euclid(xx, yy, d, b, a % b); x = yy; y = xx - (a / b) * yy;} 测试结果： 123456789101112131415161718extended_euclid_testInput the first integer a: 18Input the second integer b: 12(x, y, d): (1, -1, 6)time = 1ms======================================extended_euclid_testInput the first integer a: 56Input the second integer b: 128(x, y, d): (7, -3, 8)time = 1ms======================================extended_euclid_testInput the first integer a: 37Input the second integer b: 91(x, y, d): (32, -13, 1)time = 1ms====================================== 3. 除法的模运算铺垫了这么久，终于讲到了除法的模运算。如何进行除法的模运算？最容易想到的方法，除法就是乘法的逆运算： $$5\\cdot 6 \\mod 7=2=&gt;2/6 \\mod 7=5$$ 但是，这样做有可能会产生多个结果，如： $$10/5\\mod 15=2,5,8\\cdots$$ 这种情况下，我们就认为没有结果，类似于整数除法的除零操作。为了保证答案只有一个，类比倒数，我们不如直接定义： $$x/y\\equiv xy^{-1} (\\mod N)$$ 找到满足要求的$y^{-1}$就可以保证解唯一。在等式两边同乘$y$（$y$和$N$互质）： $$xyy^{-1}\\equiv x (\\mod N)$$ 可以推出： $$yy^{-1}\\equiv 1 (\\mod N)$$ 观察上面的推论，求解除法的模运算关键是要找到那个$y^{-1}$。我们定义： 若 $ax\\equiv 1(\\mod N)$，则称 $x$为 $a\\mod N$的乘法逆元（multiplicative inverse of $a$ modulo $N$）。 我们比较关注的第一个问题是：给定$a,N$，$a\\mod N$的乘法逆元是否一定存在？举例：$a=2,N=6$时，就不存在。先给出结论： $gcd(a,N)=1$时（互质），$a\\mod N$的乘法逆元存在；$gcd(a,N)&gt;1$时，则不存在。 $Proof$: $ax\\mod N=ax+kN$，则$gcd(a,N)$整除$ax\\mod N$。若$gcd(a,N)&gt;1$，$ax\\not\\equiv 1 (\\mod N)$。▮ 因此，只要$gcd(a,N)=1$，我们就可以求出$a\\mod N$的乘法逆元，如何求呢？ 回想一下扩展欧几里得算法，若把$a,N$作为输入，会求出$ax+Ny=d=1$。两边同时取模，得到$ax\\equiv 1 (\\mod N)$。令人惊讶的是，$x$就是$a\\mod N$的乘法逆元！（当然还有其他方法求解） 不过别急，这里求出的$x$是$a\\mod N$唯一的乘法逆元吗？实际上： 若$a\\mod N$的乘法逆元存在，则它是唯一的。 $Proof$: 反证法。假设$x_1\\not\\equiv x_2$，$ax_1\\equiv 1(\\mod N)$且$ax_2\\equiv 1(\\mod N)$，则$x_1\\equiv x_1\\cdot 1\\equiv x_1\\cdot ax_2 \\equiv ax_1\\cdot x_2\\equiv 1\\cdot x_2\\equiv x_2 (\\mod N)$，与$x_1\\not\\equiv x_2(\\mod N)$矛盾。▮ 综上所述，求解除法的模运算$a/b(\\mod N)$的步骤就是运行扩展欧几里得算法$(x,y,d)=extended-euclid(b,N)$，若$d&gt;1$，结果不存在；若$d=1$，输出$ax \\mod N$。复杂度为$O(n^3)$。 具体实现如下： 12345678910111213// by extended_euclidint get_multiplicative_inverse(int a, int N) { int x; int y; int d; extended_euclid(x, y, d, a, N); if (d != 1) return 0; // inverse not exist return x;}int mod_divide(int a, int b, int N) { int inverse_b = get_multiplicative_inverse(b, N); // 0 if inverse not exist, wrap around to 0~N-1 return inverse_b &lt; 0 ? (a * inverse_b) % N + N : (a * inverse_b) % N; } 测试结果： 123456789101112131415161718mod_divide_test (N = 1337)Input the first integer a: 5Input the second integer b: 2Output: 671time = 0ms======================================mod_divide_test (N = 1337)Input the first integer a: 29Input the second integer b: 9Output: 746time = 1ms======================================mod_divide_test (N = 1337)Input the first integer a: 3873587Input the second integer b: 45Output: 482time = 0ms====================================== Quick Link: 算法笔记整理","link":"/2021/12/24/2021-12-24-algorithms-notes-chap1-4-euclid-algorithm/"},{"title":"chap 1-2 数论算法-乘除法","text":"1. $n-bit$乘法的原理与实现小学的时候就学过乘法的竖式计算，二进制乘法步骤如下： 123456789 1 1 0 1 (13) × 1 0 1 1 (11)------------------------ 1 1 0 1 (1101×1) 1 1 0 1 (1101×1, shift left once) 0 0 0 0 (1101×0, shift left twice) + 1 1 0 1 (1101×1, shift left thrice)------------------------ 1 0 0 0 1 1 1 1 (143) 计算机硬件里乘法器的原理也是类似： 总结就是：$A$乘以$B$的第$k$位然后左移$k$位，作为部分积，最后累加所有部分积。这样做是否正确？ $Proof:$ 假设$N$和$M$是两个乘数，$M$为$k-bit$二进制整数，每一位为$b_k$，$M$可以被写做$M=b_0+2b_1+2^2b_2+\\cdots +2^kb_k$。那么，$N\\cdot M=Nb_0+2Nb_1+2^2Nb_2+\\cdots +2^kNb_k$，这符合上述步骤的结果。 该算法的复杂度是多少？观察竖式，每生成一行部分积，复杂度为$O(n)$；最后要进行$n-1$次部分积求和，故总复杂度为$O(n^2)$。 换一种视角看待乘法，我们其实可以用递归的形式来表达上述步骤： $$\\begin{equation}x\\cdot y=\\begin{cases}2(x\\cdot \\lfloor\\frac{y}{2}\\rfloor), &amp; y为偶数 \\\\ x+2(x\\cdot \\lfloor\\frac{y}{2}\\rfloor), &amp; y为奇数\\end{cases}\\end{equation}$$ $Proof:$ 若$y=2k$，则$2(x\\cdot \\lfloor\\frac{y}{2}\\rfloor)=2xk=xy$；若$y=2k+1$，则$x+2(x\\cdot \\lfloor\\frac{y}{2}\\rfloor)=x(2k+1)=xy$。▮ 递归表达式中，除以2的操作就是右移，乘以2的操作就是左移。本质上与竖式计算相同，只不过竖式计算是自上而下累加部分积，这里是自下而上累加部分积。 利用递归形式，我们可以很容易写出伪代码： 123456function multiply(x, y){ if(y = 0) return 0; z = multiply(x, y/2); if(y is even) return 2z; else return x + 2z;} 具体实现： 123456Binary multiply(const Binary&amp; x, const Binary&amp; y) { if (y.is_zero()) return get_zero(); Binary z = multiply(x, y.right_shift()); if (y.is_even()) return z.left_shift(); else return x + z.left_shift();} 测试结果： 123456789101112131415161718multiplication_testInput the first binary integer a: 11Decimal value of a: 3Input the second binary integer b: 110Decimal value of b: 6Output: 10010Decimal output: 18time = 1ms======================================multiplication_testInput the first binary integer a: 10101111101110Decimal value of a: 11246Input the second binary integer b: 101011Decimal value of b: 43Output: 1110110000011111010Decimal output: 483578time = 1ms====================================== 该递归算法的复杂度是多少？首先计算递归调用的次数，每次将$y$右移1位，所以总共调用$n$次，每次执行的复杂度为$O(n)$，故总复杂度仍然为$O(n^2)$。 是否存在更好的方法？确实存在，之后会详细介绍。 2. $n-bit$除法的原理与实现假设$x/y$，除法的本质就是找到商$q$和余数$r$，使$x=qy+r$，其中$r&lt;y$。 继续采用递归的形式实现算法： 假设$\\lfloor \\frac{x}{2}\\rfloor / y = (q, r)$，$x=2k$且$2r&lt;y$时，$x/y=(2q, 2r)$，若$2r\\geq y$，则$x/y=(2q+1, 2r-y)$； 当$x=2k+1$且$2r+1&lt;y$时，$x/y=(2q, 2r+1)$，若$2r+1\\geq y$，则$x/y=(2q+1, 2r+1-y)$； 写成伪代码就是： 123456789101112function divide(x, y){ if(x == 0) return (q, r)=(0, 0); (q, r) = divide(x/2, y); q = 2q; r = 2r; if(x is odd) r = r + 1; if(r &gt;= y){ r = r - y; q = q + 1; } return (q, r);} 具体实现： 1234567891011121314pair&lt;Binary, Binary&gt; divide(Binary&amp; x, Binary&amp; y) { if (x.is_zero()) return make_pair(get_zero(), get_zero()); pair&lt;Binary, Binary&gt; res = divide(x.right_shift(), y); Binary q = res.first; Binary r = res.second; q = q.left_shift(); r = r.left_shift(); if (x.is_odd()) r = r + get_one(); if (r &gt; y || r == y) { r = r - y; q = q + get_one(); } return make_pair(q, r);} 算法的复杂度与乘法类似，都是$O(n^2)$。 Quick Link: 算法笔记整理","link":"/2021/12/22/2021-12-22-algorithms-notes-chap1-2-multiplication-division/"},{"title":"chap 1-5 数论算法-素数","text":"1. 费马素性测试-1上一章提到过两数互质的问题，质数（素数）一直以来都是数论中的重点内容。一个基本问题就是：如何判断一个数是否为素数？最容易想到的方法：将这个数做质因数分解，若因数只有1和它本身，则为素数，但是质因数分解效率很低；另一种方法是，依次判断是否有比它小的数整除它，本质上还是质因数分解。下面要介绍的一种高效的素性测试方法，基于一个重要的定理： 费马小定理(Fermat’s little theorem)： 若 $N$为素数，则对于任意 $1\\leq a &lt; N$，都有 $a^{N-1}\\equiv 1(\\mod N)$成立。 $Proof$：设集合$S$为非零整数模$N$(素数)的完全剩余系，即$S$ = {$b_1,b_2,\\cdots,b_{N-1}$}，其中$b_i=i$。设$a$为一个正整数，则可以证明 {$ab_1\\mod N, ab_2\\mod N, \\cdots, ab_{N-1}\\mod N$} 仍然等价于$S$：反证法，假设存在$ab_i\\equiv ab_j(\\mod N),b_i\\neq b_j$，由于$a$与$N$互质，可以推出$b_i\\equiv b_j(\\mod N)$，矛盾，故结论成立。 综上所述：$S$ = {$1,2,\\cdots,N-1$} = {$a\\cdot 1\\mod N, a\\cdot 2\\mod N, \\cdots, a\\cdot (N-1)\\mod N$}，把它们所有的元素相乘得到：$(N-1)!\\equiv a^{N-1}\\cdot (N-1)! (\\mod N)$。又因为$(N-1)!$与$N$互质，可以推出$a^{N-1}\\equiv 1(\\mod N)$。▮ 利用费马小定理，再加上有很快的快速幂取模算法，我们可以设计出下面这个似乎合理的素性测试方法（判断输入$N$是否为素数）： 1234567bool primality(int N) { if (N == 1) return false; // pick a positive integer &lt; N at random int a = rand() % (N - 1) + 1; if (modexp(a, N - 1, N) == 1) return true; else return false;} 仔细分析一下，若$N$确实为素数，则对于所有的$1\\leq a &lt; N$都应该能通过测试，这没问题。但是，如果$N$为合数，是否一定意味着所有的$1\\leq a &lt; N$都不能通过测试？答案是否定的，$N$为合数时，仍然存在$1\\leq a &lt; N$能通过测试。这说明这里的算法有一定概率失败，即在$N$为合数的情况下，输出$N$为素数（伪素数）。那是否能把失败的概率降到最低？ 2. 费马素性测试-2既然当$N$为合数时，一部分$a$通过测试，一部分不通过，而且只要存在不通过的，说明$N$肯定是合数，那么我们可以多进行几次上述测试，使失败概率降低： 123456789// k=100bool primality2(int N) { if (N == 1) return false; for (int i = 0; i &lt; 100; ++i) { int a = rand() % (N-1) + 1; if (modexp(a, N - 1, N) != 1) return false; } return true;} 失败的概率具体是多少呢？ 假设整数$a(1\\leq a &lt; N)$与$N$互质，且$a^{N-1}\\not\\equiv 1(\\mod N)$，$a$将无法通过测试。假设有若干整数$b(1\\leq b &lt; N)$满足$b^{N-1}\\equiv 1(\\mod N)$即能通过测试，那么： $$(a\\cdot b)^{N-1}\\equiv a^{N-1}\\cdot b^{N-1}\\equiv a^{N-1}\\not\\equiv 1 (\\mod N)$$ 说明，只要存在一个通过测试的$b$，就必存在一个无法通过测试的$a\\cdot b$。那这些$a\\cdot b \\mod N$是否相等？固定$a$不变，选择不同的$b$，显然$ab_i\\not\\equiv ab_j (\\mod N)$。由此我们得到结论：无法通过测试的元素个数$\\geq$通过测试的元素个数，即最多只有一半的元素能通过测试。 从群论的角度也能证明这个结论。所有模$N$后还与$N$互质的正整数构成了乘法群$Z_N$，集合$B$ = {$b:b^{N-1}\\equiv 1 (\\mod N)$}是$Z_N$的子群，说明$B$中的元素个数一定整除$Z_N$的元素个数。若$B$不含有$Z_N$的所有元素，那么$B$最多含有$|Z_N|/2$个元素。 这个结论说明了以下事实： $$Pr(primality(N)=true,N=prime)=1$$ $$Pr(primality(N)=true,N\\neq prime)\\leq \\frac{1}{2}$$ 所以改进后的$primality2(N)$的失败概率为： $$Pr(primality2(N)=true,N\\neq prime)\\leq \\frac{1}{2^k}$$ 若多次测试的次数$k=100$，那么该算法失败的概率最多为$2^{-100}$，可以认为不可能失败。 3. Miller-Rabin 素性测试上述关于概率的推导存在一个前提：假设整数$a(1\\leq a &lt; N)$与$N$互质，且$a^{N-1}\\not\\equiv 1(\\mod N)$。但是有一类数，很少但是存在，叫做Carmichael数，它的特点是：对于所有与$N$互质的整数$a(1\\leq a &lt; N)$，$a^{N-1}\\equiv 1(\\mod N)$，比如561。对这些数进行费马素性测试，将无法保证上述$\\frac{1}{2^k}$的错误率。 有一种叫Miller-Rabin素性测试的算法可以解决这个问题。假设需要被测试的整数为$N$，则$N-1$可以被表示为$2^tu$的形式。计算下面的序列： $$a^u\\mod N,a^{2u}\\mod N,\\cdots,a^{2^tu}=a^{N-1}\\mod N$$ 若$a^{N-1}\\not\\equiv 1(\\mod N)$，根据费马小定理，$N$一定是合数；但是如果$a^{N-1}\\equiv 1(\\mod N)$，$N$有可能是伪素数，需要进行下面的检验：在上述序列中，如果存在某个元素（非第一个）的值等于1但是它前一个元素的值不等于$(-1)\\mod N$（即$N-1$），那么$N$就是合数。 $Proof$：假设$x^2=1+kN$，则$(x+1)(x-1)=kN$，说明$x\\pm1\\equiv 0 (\\mod N)$，即$x\\equiv\\pm 1(\\mod N)$。这里的$x^2$就是上述等于1的元素，$x$为它前一个元素。▮ 实际上，Miller-Rabin素性测试就是在费马素性测试中加入了额外的检测。代码如下： 123456789101112131415161718192021222324252627282930// Miller-Rabinbool primality3(int N) { if (N == 1) return false; for (int i = 0; i &lt; 50; ++i) { int a = rand() % (N - 1) + 1; int t = 0; int u = N - 1; while (u % 2 == 0) { u /= 2; t++; } int prev = -1; int curr = modexp(a, u, N); int val = 0; for (int i = 0; i &lt; t; ++i) { prev = curr; curr = modexp(curr, 2, N); if (curr == 1 &amp;&amp; prev == -1) val = prev; } if (curr != 1) return false; else { if (val == N - 1) return false; } } return true;} 查阅相关证明，可知对于所有的$N$（包含Carmichael number）： $$Pr(primality3(N)=true,N\\neq prime)\\leq \\frac{1}{4^k}$$ 错误率比以前更低，时间复杂度为$O(kn^3)$。这也是实际应用中，比较常用的素性检测方法。 4. 生成随机素数由于素数的诸多性质，很多算法会提前建立好素数表，那么该如何高效地生成$n-bit$素数呢？一个简单的想法就是：随机取一个数，进行素性测试，若通过测试则输出；若不通过，则重复以上过程。 12345int gen_random_prime(int lb, int ub) { int N = rand() % (ub - lb) + lb; while(!primality3(N)) N = rand() % (ub - lb) + lb; return N;} 测试结果： 1234567891011121314151617gen_random_prime_testInput the lower bound: 1Input the upper bound: 100Input the num of primes: 10Primes generated:1761131117737534783time = 6ms====================================== 比较棘手的问题是，我们不确定会重复多少次素性测试，那该如何分析这个算法的复杂度？借助下面的定理： 拉格朗日素数定理： 设 $\\pi (x)$为$\\leq x$的素数的个数，则$\\pi (x)\\approx x/\\ln x $，或 $\\lim\\limits_{x\\to+\\infty}\\frac{\\pi(x)}{x\\ln x}=1 $。 可以推出：$n-bit$的所有数中随机取一个，大约有$p=\\frac{1}{n}$的概率是素数。令随机变量$X$表示该算法需要执行循环的次数，则： $$E[X]=\\sum_{i=1}^{\\infty}i\\cdot P[X=i]=\\sum_{i=1}^{\\infty}i\\cdot (1-p)^{i-1}p=p\\cdot \\frac{d}{dp}(\\sum_{i=1}^{\\infty}-(1-p)^i)=p\\cdot \\frac{1}{p^2}=\\frac{1}{p}$$ 注意到$p=\\frac{1}{n}$，则该算法平均需要$O(n)$次循环之后停止，故平均复杂度是$O(kn^4)$。这种情况下，算法执行的computer steps不确定，故只能求出平均的step。 5. 随机算法本章所讲的算法都具有一定的随机性。令人惊讶的是，对于一些问题的求解，最快的算法都是随机化的。我们不需要算法一定输出正确的结果，我们只需要算法以高概率输出正确结果。 随机算法一般分为两类： Las Vegas算法：永远输出正确的结果。如生成随机素数。 Monte Carlo算法：输出有出错的概率。如素性测试。 随机算法在很多方面都有应用（后面会讲到）：Hashing、排序、中位数、min-cut问题等等。 Quick Link: 算法笔记整理","link":"/2021/12/26/2021-12-26-algorithms-notes-chap1-5-primality-test/"},{"title":"chap 1-6 数论算法-密码学","text":"1. 密码学简介数论算法应用最广泛的领域之一就是密码学，密码学也是网络安全的重要研究分支。密码学研究的主要问题可以用以下情境描述：Alice和Bob二人想要进行私密通信，但是Eve想要偷听他们的私密通信。Alice和Bob为了保证私密性，他们决定对消息进行加密和解密（编码和译码）： Alice把消息$x$编码为$e(x)$，然后发送消息；Eve可以在半路中截获$e(x)$；Bob收到加密消息$e(x)$后，使用解密函数$d(\\cdot)$译码，即$d(e(x))=x$。最理想的效果是，只要不知道$d(\\cdot)$就无法破解出$x$。 密码学主要分为两个体系：私钥（private-key）体系和公钥（public-key）体系。 私钥的主要思想是：Alice和Bob提前确定好一个密码本（codebook），加密和解密都根据密码本上面（原文，译文）一对一的关系进行。这里的密码本就是私钥。 公钥的主要思想是：Bob把自己的公钥公布于众，自己保留一个secret-key。Alice利用公钥加密消息发给Bob。Bob利用secret-key可以轻松地解密，Eve由于不知道secret-key，在某些条件成立的情况下基本不可能解密。 2. 一次性密钥与AES算法一次性密钥（one-time pad）和AES（Advanced Encryption Standard）算法都是私钥体系的典型代表。 在一次性密钥算法中，Alice和Bob提前商量好了一个$n-bit$二进制串$r$，Alice加密消息时使用下面的函数： $$e_r(x)=x\\oplus r$$ $\\oplus$为异或操作，假设$r=01110010$，则$e_r(11110000)=11110000\\oplus 01110010=10000010$。 Bob收到加密消息$y$时，使用如下的函数解密： $$d_r(e_r(x))=e_r(x)\\oplus r= (x\\oplus r)\\oplus r=x\\oplus (r \\oplus r)=x\\oplus 0=x$$ 如何选取$r$？每次传输消息的时候，随机选取就行，这就保证了Eve截获了$e_r(x)$后无法判断$x$的值，因为$x$可能是任何值。 每传一次消息，需要换一次$r$吗？确实需要，这也是一次性密钥算法的缺点。如果Eve知道了每次的$r$不会变，他就可以截获多个$e_r(x)$，推断出$x$的一些特性；若截获的数量很多，甚至可以直接推出$r$的值。因此，一次性密钥算法要求Alice和Bob再每次传输消息前，都要事先协商好$r$的值。 AES算法可以说是“永久性”密钥算法。AES使用了一个128位（也有其他位数）的私钥$r$，Alice和Bob之前需要协商好。与一次性密钥不同的是，AES使用的加密函数利用$r$（消息可以被截断成多个128位的片段），对每个消息片段进行了多次变换，很难通过截获的$e(x)$获取任何关于$x$和$r$的信息，故私钥$r$可以被重复使用。至少在目前，除了一个个试$r$的值，还没有找到合适的破解方法。 代码实现（一次性密钥）： 1234567int naive_AES_encode(int x, int r) { return x ^ r;}int naive_AES_decode(int y, int r) { return y ^ r;} 3. RSA算法RSA算法与上面的算法不同，它属于公钥体系。RSA的原理使用了非常多数论的知识，前几章提到的各种算法现在终于能大展身手了！ 假设Alice发给Bob的消息是一个数字$x\\mod N$后的值（$x$大于$N$就把消息分割成小片段，使其小于$N$），随机选取两个素数$p$和$q$，令$N=pq$，令$e$为任意与$(p-1)(q-1)$互质的一个数，那么有以下性质成立： $x\\to x^e\\mod N$的映射关系是在集合{ $0,1,\\cdots, N-1$ }上的双射（一一对应）。 逆映射：令 $d$为 $e\\mod (p-1)(q-1)$的乘法逆元，则 $(x^e)^d\\equiv x (\\mod N)$。 $Proof$：先证明第二个性质。$d$为 $e\\mod (p-1)(q-1)$的乘法逆元，即$ed\\equiv 1 (\\mod (p-1)(q-1))$，可以把$ed$表示为$1+k(p-1)(q-1)$。根据费马小定理：$x^{p-1}\\equiv 1 (\\mod p)$成立，而$p$能整除$N$，可以推出：$x^{p-1}\\equiv 1 (\\mod N)$；同理，$x^{q-1}\\equiv 1 (\\mod N)$。所以，$x^{ed}-x\\equiv x^{1+k(p+1)(q+1)}-x\\equiv x-x\\equiv 0 (\\mod N)$，即$(x^e)^d\\equiv x (\\mod N)$。第二个性质成立，说明映射可逆，证明了第一个性质也成立。▮ 利用上述性质，设计出RSA加密算法： Bob公布public-key，保留secret-key： 选择两个大的$n-bit$随机素数$p$和$q$。 公布public-key$(N,e)$，其中$N=pq$，$e$为任意$2n-bit$的与$(p-1)(q-1)$互质的数。通常选取$e=3$，算的会快一些。 保留secret-key $d$，$d$为$e\\mod (p-1)(q-1)$的乘法逆元。 Alice发送消息$x$给Bob： 使用Bob公布的public-key$(N,e)$，发送$y=x^e\\mod N$。 Bob使用secret-key $d$解密： 计算出$y^d\\mod N$。 现在邪恶的Eve想要破解出$x$。给定$N,x$，截获了$y=x^e\\mod N$，有可能计算出$x$吗？两种方法：第一种是穷举$x$，判断$y=x^e\\mod N$是否成立，但复杂度为指数级，$n-bit$很大时，无法算出。第二种是猜出$p$和$q$，从而获取$d$。但是，$N$为一个很大的数，对大数进行质因数分解非常困难，复杂度也是指数级，故也无法算出。 总结来说，RSA能够成为最常用的加密算法，基于的前提是：目前没有高效的质因数分解算法。 对比AES算法，RSA算法虽然安全性极高，但是开销同样很大。实际应用时，常常是先用RSA算法加密传输私钥，然后使用AES算法利用私钥通信，因为AES的开销要小得多。 RSA的代码实现： 12345678910111213141516171819pair&lt;int, int&gt; gen_public_key(int p, int q) { int N = p * q; int e = 3; return make_pair(N, e);}int gen_private_key(int e, int p, int q) { int d = get_multiplicative_inverse(e, (p - 1) * (q - 1)); return d &lt; 0 ? d + (p - 1) * (q - 1) : d;}// x &lt; Nint naive_RSA_encode(int x, int N, int e) { return modexp(x, e, N);}int naive_RSA_decode(int y, int N, int d) { return modexp(y, d, N);} 测试结果： 123456789101112131415161718naive_RSA_testInput an integer x as a message: 12345Pick two large random primes: (10601, 19763)Public key: (209507563, 3)Private key: 139651467Encoded: 197555448Decoded: 12345time = 29ms======================================naive_RSA_testInput an integer x as a message: 73658734Pick two large random primes: (10601, 19763)Public key: (209507563, 3)Private key: 139651467Encoded: 183414919Decoded: 73658734time = 28ms====================================== Quick Link: 算法笔记整理","link":"/2021/12/27/2021-12-27-algorithms-notes-chap1-6-cryptography/"},{"title":"chap 1-7 数论算法-全域哈希","text":"1. 哈希表数论算法在哈希函数的设计方面也有应用。假设在编写网络服务应用时，我们需要维护一个动态变化的客户的IPv4地址的list，如何快速地查询某个IP呢？一个最快的方法是建立大小为$2^{32}$的array，以IP作为index。虽然很快，但是会非常浪费内存，大多数内存可能都是空的。还有一个方法是使用链表，但是查询速度很慢，与客户个数成正比。使用哈希的方法能使占用内存的大小与客户数量成正比，同时获得较快的查询速度。 最常用的结构是Hash Table。假设现在有250个客户IP，我们可以建立一个大小为250的array作为哈希表。定义一个哈希函数$h(x)$，输入为客户的IP，输出为array的index值，该IP的具体信息存储在array[index]中。如果多个IP映射到同一个index怎么办（即碰撞）？那就把array每个元素改造成一个链表，同时存储多个IP，即每个元素都是一个bucket，里面装着若干个IP。故该算法的效率在最差的情况下，取决于一个bucket里面装了多少个IP。而IP映射到哪个bucket，是由哈希函数$h(x)$决定的。所以我们希望$h(x)$满足：无论$x$服从哪种概率分布，任意两个$h(x)$碰撞的概率都相等，即每个bucket里面装的IP都一样多。 不幸的是，如果我们只使用固定的一个$h(x)$，就不可能达到上述理想的效果，因为我们总能根据已知的若干$x$构造出一个$h(x)$使它们都被映射到同一个bucket中。 2. 哈希函数族办法总比困难多，我们可以使用随机来中和掉输入分布的影响，那就是定义一组哈希函数，每次运行应用时，随机选用一个哈希函数，希望在平均意义上能达到理想效果。我们还是以IP为例，假设每个IP地址可以表示为$x=(x_1,x_2,x_3,x_4)$，$x_i$为0~255范围上的整数；假设有250个客户IP，令$n$为稍大于客户IP总数的一个素数，作为哈希表中bucket的数量。我们可以定义如下的哈希函数： $$h_a(x_1,x_2,x_3,x_4)=\\sum_{i=1}^4 a_ix_i\\mod n$$ 其中，$a_i\\in$ {$0,1,\\cdots, n-1$}。若每次随机挑选一组$a=(a_1,a_2,a_3,a_4)$组成哈希函数，那么在平均意义上，任意两个$x$冲突的概率为$\\frac{1}{n}$： 假设$n$为素数，有整数 $x$，把$x$表示为 $x=(x_1,x_2,\\cdots,x_k)$，使 $x_i\\in$ { $0,1,\\cdots, n-1$ }；同理，$y$（$y\\neq x$）也可以被表示为 $y=(y_1,y_2,\\cdots,y_k)$，使 $y_i\\in$ { $0,1,\\cdots, n-1$ }；若系数为 $a=(a_1,a_2,\\cdots,a_k)$，且每个 $a_i$都是从 { $0,1,\\cdots, n-1$ } 中等概率随机选取的，那么： $$Pr[h_a(x_1,x_2,\\cdots,x_k)=h_a(y_1,y_2,\\cdots,y_k)]=\\frac{1}{n}$$ $Proof$：$h_a(x_1,x_2,\\cdots,x_k)=h_a(y_1,y_2,\\cdots,y_k)$等价于$\\sum_{i=1}^k a_ix_i\\equiv \\sum_{i=1}^k a_iy_i (\\mod n)$，即： $$\\sum_{i=1}^{k-1} a_i(x_i-y_i)\\equiv a_k(y_k-x_k) (\\mod n)$$ 上述等式何时成立？假设我们已经随机选取了$a_{1:k-1}$的值，那么等式左边的值$c=\\sum_{i=1}^{k-1} a_i(x_i-y_i)$就已经固定，所以只需要$a_k=c\\cdot (y_k-x_k)^{-1}\\mod n$，等式就会成立（$c$和$y_k-x_k$必与$n$互质，$c$可以被约掉，$y_k-x_k$的乘法逆元也一定存在）。由于$a_k$是随机选取的，所以$a_k$恰好为$c\\cdot (y_k-x_k)^{-1}\\mod n$的概率为$\\frac{1}{n}$，此时等式成立。故等式成立的概率为$\\frac{1}{n}$。▮ 综上，我们证明出了，使用随机选取的$h_a$，任意两个输入冲突的平均概率为$\\frac{1}{n}$；换句话说，设所有可能取到的$h_a$的总数为$|H|$，那么有$|H|/n$个$h_a$能把不同的$x$映射到同一个bucket。 现在假设有$m$个不同的数需要被填到哈希表中，$n$为略大于$m$的素数；假设随机变量$Y_i$（$1\\leq i \\leq m$）表示第$i$个数是否与固定的一个数$x$冲突，冲突则等于1，不冲突则等于0；根据上面的结论，可以得到：$E[Y]=\\frac{1}{n}$。显然，$Y=Y_1+Y_2+\\cdots+Y_m$表示所有与$x$冲突的数的个数，则$E[Y]=E[Y_1+Y_2+\\cdots+Y_m]=\\frac{m}{n}$。所以，使用这个方法，能够在平均意义上，使 “$h(x)$满足：无论$x$服从哪种概率分布，任意两个$h(x)$碰撞的概率都相等，即每个bucket里面装的IP都一样多。” 一组哈希函数$h(x)$，被称为一个哈希函数族$H$。若该哈希函数族满足： 对于任意两个不同的输入 $x$和 $y$，恰好有 $|H|/n$个哈希函数把 $x$和 $y$映射到同一个bucket中（$n$为bucket的数量），则称这个哈希函数族具有全域哈希性（universal）。 换句话说，全域哈希性表明，对于任意两个输入，如果从函数族里随机选取一个哈希函数做映射，那么在平均意义上讲（in expectation），它们冲突的概率为$\\frac{1}{n}$。这就等价于把$x$和$y$随机放入bucket中。总结就是：全域哈希插入、查询的平均性能较好。 在应用中使用全域哈希的步骤： 把输入$x$分割成$k$个部分，令$n$为稍大于每个部分最大值的素数。 全域哈希函数族为：$H=$ {$h_a:a\\in$ {$0,1,\\cdots,n-1$}$^k$}。 从上述函数族中随机选取一个$h_a$作为哈希函数。 Quick Link: 算法笔记整理","link":"/2021/12/28/2021-12-28-algorithms-notes-chap1-7-universal-hashing/"},{"title":"chap 1-8 数论算法-综合应用","text":"1. Divisible?$4^{1536}-9^{4824}$是否能被35整除？ $35=5\\times 7$，根据费马小定理：$a^{5-1}\\equiv 1 (\\mod 5)$，$a^{7-1}\\equiv 1(\\mod 7)$，由于5和7都是素数，易得：$a^{(5-1)(7-1)}\\equiv 1(\\mod 35)$，即$a^{24}\\equiv 1(\\mod 35),1\\leq a&lt;35$。因此$4^{1536}-9^{4824}\\equiv 4^{24\\cdot 64}-9^{24\\cdot 201}\\equiv 1-1(\\mod 35)$，故$4^{1536}-9^{4824}$能被35整除。 2. “快速”幂计算$x^y$时，假设我们想要最终的真实结果（不取模），有两种计算方法，第一种是使用迭代法： $$x\\to x^2\\to x^3\\to \\cdots\\to x^y$$ 依次累乘，直至计算出最终结果。第二种方法是递归分治（快速幂）： $$x\\to x^2\\to x^4\\to x^8\\to \\cdots\\to x^y$$ 哪种方法会更快呢？假设$x$的位数为$n$，则第一种方法的时间复杂度为： $$O(n\\cdot n+n\\cdot 2n+n\\cdot 3n + \\cdots + n\\cdot (y-1)n)=O(n^2\\cdot \\frac{y(y-1)}{2})=O(n^2y^2)$$ 第二种方法的时间复杂度为： $$O(n\\cdot n+2n\\cdot 2n+2^2n\\cdot 2^2n + \\cdots +(2^2)^{\\lfloor\\log y\\rfloor-1}n^2)=O(n^2\\cdot \\frac{(2^2)^{\\lfloor\\log y\\rfloor}-1}{3})=O(n^2y^2)$$ 对比可以发现，若考虑算术运算的复杂度，两种方法的总时间复杂度其实是同阶的。 3. 相邻的斐波那契数两个相邻的斐波那契数一定互质吗？ 使用数学归纳法，$n=1$时，$gcd(F_2,F_1)=1$；假设$n\\leq k$时，$gcd(F_{k+1},F_{k})=1$；则$n=k+1$时，$gcd(F_{k+2},F_{k+1})=gcd(F_{k+1},F_{k+2}-F_{k+1})=gcd(F_{k+1},F_{k})=1$。 故两个相邻的斐波那契数一定互质。 4. 加法器使用行波进位加法器实现两个$n-bit$整数的加法，电路的深度为$O(n)$。 若使用超前进位加法器实现两个$n-bit$整数的加法（并行化），电路的深度将减少为$O(\\log n)$。（减少了延迟） 若使用超前进位加法器实现$m$个$n-bit$整数的加法（每两个一组），电路的深度最少为$O((\\log m)(\\log n)$。 5. 阶乘设$N$为一个$n-bit$的正整数，则$N!$大约有多少位？之前证明过，$\\log(N!)=\\Theta(N\\log N)$，也可以通过Stirling公式推出： $$\\log(N!)=\\sum_{k=1}^{N}\\log k=\\log(\\sqrt{2\\pi N}(\\frac{N}{e})^N)=\\Theta(N\\log N)$$ 设计一个计算阶乘的算法： 1234factorial (N) f = 1 for i = 2 to N f = f * i 算法的时间复杂度： $$O(\\sum_{i=1}^N i\\log i\\cdot\\log i)=O((\\log N)^2\\sum_{i=1}^N i)=O((N\\log N)^2)=O((N\\cdot n)^2)$$ 6. 乘方若一个$n-bit$的正整数$N&gt;1$能够被表示为$q^k$（$q,k$为正整数，且$k&gt;1$），则$N$被称为是一个乘方数。如何设计一个算法，判断$N$是否为乘方数？ 先确定$k$的范围，$N=q^k$即$k=\\log N/\\log q$，推出$1&lt;k\\leq \\log N$。对于每个$k$，我们可以使用二分法判断$q\\in [2, N]$是否满足$q^k=N$，二分法共需$O(\\log N)=O(n)$次，每次需要计算乘方$q^k$，复杂度为$O(k^2n^2)$，故总复杂度为$O(\\log N \\cdot n \\cdot k^2n^2)=O(n^6)$。 7. lcm与gcd$lcm(x,y)$（least common multiple）表示$x,y$的最小公倍数。有如下结论成立： $$gcd(x,y)\\cdot lcm(x,y)=x\\cdot y$$ $Proof$： 设$x=p_1^{a_1}\\cdot p_2^{a_2}\\cdot p_3^{a_3}\\cdots p_k^{a_k}$，$y=p_1^{b_1}\\cdot p_2^{b_2}\\cdot p_3^{b_3}\\cdots p_k^{b_k}$，$p_k$为素数， 则$gcd(x,y)=p_1^{\\min(a_1,b_1)}\\cdot p_2^{\\min(a_2,b_2)}\\cdot p_3^{\\min(a_3,b_3)}\\cdots p_k^{\\min(a_k,b_k)}$， $lcm(x,y)=p_1^{\\max(a_1,b_1)}\\cdot p_2^{\\max(a_2,b_2)}\\cdot p_3^{\\max(a_3,b_3)}\\cdots p_k^{\\max(a_k,b_k)}$， 易得：$gcd(x,y)\\cdot lcm(x,y)=p_1^{a_1+b_1}\\cdot p_2^{a_2+b_2}\\cdot p_3^{a_3+b_3}\\cdots p_k^{a_k+b_k}=x\\cdot y$。▮ 8. Wilson定理Wilson定理也能够被用来判断素数： Wilson定理：$N$为素数，当且仅当 $(N-1)!\\equiv -1(\\mod N)$。 $Proof$： 若$N$为素数，则对于所有$1\\leq x&lt;N$，$x\\mod N$的乘法逆元均存在（双射关系）。设$x^2\\equiv 1(\\mod N)$，推出$x\\equiv 1$或$x\\equiv N-1 (\\mod N)$，说明$1$和$N-1$的乘法逆元是自身。由此可得：$(N-2)\\cdot(N-1)\\cdots 2\\equiv 1(\\mod N)$，即$(N-1)!\\equiv N-1\\equiv -1(\\mod N)$。 若$N$不是素数，假设$(N-1)!\\equiv -1(\\mod N)$仍成立，令$(N-1)!=-1+kN$，即$1=-(N-1)!+kN$，说明$gcd((N-1)!,N)=1$，显然不成立。故若$N$不是素数，$(N-1)!\\not\\equiv -1(\\mod N)$。▮ 对比费马小定理，如果使用Wilson定理进行素性测试，将不会出错，那为何不这样做呢？主要原因就是Wilson定理需要计算阶乘，而计算阶乘的复杂度太高，不适合对大数进行运算。 9. 中国剩余定理假设$p,q$为两个不同的互质的数，那么对于每对$(j,k)$（$0\\leq j&lt;p,0\\leq k&lt;q$），都存在一个唯一的整数$0\\leq i&lt;pq$使得$i\\equiv j(\\mod p)$，且$i\\equiv k(\\mod q)$： $$i=[j\\cdot q\\cdot (q^{-1}\\mod p)+k\\cdot p\\cdot(p^{-1}\\mod q)]\\mod pq$$ $Proof$：上述等式易证，下面证明唯一性，反证法。假设存在两个不同的$i,i’$满足上述条件，则$i=Ap+j=Bq+k,i’=Cp+j=Dq+k$，$i-i’=(A-C)p=(B-D)q$，表明$p$整除$B-D$，$q$整除$A-C$。推出$i-i’\\equiv 0(\\mod pq)$，与假设矛盾。故原结论成立。▮ 推广至一般情况，中国剩余定理其实提供了一元同余线性方程组有解的判定条件，以及通解的形式： $$\\begin{equation}\\begin{cases}x\\equiv a_1(\\mod p_1) \\\\ x\\equiv a_2(\\mod p_2) \\\\ \\vdots \\\\ x\\equiv a_n(\\mod p_n)\\end{cases}\\end{equation}$$ 若方程组中的$p_{1:n}$都互质，则对于任意整数$a_{1:n}$，该方程组都有解，通解为： $$x=[\\sum_{k=1}^N a_k \\cdot P_k \\cdot (P_k^{-1}\\mod p_k)]\\mod\\prod_{k=1}^N p_k, 其中P_k=\\prod_{i=1,i\\neq k}^N p_i$$ 10. 被素数整除把一个正整数$n$从右至左分成几组，每组有$r$个数字，假设$p$为非2和5的素数，若能通过判断$p$是否能整除几组数字之和，来推出$p$是否能整除$n$ ，那么$r$一定是$p-1$的因子。比如$n=1716,p=11$时，令$r=2$，1716可分为两组：(16,17)，16+17=33能被11整除，那么1716一定能被11整除，此时$r$也是$p-1$的一个因子。（大家一定都用过$p=3,r=1$的情况） $Proof$：假设整数$N$被分为了$k$组：$N_kN_{k-1}\\cdots N_1$，则$N=N_1+N_210^r+\\cdots+N_k(10^r)^{k-1}$，所有组数字之和为$N_1+N_2+\\cdots+N_k$。若$N_1+N_210^r+\\cdots+N_k(10^r)^{k-1}\\equiv N_1+N_2+\\cdots+N_k (\\mod p)$，那么需要满足$10^r\\equiv 1(\\mod p)$。由费马小定理可知，$10^{p-1}\\equiv 1(\\mod p)$，故$r$为$p-1$的因子。▮ 11. $a^{b^{c}}\\mod p$设$p$为素数，计算$a^{b^{c}}\\mod p$。 利用费马小定理，$a^{b^{c}}\\mod p=a^{b^{c}\\mod (p-1)}\\mod p$，然后使用快速幂。 12. “破译”RSA(1) 假设在RSA算法中，令$N=p$，$e$为与$p-1$互质的整数，$d$为$e\\mod p-1$的逆元，加密算法为$x^e\\mod p$，解密算法为$(x^e)^d\\mod p$。截获了$x^e\\mod p$，是否有方法破译？ 直接计算$d$的值即可，然后解密。 (2) 假设在RSA算法中，Alice的secret-key $d$的值泄露，Eve是否能借助$d$值求出$p,q$？ 由$ed\\equiv 1(\\mod(p-1)(q-1))$得：$ed=1+k(p-1)(q-1)$，而$N=pq,d&lt;(p-1)(q-1)$，通过试探$k$可以解出$p,q$。 (3) Alice使用RSA算法，给她的三位朋友（$(N_i,e_i=3),N_i=p_iq_i$）发送了相同的消息$M$，然后都被Eve截获了：$M^3\\mod N_1,M^3\\mod N_2,M^3\\mod N_3$，该消息有被破译的风险吗？ 令$x=M^3$，运用中国剩余定理可知，$x&lt;N_1\\cdot N_2\\cdot N_3$存在且唯一，可以直接套用公式解出，解出$M^3$后开立方即得到$M$。 13. RSA数字签名Alice和Bob使用RSA加密算法传递消息可以确保消息不会被Eve破译，但是Eve可以截获消息后修改消息再发送，或者Eve可以假冒Alice给Bob发送消息，如何避免这个问题呢？数字签名就派上用场了。数字签名的主要作用是解决伪造、抵赖、冒充和篡改问题。下面详细介绍RSA数字签名算法。 假设Alice的public-key为$(N_a,e_a)$，secret-key为$d_a$；假设Bob的public-key为$(N_b,e_b)$，secret-key为$d_b$。现在Alice想要给Bob发送一条消息，Bob需要确认消息确实是Alice发的而且中途未被篡改，他们可以这样做： Alice将要发送的消息为$M$。和常规的RSA算法一样，Alice将发送加密后的消息$M^{e_b}\\mod N_b$。 Alice除了发送$M^{e_2}\\mod N_2$，她还要对消息$M$进行签名操作（sign）：使用哈希函数生成消息全文的摘要信息$h(M)$（不可逆，如md5），然后发送签名$[h(M)]^{d_a}\\mod N_a$。总结来说，Alice发送了加密消息$M^{e_2}\\mod N_2$和她的签名$[h(M)]^{d_a}\\mod N_a$。 Bob将收到加密消息$M^{e_b}\\mod N_b$。和常规的RSA算法一样，Bob可以使用自己的secret-key解密$M’\\equiv (M^{e_b})^{d_b}(\\mod N_b)$。 Bob获得消息$M’$后，还需要对消息$M’$进行验证操作（verify）：解开Alice的签名$h(M)\\equiv [[h(M)]^{d_a}]^{e_a}(\\mod N_a)$，使用相同的哈希函数生成对消息$M’$的摘要$h(M’)$，若$h(M’)=h(M)$，则说明消息$M’$确实是Alice发送的，且中途未被篡改；否则，该消息是不可信任的。 为什么一定要对消息的摘要签名，而不是直接对消息签名呢？假设现在直接对消息签名，Alice发送消息$M$给Bob，Eve截获了$M^{e_b}\\mod N_b$；然后Eve请Bob发这段可疑的文字内容$M^{e_b}\\mod N_b$给Alice。若Bob发送了，Eve便可以截获数字签名$(M^{e_b})^{d_b}\\mod N_b$，从而得到$M$。就算Bob拒绝发送可疑的文字内容，Eve也可以让内容变得不可疑：挑选一个与$N_b$互质的整数$k$，然后让Bob发送$M^{e_b}\\cdot k^{e_b}\\mod N_b$。若Bob发送，Eve便可截获数字签名$((Mk)^{e_b})^{d_b}\\mod N_b=Mk\\mod N_b$，此时Eve只需要计算出$k^{-1}\\mod N_b$，就可以破解出$M$。综上所述，我们需要对消息进行不可逆的摘要后，再进行签名。 RSA加密算法与数字签名看似已经非常完美了，但是仍然存在风险：在传输消息之前，Alice和Bob都需要互换对方的公钥，如果在传输公钥的过程中，Eve截获了公钥，然后伪造公钥，Eve便可以作为第三者和Alice、Bob通信，而Alice和Bob都还以为自己和对方正常通信。总结来说就是，无法确定接收到的公钥是否是对方生成的且未被篡改，这显然这可以通过数字签名来解决。目前的通用方案是：Bob先去一个被大家所信任的第三方机构（CA机构）注册他的数字证书，数字证书里面包含了Bob的公钥和CA机构对证书内容的数字签名，CA机构会把该数字证书颁发给Bob。Alice若想发消息给Bob，先要取得Bob的公钥。于是Alice向Bob请求数字证书，Alice使用CA机构的公钥验证证书的数字签名，保证该证书一定是由机构发出的且未被篡改，Alice便可以获得Bob真实的公钥。问题又来了，CA机构公钥的真实性如何保障，这个公钥是否能被第三方篡改？不可能，因为CA机构被大家所信任，它的公钥一般都直接被保存在了本地电脑中，无需网络通信传输。 Quick Link: 算法笔记整理","link":"/2022/01/02/2022-01-02-algorithms-notes-chap1-8-application/"},{"title":"chap 2-1 分治算法-乘法、矩阵乘、主定理","text":"1. 分治（Divide and Conquer）分治算法是算法的重要分支之一，主要思想就是： 自上而下把问题划分成几个小的子问题，每个子问题与原问题类型相同。 自下而上递归地解决子问题。 把子问题的解适当地组合成原问题的解。 虽然分治法的核心结构是递归，但也不一定非得用函数递归来实现；递归法便于分析问题，迭代法可能却更为高效 。 2. 乘法假设$x$和$y$是两个$n-bit$整数（若不足$n$位则补零至$n$），为了使用分治法实现乘法，我们可以考虑将$x,y$各分成两半： $$x=(x_L)(x_R)=x_L\\cdot 2^{\\lfloor n/2 \\rfloor}+x_R$$ $$y=(y_L)(y_R)=y_L\\cdot 2^{\\lfloor n/2 \\rfloor}+y_R$$ 其中，$x_L$为$x$靠左的$\\lceil n/2 \\rceil-bit$整数，$x_R$为$x$靠右的$\\lfloor n/2 \\rfloor-bit$整数；$y_L$为$y$靠左的$\\lceil n/2 \\rceil-bit$整数，$y_R$为$y$靠右的$\\lfloor n/2 \\rfloor-bit$整数。两者相乘： $$xy=(x_L\\cdot 2^{\\lfloor n/2 \\rfloor}+x_R)(y_L\\cdot 2^{\\lfloor n/2 \\rfloor}+y_R)=x_Ly_L\\cdot 2^{2\\lfloor n/2\\rfloor}+(x_Ly_R+x_Ry_L)\\cdot 2^{\\lfloor n/2 \\rfloor}+x_Ry_R$$ 观察发现，我们把大的问题$xy$分成了四个小的子问题$x_Ly_L,x_Ly_R,x_Ry_L,x_Ry_R$，可以写出如下的递归关系式： $$T(n)=4T(\\lceil \\frac{n}{2} \\rceil)+O(n)$$ 根据推导（后面会证明），该算法复杂度为$O(n^2)$，与普通乘法并无二异。 再仔细想想，上述表达式中的$x_Ly_R+x_Ry_L$可以被写成$(x_L+x_R)(y_L+y_R)-x_Ly_L-x_Ry_R$。总的来看，子问题的数目就从4降到了3，这是否能降低复杂度？写出递归表达式： $$T(n)\\leq3T(\\lceil \\frac{n}{2} \\rceil+1)+O(n)$$ 容易看出，表达式内加上的常数项（$x_L+x_R,y_L+y_R$可能有$\\lceil \\frac{n}{2} \\rceil+1$位）并不会影响最终的复杂度，我们不如写成： $$T(n)=3T(\\lceil \\frac{n}{2} \\rceil)+O(n)$$ 根据推导，现在的复杂度为$O(n^{\\log_2 3})\\approx O(n^{1.59})$，比普通乘法要更快！ 伪代码： 123456789101112function multiply2(x, y){ n = max(size of x, size of y) if n=1: return xy x_L, x_R = leftmost ⌈n/2⌉, rightmost ⌊n/2⌋ bits of x y_L, y_R = leftmost ⌈n/2⌉, rightmost ⌊n/2⌋ bits of y P1 = multiply2(x_L, y_L) P2 = multiply2(x_R, y_R) P3 = multiply2(x_L+x_R, y_L+y_R) return P1×2^(2⌊n/2⌋) + (P3-P1-P2)×2^(⌊n/2⌋) + P2} 上述代码中，我们一直递归到了n=1的情况。在实际操作中，大整数被拆成的每个部分可能是16位，我们可以只递归到n=16的情况，然后直接用处理器内置的算术运算指令进行运算。 我们已经把乘法的复杂度从$O(n^2)$优化到了$O(n^{1.59})$，还有没有更快的方法呢？确实有，后面会提到。 3. 矩阵乘法设$X,Y$都是$n\\times n$的矩阵，$Z$为$X,Y$的乘积： $$Z_{ij}=\\sum_{k=1}^n X_{ik}Y_{kj}$$ 使用以上表达式求解矩阵乘，复杂度为$O(n^3)$，有无更快的方法？ Strassen提出了一种基于分治法的矩阵乘算法。$X,Y$可以分别被划分成$\\lceil n/2\\rceil \\times \\lceil n/2\\rceil$的四个块（block），若$n$不是偶数，则填补全零的一行/列： $$\\begin{equation}X=\\begin{bmatrix} A &amp; B \\\\ C &amp; D\\end{bmatrix}\\end{equation}$$ $$\\begin{equation}Y=\\begin{bmatrix} E &amp; F \\\\ G &amp; H\\end{bmatrix}\\end{equation}$$ 容易证明出： $$\\begin{equation}XY=\\begin{bmatrix} A &amp; B \\\\ C &amp; D\\end{bmatrix}\\begin{bmatrix} E &amp; F \\\\ G &amp; H\\end{bmatrix}=\\begin{bmatrix} AE+BG &amp; AF+BH \\\\ CE+DG &amp; CF+DH\\end{bmatrix}\\end{equation}$$ 算出结果后要删除掉之前填补过的全零行/列。 上述算法把求解$XY$的问题，分成了8个子问题，可以列出下面的递归关系式： $$T(n)=8T(\\lceil \\frac{n}{2}\\rceil)+O(n^2)$$ 根据推导，复杂度为$O(n^3)$。Strassen所做的优化与上面的乘法优化一样，把8个子问题缩减到了7个子问题： $$P_1=A(F-H)$$ $$P_2=(A+B)H$$ $$P_3=(C+D)E$$ $$P_4=D(G-E)$$ $$P_5=(A+D)(E+H)$$ $$P_6=(B-D)(G+H)$$ $$P_7=(A-C)(E+F)$$ $$\\begin{equation}XY= =\\begin{bmatrix} P_5+P_4-P_2+P_6 &amp; P_1+P_2 \\\\ P_3+P_4 &amp; P_1+P_5-P_3-P_7\\end{bmatrix}\\end{equation}$$ 此时递归关系式变为： $$T(n)=7T(\\lceil \\frac{n}{2}\\rceil)+O(n^2)$$ 根据推导，Strassen矩阵乘算法的复杂度为$O(n^{\\log_2 7})\\approx O(n^{2.81})$。 4. 主定理（Master Theorem）分析分治算法的复杂度时，我们都推出了递归关系式，如何快速根据关系式得到复杂度呢？可以直接使用主定理： Master Theorem 令 $a\\geq 1$和 $b&gt;1$是常数，$f(n)$是一个函数，$T(n)$是定义在非负整数上的递归表达式： $$T(n)=aT(n/b)+f(n)$$ 其中，$n/b$可以是 $\\lceil n/b \\rceil$或是 $\\lfloor n/b \\rfloor$，那么 $T(n)$有如下渐进界： 若对于某个常数 $\\varepsilon&gt;0$有 $f(n)=O(n^{\\log_b a -\\varepsilon})$，则 $T(n)=\\Theta(n^{\\log_b a})$。 若 $f(n)=\\Theta(n^{\\log_b a})$，则 $T(n)=\\Theta(n^{\\log_b a}\\log n)$。 若对于某个常数 $\\varepsilon&gt;0$有 $f(n)=\\Omega(n^{\\log_b a +\\varepsilon})$，且对于某个常数 $c&lt;1$和所有足够大的 $n$有 $af(n/b)\\leq cf(n)$，则 $T(n)=\\Theta(f(n))$。 简单来说就是，我们将函数$f(n)$与$n^{\\log_b a}$进行比较：若$f(n)$渐进小于$n^{\\log_b a}$，则$T(n)=\\Theta(n^{\\log_b a})$；若$f(n)$渐进等于$n^{\\log_b a}$，则$T(n)=\\Theta(n^{\\log_b a}\\log n)$；若$f(n)$渐进大于$n^{\\log_b a}$，且满足正则条件$af(n/b)\\leq cf(n)$（大多数多项式界函数都满足），则$T(n)=\\Theta(f(n))$。 不是所有情况都能直接套用主定理，比如$T(n)=2T(n/2)+n\\log n$就无法套用情况3。 $Proof$：首先证明若$n$恰好为$b$的幂的情况。 根据递归树，容易推出： $$\\begin{equation}\\begin{aligned}T(n) &amp; = aT(n/b)+f(n) \\\\ &amp; =a^2T(n/b^2)+f(n)+af(n/b) \\\\ &amp;= a^3f(n/b^3)+f(n)+af(n/b)+a^2f(n/b^2) \\\\ &amp;= \\cdots \\\\ &amp;=a^{\\log_b n}\\cdot\\Theta(1)+\\sum_{k=0}^{\\log_b n - 1} a^kf(n/b^k) \\\\ &amp;=\\Theta(n^{\\log_b a})+\\sum_{k=0}^{\\log_b n - 1} a^kf(n/b^k)\\end{aligned}\\end{equation}$$ 令$g(n)=\\sum_{k=0}^{\\log_b n - 1} a^kf(n/b^k)$， 对于情况1：$f(n)=O(n^{\\log_b a -\\varepsilon})$，代入公式： $$\\begin{equation}\\begin{aligned}g(n) &amp;=O(\\sum_{k=0}^{\\log_b n - 1} a^k(\\frac{n}{b^k})^{\\log_b a -\\varepsilon}) \\\\ &amp;=O(n^{\\log_b a -\\varepsilon}\\sum_{k=0}^{\\log_b n - 1}(b^{\\varepsilon})^k) \\\\ &amp;= O(n^{\\log_b a -\\varepsilon}\\cdot\\frac{n^{\\varepsilon}-1}{b^{\\varepsilon}-1}) \\\\ &amp;= n^{\\log_b a -\\varepsilon}\\cdot O(n^{\\varepsilon}) \\\\ &amp;=O(n^{\\log_b a})\\end{aligned}\\end{equation}$$ 带入$T(n)$的表达式，可得$T(n)=\\Theta(n^{\\log_b a})$。 对于情况2：$f(n)=\\Theta(n^{\\log_b a})$，代入公式： $$\\begin{equation}\\begin{aligned}g(n) &amp;=\\Theta(\\sum_{k=0}^{\\log_b n - 1} a^k(\\frac{n}{b^k})^{\\log_b a}) \\\\ &amp;= \\Theta(n^{\\log_b a}\\cdot \\sum_{k=0}^{\\log_b n - 1}1 ) \\\\ &amp;=\\Theta(n^{\\log_b a}\\log n)\\end{aligned}\\end{equation}$$ 带入$T(n)$的表达式，可得$T(n)=\\Theta(n^{\\log_b a}\\log n)$。 对于情况3：首先证明一下，对于某个常数 $c&lt;1$和所有足够大的$n$有$af(n/b)\\leq cf(n)$，就已经暗含了若对于某个常数$\\varepsilon&gt;0$有$f(n)=\\Omega(n^{\\log_b a +\\varepsilon})$。将$af(n/b)\\leq cf(n)$迭代$k$次，可得$a^kf(n/b^k)\\leq c^kf(n)$，令$n=b^k$，则$f(n)\\geq (a/c)^{\\log_b n}\\cdot f(1)=n^{\\log_b a - \\log_b c}\\cdot f(1)$，即$f(n)=\\Omega(n^{\\log_b a +\\varepsilon})$。 观察$g(n)$的表达式，可知$g(n)=\\Omega(f(n))$。又因为： $$\\begin{equation}\\begin{aligned}g(n) &amp;=\\sum_{k=0}^{\\log_b n - 1} a^kf(n/b^k) \\\\ &amp;\\leq \\sum_{k=0}^{\\log_b n - 1} c^kf(n)+O(1) \\\\ &amp;\\leq f(n) \\sum_{k=0}^{\\infty} c^k+O(1) \\\\ &amp;= f(n)\\cdot\\frac{1}{1-c}+O(1)\\\\ &amp;=O(f(n))\\end{aligned}\\end{equation}$$ 故$g(n)=\\Theta(f(n))$。带入$T(n)$的表达式，可得$T(n)=\\Theta(f(n))$。 下面证明若$n$不是$b$的幂的情况。易证有如下不等式成立： $$\\cdots\\leq n/b\\leq b^{\\lfloor \\log_b n\\rfloor-1}\\leq n\\leq b^{\\lfloor \\log_b n\\rfloor}\\leq bn\\leq b^{\\lfloor \\log_b n\\rfloor+1}\\leq\\cdots$$ 上述不等式说明，对于任意$n$，都能在附近找到一个比它大的数（不大于$bn$）使其称为$b$的幂，都能在附近找到一个比它小的数（不小于$n/b$）使其称为$b$的幂。 先考虑上取整的情况，参数调用序列如下： $$n,\\lceil n/b \\rceil,\\lceil \\lceil n/b \\rceil/b \\rceil,\\lceil \\lceil \\lceil n/b \\rceil/b \\rceil/b \\rceil,\\cdots$$ 令$n_k$表示序列中的第$k$个元素： $$\\begin{equation}n_k=\\begin{cases} n, &amp; k=0 \\\\ \\lceil n_{k-1}/b \\rceil, &amp; k&gt;0\\end{cases}\\end{equation}$$ 则根据上述不等式，可得$n_k\\in[b^{\\lfloor \\log_b n\\rfloor-1}/b^k,b^{\\lfloor \\log_b n\\rfloor}/b^k]$，即$n_k=\\Theta(n/b^k)$。 根据递归树，容易推出： $$T(n)=\\Theta(n^{\\log_b a})+\\sum_{k=0}^{\\lfloor\\log_b n\\rfloor - 1} a^kf(n_k)$$ 令$g(n)=\\sum_{k=0}^{\\lfloor\\log_b n\\rfloor - 1} a^kf(n_k)$， 对于情况1：$f(n)=O(n^{\\log_b a -\\varepsilon})$，代入公式： $$\\begin{equation}\\begin{aligned}g(n) &amp;=\\sum_{k=0}^{\\lfloor\\log_b n\\rfloor - 1} a^kO(n_k^{\\log_b a -\\varepsilon}) \\\\ &amp;= O(\\sum_{k=0}^{\\lfloor\\log_b n\\rfloor - 1} a^k(\\frac{n}{b^k})^{\\log_b a -\\varepsilon}))\\end{aligned}\\end{equation}$$ 证明同上。 对于情况2：$f(n)=\\Theta(n^{\\log_b a})$，代入公式： $$\\begin{equation}\\begin{aligned}g(n) &amp;=\\sum_{k=0}^{\\lfloor\\log_b n\\rfloor - 1} a^k\\Theta(n_k^{\\log_b a}) \\\\ &amp;= \\Theta(\\sum_{k=0}^{\\lfloor\\log_b n\\rfloor - 1} a^k(\\frac{n}{b^k})^{\\log_b a})\\end{aligned}\\end{equation}$$ 证明同上。 对于情况3：观察$g(n)$的表达式，可知$g(n)=\\Omega(f(n))$。根据$af(n_1)\\leq cf(n)$，容易推出$a_kf(n_k)\\leq c^k f(n)$，证明同上。 下取整的证明与上取整几乎相同，此处不再赘述。▮ 现在忘了上面繁琐的证明吧，直接记住下面简化版本的主定理，已经能解决大部分问题了： Master Theorem (simplified) 令 $a\\geq 1$和 $b&gt;1$是常数，$T(n)$是定义在非负整数上的递归表达式： $$T(n)=aT(n/b)+O(n^d)$$ 其中，$n/b$可以是 $\\lceil n/b \\rceil$或是 $\\lfloor n/b \\rfloor$，那么 $T(n)$有如下渐进界： $$\\begin{equation}T(n)=\\begin{cases}O(n^{\\log_b a}), &amp; \\log_b a&gt;d \\\\ O(n^d\\log n), &amp; \\log_b a=d \\\\ O(n^d), &amp; \\log_b a&lt;d\\end{cases}\\end{equation}$$ 使用简化版的主定理，可以一眼看出上述提到的乘法和矩阵乘的复杂度： $$T(n)=3T(\\frac{n}{2})+O(n),\\log_b a=\\log_2 3 &gt; d=1,O(n^{\\log_23})$$ $$T(n)=7T(\\frac{n}{2})+O(n^2),\\log_ba=\\log_27&gt;d=2,O(n^{\\log_27})$$ Quick Link: 算法笔记整理","link":"/2022/01/06/2022-01-06-algorithms-notes-chap2-1-master-theorem/"},{"title":"chap 2-2 分治算法-排序和选择","text":"1. 快速排序（Quicksort）排序算法经常用到分治策略。在现实中，最常用的排序算法当属快速排序。主要过程：首先进行partition操作，从数组中挑选一个元素作为主元pivot，将小于pivot的元素放置到它的左边，将大于pivot的元素放置到它的右边；然后递归地对pivot左右两边的数组进行partition。 具体实现如下： 1234567891011121314151617181920int partition(int* a, int l, int r) { int p = a[r - 1]; int i = l - 1; for (int j = l; j &lt; r - 1; ++j) { if (a[j] &lt;= p) { i++; swap(a, i, j); } } swap(a, i + 1, r - 1); return i + 1;}void quicksort(int* a, int l, int r) { if (r - l &gt;= 2) { int m = partition(a, l, r); quicksort(a, l, m); quicksort(a, m + 1, r); }} 下面进行复杂度的分析，由于复杂度与选择的pivot有关，所以我们要逐一分析最坏、最好和平均的复杂度。 最坏情况复杂度：每次partition时都出现了极其不平衡的划分，分出了大小为$0$和$n-1$的两个子问题，递归表达式如下： $$T(n)=T(0)+T(n-1)+\\Theta(n)=T(n-1)+\\Theta(n)$$ 故最坏情况的复杂度为$\\Theta(n^2)$。 最好情况复杂度：每次partition时都出现了恰好平衡的划分，递归表达式如下： $$T(n)=2T(n/2)+\\Theta(n)$$ 故最好情况的复杂度为$\\Theta(n\\log n)$。 平均情况复杂度：假设输入的数据完全是随机的，则每个元素成为主元的概率为$1/n$（$n$为本次划分的数组的大小）。若挑选的主元在数组中排第$i$位，则子问题的大小为$i-1$和$n-i$，列出以下递归表达式： $$T(n)=\\frac{1}{n}\\sum_{i=1}^{n}[T(i-1)+T(n-i)+O(n)]=O(n)+\\frac{2}{n}\\sum_{i=1}^{n-1}T(i)$$ 则： $$T(n-1)=O(n-1)+\\frac{2}{n-1}\\sum_{i=1}^{n-2}T(i)$$ 联合两个式子，可得： $$\\begin{equation}\\begin{aligned}T(n) &amp; = \\frac{n+1}{n}T(n-1)+O(1) \\\\ &amp; =O(1)(1+\\frac{n+1}{n}+\\frac{n+1}{n-1}+\\frac{n+1}{n-2}+\\cdots+\\frac{n+1}{1}) \\\\ &amp;=O(1)[1+(n+1)\\sum_{i=1}^n\\frac{1}{i}] \\\\ &amp;= O(n\\log n)\\end{aligned}\\end{equation}$$ 故平均复杂度为$O(n\\log n)$。但是这是在我们假定输入数据完全随机的条件下推导出的，在现实中很少会出现这种情况。为了保证较好的平均复杂度，我们每次partition时可以随机选取主元，人工引入随机因素。下面是随机版快速排序的实现： 12345678910111213int randomized_partition(int* a, int l, int r) { int m = rand() % (r - l) + l; swap(a, m, r - 1); return partition(a, l, r);}void randomized_quicksort(int* a, int l, int r) { if (r - l &gt;= 2) { int m = randomized_partition(a, l, r); randomized_quicksort(a, l, m); randomized_quicksort(a, m + 1, r); }} 随机版快速排序的良好性能使之成为排序大量数据的首选算法，包括Unix系统内置的文件排序命令。 2. 归并排序（Mergesort）另一种比较容易想到的方法就是归并排序，主要过程：把数组分成两部分，分别排序好每个部分（子问题），然后进行合并操作（merge），返回排序好的整个数组。 伪代码： 1234567891011function mergesort(a[1:n]){ if n&gt;1: return merge(mergesort(a[1:n/2]), mergesort(a[n/2+1, n])) else return a}function merge(x[1:k], y[1:l]){ if k=0: return y[1:l] if l=0: return x[1:k] if x[1]&lt;=y[1]: return x[1] concat merge(x[2:k], y[1:l]) else: return y[1] concat merge(x[1:k], y[2:l])} mergesort(a[1:n/2])和mergesort(a[n/2+1, n])是划分子问题，merge为合并操作。具体实现如下： 1234567891011121314151617181920212223242526void merge(int* a, int l, int m, int r) { int* left = new int[m - l]; int* right = new int[r - m]; for (int i = l; i &lt; m; ++i) left[i - l] = a[i]; for (int i = m; i &lt; r; ++i) right[i - m] = a[i]; int i = 0; int j = 0; int k = l; while (i &lt; m - l &amp;&amp; j &lt; r - m) { if (left[i] &lt;= right[j]) a[k++] = left[i++]; else a[k++] = right[j++]; } while (i &lt; m - l) a[k++] = left[i++]; while (j &lt; m - l) a[k++] = right[j++]; delete[] left; delete[] right;}// [l, r)void mergesort(int* a, int l, int r) { if (r - l &lt;= 1) return; int m = l + (r - l) / 2; mergesort(a, l, m); mergesort(a, m, r); merge(a, l, m, r);} 下面分析该算法的复杂度，列出递归表达式： $$T(n)=2T(n/2)+O(n)$$ 根据主定理，易得复杂度为$O(n\\log n)$。 虽然归并排序时间复杂度较低，但是每次归并（merge）操作都要复制数组，占用太多内存，空间复杂度较高。但如果需要排序的数据比内存还大，归并排序的思想就有用武之地了。 3. 外部归并排序（External Mergesort）假设现在计算机的内存为8GB，硬盘中有128GB的数据需要排序，我们显然不能采取一般的排序方法：直接把数据全部装载到内存，然后一次性排好序，最后存回硬盘。我们可以利用归并排序的思想进行外部排序（external sorting）：每次装载8GB数据到内存，排好序后（快排或其他）存回硬盘，重复16次，硬盘中就有了16个内部有序的子文件；然后对这16个文件进行合并操作，最终生成一个内部有序的大文件。内存中归并排序的不足是需要复制数组，而从硬盘装载数据到内存这一操作必须要复制数组，所以正好适合使用归并排序的思想。 外部归并排序与内存中归并排序的相同点是，都从最初一个个的有序数组开始，一步步合并成最后的一个有序数组；不同点是，外部归并排序最初的有序数组元素很多，而内存中归并排序最初的有序数组中只有一个元素。 下面详细阐述外部归并排序的步骤： 我们定义一次磁盘I/O传输的数据单元为一个page（假设一个page大小为4KB，在磁盘中通常被称为block），比如从硬盘中取16KB的数据进行排序，然后再写回磁盘，共需8次I/O。给定计算机的内存RAM大小为$B$-page，需要对磁盘中大小为$N$-page的文件进行排序（$N&gt;&gt;B$），可以使用如下的外部归并排序方法。 首先进行conquer：每次从磁盘中装载$B$-pages的数据到RAM中，使用快排或其他方法对该$B$-pages数据进行排序，排序后将其全部写入磁盘中的一个文件中。重复上述步骤直至取完$N$-pages的数据，此时磁盘中应有$\\lceil N/B\\rceil$个有序的子文件，每个子文件的大小为$B$-page（可能不足$B$-page，下同）。 然后进行merge：现在的目标是将$\\lceil N/B\\rceil$个大小为$B$-pages的有序子文件合并成1个大小为$N$-pages的大文件。我们将RAM划分成两个部分，一部分是$B-1$个大小为$1$-page的input_buffer，另一部分是1个大小为$1$-page的output_buffer。每个input_buffer关联一个子文件，负责读取子文件中的数据。类比归并排序的合并操作，我们需要从所有input_buffer中找到最小/大的元素填入output_buffer中。若output_buffer填满，则将其中的数据flush到磁盘中的一个文件中；若某一个input_buffer中的数据被读取完，则继续从对应子文件中读入数据，直至所有关联的子文件的数据全被读完。经过上述的一次merge（$B-1$路merge），我们能将$B-1$个有序子文件合并成1个大的有序文件（$B(B-1)$-pages）。经过第一次conquer，生成了$\\lceil N/B\\rceil$个子文件，如果像上面每次merge了$B-1$个子文件，merge全部$\\lceil N/B\\rceil$个子文件，则会生成$\\lceil \\lceil N/B\\rceil/(B-1)\\rceil$个有序文件。我们称一次完整的上述过程为一个PASS，重复上述过程： 第1个PASS，$\\lceil N/B\\rceil$个大小为$B$-pages的有序文件合并成了$\\lceil \\lceil N/B\\rceil/(B-1)\\rceil$个大小为$B(B-1)$-pages的有序文件； 第2个PASS，$\\lceil \\lceil N/B\\rceil/(B-1)\\rceil$个大小为$B$-pages的有序文件合并成了$\\lceil \\lceil \\lceil N/B\\rceil/(B-1)\\rceil/(B-1)\\rceil$个大小为$B(B-1)^2$-pages的有序文件； …… 第$\\lceil \\log_{B-1}\\lceil N/B\\rceil\\rceil$个PASS，最终只剩了1个大小为$N$-pages的有序文件，完成排序。 下面分析一下该算法耗费的时间，分为CPU计算的时间和磁盘I/O的时间。这里假设每个page含有$p$个元素，内存中排序使用快排，$k$路merge使用最普通的进行$k$次比较选出最小/大元素的方法。 先考虑CPU计算的时间。conquer阶段，进行了$\\lceil N/B\\rceil$次排序，每次排序的元素个数为$O(Bp)$，则耗费时间为$O(\\lceil N/B\\rceil Bp\\log (Bp))=O(Np\\log (Bp))$。每个PASS，output_buffer都一共会输出$Np$个元素，生成每个元素需要$O(B)$，故merge阶段，耗费时间为$O(NBp\\lceil \\log_{B-1}\\lceil N/B\\rceil\\rceil)=O(NBp\\log_B N)$。 再考虑磁盘I/O的时间。conquer和每个PASS，都需要读取和写入$N$-pages，故总的I/O次数为$2N(1+\\lceil \\log_{B-1}\\lceil N/B\\rceil\\rceil)$。 分析可以发现，$N$和$p$大小不变时，增加$B$可以大大减少磁盘I/O的次数，但是却使merge操作耗费的时间大大增加，最终可能抵消了减少磁盘I/O带来的好处。实际测试中也发现，当$N$很大时，merge操作通常是性能瓶颈。其实有不少关于$k$路merge的优化方案，比如败者树等等，可以大大提升merge的性能，此处不再赘述。 4. 排序算法的下界研究了这么久排序，那么排序算法最快能有多快呢？其实上述的所有排序，都可以用决策树模型来描述： 每一次排序，算法在做的事情都是寻找从根节点到叶节点的一条路径，叶节点就是排序的结果。这棵二叉树的深度就是最坏情况下我们需要比较的次数，可能的最小深度即是排序算法的下界。 通过观察我们发现，若输入数组长度为$n$，那么叶节点的数量至少为$n!$个。反证法，若某个排列不是叶节点，我们总能构造出一个符合这个排列的输入数组，与假设矛盾。因此，若该二叉树的深度为$d$，则它至多有$2^d$个叶节点，又因为叶节点的数量至少为$n!$个，则$n!\\leq 2^d$，可以推出$d=\\Omega(\\log (n!))=\\Omega(n\\log n)$。 综上所述，基于比较的排序算法的下界为$\\Omega(n\\log n)$。注意该结论成立的前提是，我们使用比较的方法确定顺序。若数据满足一定的条件，我们甚至可以在线性时间内完成排序，比如计数排序、基数排序等等。 5. 快速选择算法有些时候，我们并不需要对数据进行排序，我们可能只想知道最大的是哪个，中位数是哪个，最小的是哪个等等。我们需要设计一个选择算法select，返回数组中排名第$k$的元素。回想快速排序，我们选择主元，然后把比它小的和比它大的都排到它左右两边，如果$k$比主元的索引还小，那排名第$k$的元素必然在左边的数组。 受到快排的启发，我们可以设计如下的快速选择算法，同样利用了分治，令$S$为输入的数组，令主元为$v$，$S_L$为比$v$小的子数组，$S_R$为比$v$大的子数组，$S_v$为值都等于$v$的子数组，则排名为第$k$为的元素值为： $$\\begin{equation}select(S, k)=\\begin{cases} select(S_L,k), &amp; k\\leq|S_L| \\\\ v, &amp; |S_L|&lt;k\\leq|S_L|+|S_v| \\\\ select(S_R,k), &amp; k&gt;|S_L|+|S_v|\\end{cases}\\end{equation}$$ 具体实现如下： 12345678910111213141516171819202122232425262728pair&lt;int, int&gt; split(int* a, int l, int r, int val) { int k = l; for (int i = l; i &lt; r; ++i) { if (a[i] &lt; val) { swap(a, k, i); k++; } } int lb = k; for (int i = k; i &lt; r; ++i) { if (a[i] == val) { swap(a, k, i); k++; } } int ub = k; return make_pair(lb, ub);}// k'th smallest elementint select(int* a, int l, int r, int k) { int val = a[rand() % (r - l) + l]; pair&lt;int, int&gt; res = split(a, l, r, val); int lb = res.first; int ub = res.second; if (k &lt;= lb - l) return select(a, l, lb, k); else if (k &gt; ub - l) return select(a, ub, r, k - ub + l); else return val;} 我们用split()代替了partition()，二者功能基本相同，但split()可以处理有多个相同主元的情况，返回相同主元区域的左右边界。快速选择与快排的思路基本相同，但是快速选择算法每次分治后，只处理一个子问题，而快排需要处理两个。那两者的复杂度有区别吗？ 最坏情况复杂度：选择最小的元素，但是每次挑选主元都选了最大的，递归表达式如下： $$T(n)=n+(n-1)+\\cdots+1=\\Theta(n^2)$$ 故最坏情况的复杂度为$\\Theta(n^2)$。 最好情况复杂度：第一次挑选主元都选到了第$k$位的元素，等同于split()的复杂度$O(n)$。 平均情况复杂度：假设所有元素互异，排第$i$位的元素被选取为主元的概率为$1/n$，$k$小于$i$的概率为$(i-1)/n$，$k$大于$i$的概率为$(n-i)/n$，$k$等于$i$的概率为$1/n$。可以列出以下递归关系式： $$\\begin{equation}\\begin{aligned}T(n) &amp; = \\frac{1}{n}\\sum_{i=1}^n [\\frac{i-1}{n}T(i-1)+\\frac{1}{n}O(1)+\\frac{n-i}{n}T(n-i)+O(n)] \\\\ &amp; = \\frac{1}{n^2}\\sum_{i=1}^n[(i-1)T(i-1)+(n-i)T(n-i)]+O(n)\\end{aligned}\\end{equation}$$ 则： $$T(n-1)=\\frac{1}{(n-1)^2}\\sum_{i=1}^{n-1}[(i-1)T(i-1)+(n-1-i)T(n-1-i)]+O(n-1)$$ 联合两个式子，得： $$\\begin{equation}\\begin{aligned}T(n) &amp; = \\frac{(n+1)(n-1)}{n^2}T(n-1)+O(1) \\\\ &amp;= O(1)[1+\\frac{(n+1)(n-1)}{n\\cdot n}+\\frac{(n+1)(n-2)}{n(n-1)}+\\frac{(n+1)(n-3)}{n(n-2)}+\\cdots] \\\\ &amp;= O(1)[1+\\frac{n+1}{n}(n-\\sum_{i=1}^n \\frac{1}{i})] \\\\ &amp;= O(n)\\end{aligned}\\end{equation}$$ 若存在相同元素，花费的时间显然小于$O(n)$，故平均复杂度为$O(n)$。 因此，利用分治策略，我们可以在$O(n)$时间内选出数组中排第$k$的元素。较常见的应用是寻找一个数组的中位数，只需要把快速选择算法的$k$设置为$n/2$。 Quick Link: 算法笔记整理","link":"/2022/01/08/2022-01-08-algorithms-notes-chap2-2-sort_and_select/"},{"title":"面试-计算机网络与网络编程","text":"Abstract: 常见的计算机网络面试题集合，包括Leetcode面试宝典、阅读整理、课堂资料等等。 Quick Link: 面试-2021微信暑期实习 （非完整版~） 1 计算机网络基础1.1 包传输(Packet) 1.1.1 什么是带宽(bandwidth)单位时间内发送/接受到的bits数(bits/second, bps)。可理解为link的宽度。 1.1.2 有哪4种包延迟 传输延时(transmission delay) Packet中第一个bit进入link和最后一个bit进入link的时间差，即packet需要花多长时间才能进入link中。 transmissionDelay=packetSize / bandwidth 传播延时(propagation delay, latency) 对于packet中的每个bit来说，端到端(end2end)的传输时间。与packet大小无关。可理解为link的长度。 propagationDelay=lengthOfLink / speedOfLight 排队延时(queuing delay) packet需要在host/router中等待多长时间才能被送到link上。通常在到达速率＞传输速率时出现。 网络中的bursty flows会增加排队延时。如果队列已满，packet会被丢弃。 处理延时(processing delay) router处理packet花费的时间。 1.1.3 什么是带宽时延积(BDP)带宽与传播延时的积，单位为bits。可以理解为link的容量，即在任意时间有多少bits在link中传输(in flight)。 1.1.4 什么是端到端延时(end to end delay)即上述4种包延时之和，处理延时较短通常可忽略。 1.2 体系结构1.2.1 什么是分组交换(Packet Switching)包含一定字节数的数字信息块(分组)独立通过网络。 1.2.2 什么是多路复用(Multiplexing) 来自不同来源或发送方的块可以组合，而且以后可以分解。 频分复用（FDM，Frequency Division Multiplexing）频分复用将传输信道的总带宽按频率划分为若干个子频带或子信道，每个子信道传输一路信号。用户分到一定的频带后，在数据传输的过程中自始至终地占用这个频带。由于每个用户所分到的频带不同，使得传输信道在同一时刻能够支持不同用户进行数据传输，从而实现复用。除了传统意义上的 FDM 外，目前正交频分复用（OFDM）已在高速通信系统中得到广泛应用。 时分复用（TDM，Time Division Multiplexing）顾名思义，时分复用将信道传输信息的时间划分为若干个时间片，每一个时分复用的用户在每一个 TDM 帧中占用固定时隙进行数据传输。用户所分配到的时隙是固定的，所以时分复用有时也叫做同步时分复用。这种分配方式能够便于调节控制，但是也存在缺点，当某个信道空闲时，其他繁忙的信道无法占用该空闲信道，因此会降低信道利用率。 波分复用（WDM，Wavelength Division Multiplexing）在光通信领域通常按照波长而不是频率来命名，因为光的频率和波长具有单一对应关系，因此 WDM 本质上也是 FDM，光通信系统中，通常由光来运载信号进行传输，WDM 是在一条光纤上传输多个波长光信号，其将 1 根光纤看做多条「虚拟」光纤，每条「虚拟」光纤工作在不同的波长上，从而极大地提高了光纤的传输容量。 码分复用（CDM，Code Division Multiplexing）码分复用是靠不同的编码来区分各路原始信号的一种复用方式，不同的用户使用相互正交的码字携带信息。由于码组相互正交，因此接收方能够有效区分不同的用户数据，从而实现每一个用户可以在同样的时间在同样的频带进行数据传输，频谱资源利用率高。其主要和各种多址接入技术相结合从而产生各种接入技术，包括无线和优先接入。 1.2.3 简述端到端论点和命运共享端到端论点倾向于支持使用“哑”网络和连接到网络的“智能”系统的设计方案，很多功能在端主机的应用程序中实现。 命运共享建议将所有必要的状态放在通信端点。 1.2.4 简述OSI七层模型 OSI 模型全称为开放式通信系统互连参考模型，是国际标准化组织 ( ISO ) 提出的一个试图使各种计算机在世界范围内互连为网络的标准框架。 OSI 将计算机网络体系结构划分为七层，每一层实现各自的功能和协议，并完成与相邻层的接口通信。OSI 的服务定义详细说明了各层所提供的服务。某一层的服务就是该层及其下各层的一种能力，它通过接口提供给更高一层。各层所提供的服务与这些服务是怎么实现的无关。 ① 应用层(Application) 应用层位于 OSI 参考模型的第七层，其作用是通过应用程序间的交互来完成特定的网络应用。该层协议定义了应用进程之间的交互规则，通过不同的应用层协议为不同的网络应用提供服务。例如域名系统 DNS，支持万维网应用的 HTTP 协议，电子邮件系统采用的 SMTP 协议等。在应用层交互的数据单元我们称之为报文。 ② 表示层(Presentation) 表示层的作用是使通信的应用程序能够解释交换数据的含义，其位于 OSI 参考模型的第六层，向上为应用层提供服务，向下接收来自会话层的服务。该层提供的服务主要包括数据压缩，数据加密以及数据描述。这使得应用程序不必担心在各台计算机中表示和存储的内部格式差异。 ③ 会话层(Session) 会话层就是负责建立、管理和终止表示层实体之间的通信会话。该层提供了数据交换的定界和同步功能，包括了建立检查点和恢复方案的方法。 ④ 传输层(Transport) 传输层的主要任务是为两台主机进程之间的通信提供服务。应用程序利用该服务传送应用层报文。该服务并不针对某一特定的应用，多种应用可以使用同一个传输层服务。由于一台主机可同时运行多个线程，因此传输层有复用和分用的功能。所谓复用就是指多个应用层进程可同时使用下面传输层的服务，分用和复用相反，是传输层把收到的信息分别交付上面应用层中的相应进程。 ⑤ 网络层(Internet) 两台计算机之间传送数据时其通信链路往往不止一条，所传输的信息甚至可能经过很多通信子网。网络层的主要任务就是选择合适的网间路由和交换节点，确保数据按时成功传送。在发送数据时，网络层把传输层产生的报文或用户数据报封装成分组和包向下传输到数据链路层。在网络层使用的协议是无连接的网际协议（Internet Protocol）和许多路由协议，因此我们通常把该层简单地称为 IP 层。 ⑥ 数据链路层(Data Link) 数据链路层通常也叫做链路层，在物理层和网络层之间。两台主机之间的数据传输，总是在一段一段的链路上传送的，这就需要使用专门的链路层协议。在两个相邻节点之间传送数据时，数据链路层将网络层交下来的 IP 数据报组装成帧，在两个相邻节点间的链路上传送帧。每一帧包括数据和必要的控制信息。通过控制信息我们可以知道一个帧的起止比特位置，此外，也能使接收端检测出所收到的帧有无差错，如果发现差错，数据链路层能够简单的丢弃掉这个帧，以避免继续占用网络资源。 ⑦ 物理层(Physics) 作为 OSI 参考模型中最低的一层，物理层的作用是实现计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异。使其上面的数据链路层不必考虑网络的具体传输介质是什么。该层的主要任务是确定与传输媒体的接口的一些特性（机械特性、电气特性、功能特性，过程特性）。 1.2.5 简述TCP/IP参考模型(ARPANET) OSI 七层模型在提出时的出发点是基于标准化的考虑，而没有考虑到具体的市场需求，使得该模型结构复杂，部分功能冗余，因而完全实现 OSI 参考模型的系统不多。而 TCP/IP 参考模型直接面向市场需求，实现起来也比较容易，因此在一经提出便得到了广泛的应用。基于 TCP/IP 的参考模型将协议分成四个层次，如上图所示，它们分别是：网络访问层、网际互联层、传输层、和应用层。 ① 应用层 TCP/IP 模型将 OSI 参考模型中的会话层、表示层和应用层的功能合并到一个应用层实现，通过不同的应用层协议为不同的应用提供服务。例如：FTP、Telnet、DNS、SMTP 等。 ② 传输层 该层对应于 OSI 参考模型的传输层，为上层实体提供源端到对端主机的通信功能。传输层定义了两个主要协议：传输控制协议（TCP）和用户数据报协议（UDP）。其中面向连接的 TCP 协议保证了数据的传输可靠性，面向无连接的 UDP 协议能够实现数据包简单、快速地传输。 ③ 网际互联层 网际互联层对应 OSI 参考模型的网络层，主要负责相同或不同网络中计算机之间的通信。在网际互联层， IP 协议提供的是一个不可靠、无连接的数据报传递服务。该协议实现两个基本功能：寻址和分段。根据数据报报头中的目的地址将数据传送到目的地址，在这个过程中 IP 负责选择传送路线。除了 IP 协议外，该层另外两个主要协议是互联网组管理协议（IGMP）和互联网控制报文协议（ICMP）。 ④ 网络接入层 网络接入层的功能对应于 OSI 参考模型中的物理层和数据链路层，它负责监视数据在主机和网络之间的交换。事实上，TCP/IP 并未真正描述这一层的实现，而由参与互连的各网络使用自己的物理层和数据链路层协议，然后与 TCP/IP 的网络接入层进行连接，因此具体的实现方法将随着网络类型的不同而有所差异。 1.2.6 OSI模型和TCP/IP模型的比较OSI 七层网络模型 TCP/IP 四层概念模型 对应的网络协议应用层（Application） 应用层 HTTP, TFTP, FTP, NFS, WAIS, SMTP, Telnet, DNS, SNMP表示层（Presentation） 应用层 TIFF, GIF, JPEG, PICT会话层（Session） 应用层 RPC, SQL, NFS, NetBIOS, names, AppleTalk传输层（Transport） 传输层 TCP, UDP网络层（Network） 网络层 IP, ICMP, ARP, RARP, RIP, IPX数据链路层（Data Link） 数据链路层 FDDI, Frame Relay, HDLC, SLIP, PPP物理层（Physical） 数据链路层 EIA/TIA-232, EIA/TIA-499, V.35, 802.3 相同点 ① OSI 参考模型与 TCP/IP 参考模型都采用了层次结构。 ② 都能够提供面向连接和无连接两种通信服务机制。 不同点 ① OSI 采用的七层模型； TCP/IP 是四层结构。 ② TCP/IP 参考模型没有对网络接口层进行细分，只是一些概念性的描述； OSI 参考模型对服务和协议做了明确的区分。 ③ OSI 先有模型，后有协议规范，适合于描述各种网络；TCP/IP 是先有协议集然后建立模型，不适用于非 TCP/IP 网络。 ④ TCP/IP 一开始就提出面向连接和无连接服务，而 OSI 一开始只强调面向连接服务，直到很晚才开始制定无连接的服务标准。 ⑤ OSI 参考模型虽然被看好，但将网络划分为七层，实现起来较困难；相反，TCP/IP 参考模型虽然有许多不尽人意的地方，但作为一种简化的分层结构还是比较成功的。 1.2.7为何TCP/IP去除表示层和会话层OSI 参考模型在提出时，他们的理想是非常好的，但实际上，由于会话层、表示层、应用层都是在应用程序内部实现的，最终产出的是一个应用数据包，而应用程序之间是几乎无法实现代码的抽象共享的，这也就造成 OSI 设想中的应用程序维度的分层是无法实现的，例如，我们几乎不会认为数据的压缩、加密算法算是一种协议，而会话的概念则更为抽象，难以用协议来进行描述，所以在后来的 TCP/IP 协议框架的设计中，便将表示层和会话层与应用层整合在一起，让整个过程更为清晰明了。 1.2.8 简述数据在各层的传输过程 在发送主机端，一个应用层报文被传送到运输层。在最简单的情况下，运输层收取到报文并附上附加信息，该首部将被接收端的运输层使用。应用层报文和运输层首部信息一道构成了运输层报文段。附加的信息可能包括：允许接收端运输层向上向适当的应用程序交付报文的信息以及差错检测位信息。该信息让接收端能够判断报文中的比特是否在途中已被改变。运输层则向网络层传递该报文段，网络层增加了如源和目的端系统地址等网络层首部信息，生成了网络层数据报。该数据报接下来被传递给链路层，在数据链路层数据包添加发送端 MAC 地址和接收端 MAC 地址后被封装成数据帧，在物理层数据帧被封装成比特流，之后通过传输介质传送到对端。 1.2.9 简述网络应用的两种典型模式 客户机/服务器模式(C/S) 对等模式(P2P)：每个应用既是客户机又是服务器。 1.2.10 什么是RFCRequest For Comments，征求意见。每个官方标准都以一个RFC的形式发布。 1.2.11 简述主机之间的通信方式 单工通信：也叫单向通信，发送方和接收方是固定的，消息只能单向传输。例如采集气象数据、家庭电费，网费等数据收集系统，或者打印机等应用主要采用单工通信。 半双工通信：也叫双向交替通信，通信双方都可以发送消息，但同一时刻同一信道只允许单方向发送数据。例如传统的对讲机使用的就是半双工通信。 全双工通信：也叫双向同时通信，全双工通信允许通信双方同时在两个方向是传输，其要求通信双方都具有独立的发送和接收数据的能力。例如平时我们打电话，自己说话的同时也能听到对面的声音。 1.2.12 传输层协议和网络层协议的区别网络层协议负责提供主机间的逻辑通信；运输层协议负责提供进程间的逻辑通信。 1.3 链路层1.3.1 简述几种常见的宽带接入技术我们一般将速率超过 1 Mbps 的接入称为宽带接入，目前常用的宽带接入技术主要包括：ADSL 和 FTTx + LAN。 ADSLADSL 全称为非对称用户数字环路，是铜线宽带接入技术的一种。其非对称体现在用户上行和下行的传输速率不相等，一般上行速率较低，下行速率高。这种接入技术适用于有宽带业务需求的家庭用户或者中小型商务用户等。 FTTx + LAN其中 FTTx 英文翻译为 Fiber To The X，这里的 X 指任何地方，我们可以理解为光纤可以接入到任何地方，而 LAN 指的是局域网。FTTx + LAN 是一种在接入网全部或部分采用光纤传输介质，构成光纤用户线路，从而实现用户高速上网的接入技术，其中用户速率可达 20 Mbps。这种接入技术投资规模小，网络拓展性强，网络可靠稳定，使得其应用广泛，目前是城市汇总较为普及的一种宽带接入技术。 其它还有 光纤同轴混合网（HFC）、光接入技术（有源和无源光纤系统）和无线接入技术等等。 1.3.2 什么是以太网一种局域网标准，IEEE802 1.3.3 什么是CSMA/CD 协议CSMA/CD 为载波侦听多路访问/冲突检测，是像以太网这种广播网络采用的一种机制，我们知道在以太网中多台主机在同一个信道中进行数据传输，CSMA/CD 很好的解决了共享信道通信中出现的问题，它的工作原理主要包括两个部分： 载波监听：当使用 CSMA/CD 协议时，总线上的各个节点都在监听信道上是否有信号在传输，如果有的话，表明信道处于忙碌状态，继续保持监听，直到信道空闲为止。如果发现信道是空闲的，就立即发送数据。 冲突检测：当两个或两个以上节点同时监听到信道空闲，便开始发送数据，此时就会发生碰撞（数据的传输延迟也可能引发碰撞）。当两个帧发生冲突时，数据帧就会破坏而失去了继续传输的意义。在数据的发送过程中，以太网是一直在监听信道的，当检测到当前信道冲突，就立即停止这次传输，避免造成网络资源浪费，同时向信道发送一个「冲突」信号，确保其它节点也发现该冲突。之后采用一种二进制退避策略让待发送数据的节点随机退避一段时间之后重新。 1.3.4 数据链路层上的三个基本问题 封装成帧：将网络层传下来的分组前后分别添加首部和尾部，这样就构成了帧。首部和尾部的一个重要作用是帧定界，也携带了一些必要的控制信息，对于每种数据链路层协议都规定了帧的数据部分的最大长度。 透明传输：帧使用首部和尾部进行定界，如果帧的数据部分含有和首部和尾部相同的内容， 那么帧的开始和结束的位置就会判断错，因此需要在数据部分中出现有歧义的内容前边插入转义字符，如果数据部分出现转义字符，则在该转义字符前再加一个转义字符。在接收端进行处理之后可以还原出原始数据。这个过程透明传输的内容是转义字符，用户察觉不到转义字符的存在。 差错检测：目前数据链路层广泛使用循环冗余检验（CRC）来检查数据传输过程中是否产生比特差错。 1.3.5 MAC 地址和 IP 地址分别有什么作用MAC 地址是数据链路层和物理层使用的地址，是写在网卡上的物理地址。MAC 地址用来定义网络设备的位置。(身份证号)IP 地址是网络层和以上各层使用的地址，是一种逻辑地址。IP 地址用来区别网络上的计算机。（住址） 1.3.6 为什么有了 MAC 地址还需要 IP 地址如果我们只使用 MAC 地址进行寻址的话，我们需要路由器记住每个 MAC 地址属于哪一个子网，不然每一次路由器收到数据包时都要满世界寻找目的 MAC 地址。而我们知道 MAC 地址的长度为 48 位，也就是说最多总共有 2 的 48 次方个 MAC 地址，这就意味着每个路由器需要 256 T 的内存，这显然是不现实的。 和 MAC 地址不同，IP 地址是和地域相关的，在一个子网中的设备，我们给其分配的 IP 地址前缀都是一样的，这样路由器就能根据 IP 地址的前缀知道这个设备属于哪个子网，剩下的寻址就交给子网内部实现，从而大大减少了路由器所需要的内存。 1.3.7 为什么有了 IP 地址还需要 MAC 地址只有当设备连入网络时，才能根据他进入了哪个子网来为其分配 IP 地址，在设备还没有 IP 地址的时候或者在分配 IP 地址的过程中，我们需要 MAC 地址来区分不同的设备。 1.3.8 私网地址和公网地址之间进行转换：同一个局域网内的两个私网地址，经过转换之后外面看到的一样吗当采用静态或者动态转换时，由于一个私网 IP 地址对应一个公网地址，因此经过转换之后的公网 IP 地址是不同的；而采用端口复用方式的话，在一个子网中的所有地址都采用一个公网地址，但是使用的端口是不同的。 1.3.9 简述距离矢量路由算法(Distance-Vector Routing, DV)1.3.10 简述链路状态路由算法(Link State Routing, LS)1.3.11 简述生成树协议(Spanning Tree Protocol, STP)1.3.12 路由器和交换机的区别交换机(switch)：交换机用于局域网，利用主机的物理地址（MAC 地址）确定数据转发的目的地址，它工作与数据链路层。路由器(router)：路由器通过数据包中的目的 IP 地址识别不同的网络从而确定数据转发的目的地址，网络号是唯一的。路由器根据路由选择协议和路由表信息从而确定数据的转发路径，直到到达目的网络，它工作于网络层。 1.3.13 什么是BGP, eBGP, iBGP, IGP1.3.14 简述PPP协议互联网用户通常需要连接到某个 ISP 之后才能接入到互联网，PPP（点对点）协议是用户计算机和 ISP 进行通信时所使用的数据链路层协议。点对点协议为点对点连接上传输多协议数据包提供了一个标准方法。该协议设计的目的主要是用来通过拨号或专线方式建立点对点连接发送数据，使其成为各种主机、网桥和路由器之间简单连接的一种解决方案。 PPP 协议具有以下特点： PPP 协议具有动态分配 IP 地址的能力，其允许在连接时刻协商 IP 地址。 PPP 支持多种网络协议，例如 TCP/IP、NETBEUI 等。 PPP 具有差错检测能力，但不具备纠错能力，所以 PPP 是不可靠传输协议。 无重传的机制，网络开销小，速度快。 PPP 具有身份验证的功能。 1.3.15 为什么 PPP 协议不使用序号和确认机制 IETF 在设计因特网体系结构时把其中最复杂的部分放在 TCP 协议中，而网际协议 IP 则相对比较简单，它提供的是不可靠的数据包服务，在这种情况下，数据链路层没有必要提供比 IP 协议更多的功能。若使用能够实现可靠传输的数据链路层协议，则开销就要增大，这在数据链路层出现差错概率不大时是得不偿失的。 即使数据链路层实现了可靠传输，但其也不能保证网络层的传输也是可靠的，当数据帧在路由器中从数据链路层上升到网络层后，仍有可能因为网络层拥塞而被丢弃。 PPP 协议在帧格式中有帧检验序列，对每一个收到的帧，PPP 都会进行差错检测，若发现差错，则丢弃该帧。 1.3.16 什么是环回/回送使用协议与同一计算机上的服务通信，通常使用一个虚拟的环回网络接口实现，实际上是一个由操作系统提供的软件，可通过TCP/IP与同一主机的其他部分通信。如IPv4地址127::，IPv6地址::1，分配的名称为localhost。发送到环回的IP数据报不会出现在任何网络中。 1.3.17 什么是MTU，什么是路径MTUMaximum Transmission Unit，最大传输单元，以太网有效载荷的字节数限制。 路径MTU：两台主机跨越多个网络通信时，每条链路上可能有不同大小的MTU，整条路径上最小的MTU为路径MTU。 1.3.18 什么是隧道技术将其他协议的数据帧或包重新封装在新的包头中发送。(高/同层分组中携带低层数据) 1.4 IP地址1.4.1 IPv4和IPv6的表示 IPv4: 点分十进制，32位，[0, 255] IPv6: 冒号分隔，十六进制，128位 1.4.2 简述分类寻址 A、B、C类用于单播(网络号+主机)，D类用于组播，E类保留 1.4.3 简述子网寻址 将基础地址中的主机部分进一步划分为一个子网号和一个主机号，站点管理员在子网数和每个子网主机数之间折中。 子网掩码：从一台主机对于的IP地址中获得网络和子网信息，确定网络部分的结束和主机部分的开始。IP地址与子网掩码进行按位与操作，形成前缀。 1.4.4 IPV4 地址不够如何解决 DHCP：动态主机配置协议。动态分配 IP 地址，只给接入网络的设备分配IP地址，因此同一个 MAC 地址的设备，每次接入互联网时，得到的IP地址不一定是相同的，该协议使得空闲的 IP 地址可以得到充分利用。 CIDR：无类别域间路由。CIDR 消除了传统的 A 类、B 类、C 类地址以及划分子网的概念，因而更加有效的分配 IPv4 的地址空间，但无法从根本上解决地址耗尽问题。 NAT：网络地址转换协议。我们知道属于不同局域网的主机可以使用相同的 IP 地址，从而一定程度上缓解了 IP 资源枯竭的问题。然而主机在局域网中使用的 IP 地址是不能在公网中使用的，当局域网主机想要与公网进行通信时， NAT 方法可以将该主机 IP 地址转换成全球 IP 地址。该协议能够有效解决 IP 地址不足的问题。 IPv6 ：作为接替 IPv4 的下一代互联网协议，其可以实现 2 的 128 次方个地址，而这个数量级，即使是给地球上每一颗沙子都分配一个IP地址，该协议能够从根本上解决 IPv4 地址不够用的问题。 1.4.5 列举几种特殊用途的IPv4地址127.0.0.1/8：回送地址 10.0.0.0/8：内联网地址 192.168.0.0./16：内联网地址 255.255.255.255/32：本地广播地址 1.4.6 IPv4可以被映射成IPv6地址吗，反之可行吗可以，反之不可行。 1.4.7 简述单播、广播、组播和任播 单播(unicast): 是指封包在计算机网络的传输中，目的地址为单一目标的一种传输方式。它是现今网络应用最为广泛，通常所使用的网络协议或服务大多采用单播传输，例如一切基于TCP的协议。 组播(multicast): 也叫多播， 多点广播或群播。 指把信息同时传递给一组目的地址。它使用策略是最高效的，因为消息在每条网络链路上只需传递一次，而且只有在链路分叉的时候，消息才会被复制。任意源组播和特定源组播。 **广播(broadcast):**是指封包在计算机网络中传输时，目的地址为网络中所有设备的一种传输方式。实际上，这里所说的“所有设备”也是限定在一个范围之中，称为“广播域”。 **任播(anycast):**是一种网络寻址和路由的策略，使得资料可以根据路由拓朴来决定送到“最近”或“最好”的目的地。 1.4.8 ARP 地址解析协议的原理和地址解析过程 ARP（Address Resolution Protocol）是地址解析协议的缩写，该协议提供根据 IP 地址获取物理地址的功能，它工作在第二层，是一个数据链路层协议，其在本层和物理层进行联系，同时向上层提供服务。当通过以太网发送 IP 数据包时，需要先封装 32 位的 IP 地址和 48位 MAC 地址。在局域网中两台主机进行通信时需要依靠各自的物理地址进行标识，但由于发送方只知道目标 IP 地址，不知道其 MAC 地址，因此需要使用地址解析协议。 ARP 协议的解析过程如下： ① 首先，每个主机都会在自己的 ARP 缓冲区中建立一个 ARP 列表，以表示 IP 地址和 MAC 地址之间的对应关系； ② 当源主机要发送数据时，首先检查 ARP 列表中是否有 IP 地址对应的目的主机 MAC 地址，如果存在，则可以直接发送数据，否则就向同一子网的所有主机发送 ARP 数据包（广播）。该数据包包括的内容有源主机的 IP 地址和 MAC 地址，以及目的主机的 IP 地址。 ③ 当本网络中的所有主机收到该 ARP 数据包时，首先检查数据包中的 目的 主机IP 地址是否是自己的 IP 地址，如果不是，则忽略该数据包，如果是，则首先从数据包中取出源主机的 IP 和 MAC 地址写入到 ARP 列表中，如果已经存在，则覆盖，然后将自己的 MAC 地址写入 ARP 响应包中，告诉源主机自己是它想要找的 MAC 地址。 ④ 源主机收到 ARP 响应包后。将目的主机的 IP 和 MAC 地址写入 ARP 列表，并利用此信息发送数据。如果源主机一直没有收到 ARP 响应数据包，表示 ARP 查询失败。 1.5 Internet协议1.5.1 IP 协议的定义和作用IP 协议（Internet Protocol）又称互联网协议，是支持网间互联的数据包协议。该协议工作在网络层，主要目的就是为了提高网络的可扩展性，和传输层 TCP 相比，IP 协议提供一种无连接/不可靠、尽力而为的数据包传输服务，其与TCP协议（传输控制协议）一起构成了TCP/IP 协议族的核心。IP 协议主要有以下几个作用： 寻址和路由：在IP 数据包中会携带源 IP 地址和目的 IP 地址来标识该数据包的源主机和目的主机。IP 数据报在传输过程中，每个中间节点（IP 网关、路由器）只根据网络地址进行转发，如果中间节点是路由器，则路由器会根据路由表选择合适的路径。IP 协议根据路由选择协议提供的路由信息对 IP 数据报进行转发，直至抵达目的主机。 分段与重组：IP 数据包在传输过程中可能会经过不同的网络，在不同的网络中数据包的最大长度限制是不同的，IP 协议通过给每个 IP 数据包分配一个标识符以及分段与组装的相关信息，使得数据包在不同的网络中能够传输，被分段后的 IP 数据报可以独立地在网络中进行转发，在到达目的主机后由目的主机完成重组工作，恢复出原来的 IP 数据包。 1.5.2 简述IPv4 Header各个字段的含义 头部大小可变。 版本：IP数据报的版本号，IPv4为4，IPv6为6. IHL，头部长度，保存头部中32位字的数量 DS，区分服务 ECN，显式拥塞通知 总长度：数据报总长度，字节为单位。被分片时，反应具体的分片长度。 标识：标识属于同一组的分片 TTL：TTL 是指生存时间，简单来说，它表示了数据包在网络中的时间。每经过一个路由器后 TTL 就减一，这样 TTL 最终会减为 0 ，当 TTL 为 0 时，则将数据包丢弃。通过设置 TTL 可以避免这两个路由器之间形成环导致数据包在环路上死转的情况，由于有了 TTL ，当 TTL 为 0 时，数据包就会被抛弃。 协议：有效载荷的数据类型。TCP: 6, UDP: 17。 头部校验和：仅计算头部。 源IP地址 目的IP地址 （选项部分） 头部之后是载荷(Payload)部分 1.5.3 简述IPv6 Header各个字段的含义头部大小固定。 版本：IP数据报的版本号，IPv4为4，IPv6为6. DS，区分服务 ECN，显式拥塞通知 流标签 负载长度 下一个头部：说明头部之后其他扩展头部的存在和类型，形成头部链，数据跟在头部链后。 跳数限制 源IP地址 目的IP地址 1.5.4 列举几个IPv6头部类型逐条选项（紧跟IPv6头部），超大有效载荷，路由头部，分片头部 1.5.5 简述路由器的分组转发流程① 从 IP 数据包中提取出目的主机的 IP 地址，找到其所在的网络； ② 判断目的 IP 地址所在的网络是否与本路由器直接相连，如果是，则不需要经过其它路由器直接交付，否则执行 ③； ③ 检查路由表中是否有目的 IP 地址的特定主机路由。如果有，则按照路由表传送到下一跳路由器中，否则执行 ④； ④ 逐条检查路由表，若找到匹配路由，则按照路由表转发到下一跳路由器中，否则执行步骤 ⑤； ⑤ 若路由表中设置有默认路由，则按照默认路由转发到默认路由器中，否则执行步骤 ⑥； ⑥ 无法找到合适路由，向源主机报错。 1.5.6 路由器内转发表内有哪些必要字段 目的地IP地址 掩码：掩码结果与条目中的多个目的地进行比较 下一跳：网关，下一个IP实体的IP地址 接口：下一跳的网络接口 1.5.7 如何在转发表内找到合适的下一跳 LPM，最长前缀匹配算法 1.5.8 什么是移动IP使用移动 IP 可将 IP 数据报路由到移动节点。无论移动节点连接到何处，移动节点的家乡地址可始终标识该移动节点。如果移动节点不在家乡网络上，则转交地址将与移动节点的家乡地址相关联。转交地址可提供有关移动节点当前连接点的信息。移动 IP 使用注册机制向家乡代理注册转交地址。 1.5.9 对比强弱主机模式在弱主机模式下，IP 主机（IPv4 或 IPv6）可在未分配正处于发送状态的数据包的源 IP 地址的接口上发送数据包。这称为弱主机发送行为。IP 主机还可在未分配处于接收状态的数据包的目标 IP 地址的接口上接收数据包。这称为弱主机接收行为。 在强主机模式下，发送和接收行为有所不同。使用强主机发送，主机仅可在分配了处于发送状态的数据包的源 IP 地址的接口上发送数据包。使用强主机接收，主机仅可在分配了处于接收状态的数据包的目标 IP 地址的接口上接收数据包。 1.6 DHCP与自动配置1.6.1 简述DHCPDHCP(Dynamic Host Configuration Protocol),动态主机配置协议，是一个应用层协议。当我们将客户主机ip地址设置为动态获取方式时，DHCP服务器就会根据DHCP协议给客户端分配IP，使得客户机能够利用这个IP上网。DHCP的前身是BOOTP协议（Bootstrap Protocol）,BOOTP被创建出来为连接到网络中的设备自动分配地址，后来被DHCP取代了，DHCP比BOOTP更加复杂，功能更强大。 1.6.2 简述DHCP的过程 DHCP的实现分为4步，分别是：第一步：Client端在局域网内发起一个DHCP Discover包，目的是想发现能够给它提供IP的DHCP Server。第二步：可用的DHCP Server接收到Discover包之后，通过发送DHCP Offer包给予Client端应答，意在告诉Client端它可以提供IP地址。第三步：Client端接收到Offer包之后，发送DHCP Request包请求分配IP。第四步：DHCP Server发送ACK数据包，确认信息。 1.6.3 在DHCP中，分配的IP若快过期怎么办客户机可以提出延长租用期的请求，续订IP租约。 1.7 防火墙和网络地址转换(NAT)1.7.1 什么是防火墙一种能够限制所转发的流量类型的路由器。 1.7.2 常用的两种防火墙 代理防火墙：是一个多宿主的服务器主机，一般在终端。在应用层中继特定类型的流量。如HTTP代理防火墙和SOCKS防火墙。 包过滤防火墙：是一个互联网路由器，能丢弃特定的包。 1.7.3 什么是NAT 一种允许在互联网的不同地方重复使用相同IP地址集的机制。 NAT（Network Address Translation），即网络地址转换，它是一种把内部私有网络地址翻译成公有网络 IP 地址的技术。该技术不仅能解决 IP 地址不足的问题，而且还能隐藏和保护网络内部主机，从而避免来自外部网络的攻击。 NAT 的实现方式主要有三种： 静态转换：内部私有 IP 地址和公有 IP 地址是一对一的关系，并且不会发生改变。通过静态转换，可以实现外部网络对内部网络特定设备的访问，这种方式原理简单，但当某一共有 IP 地址被占用时，跟这个 IP 绑定的内部主机将无法访问 Internet。动态转换：采用动态转换的方式时，私有 IP 地址每次转化成的公有 IP 地址是不唯一的。当私有 IP 地址被授权访问 Internet 时会被随机转换成一个合法的公有 IP 地址。当 ISP 通过的合法 IP 地址数量略少于网络内部计算机数量时，可以采用这种方式。端口多路复用：该方式将外出数据包的源端口进行端口转换，通过端口多路复用的方式，实现内部网络所有主机共享一个合法的外部 IP 地址进行 Internet 访问，从而最大限度地节约 IP 地址资源。同时，该方案可以隐藏内部网络中的主机，从而有效避免来自 Internet 的攻击。 1.7.4 NAT的工作原理是什么重写通过路由器的数据包的识别信息。 1.7.5 NAT有哪些缺点 需特殊配置 需重写数据包的寻址信息，对一些其他的应用协议造成困扰，如FTP，UDP的分片 1.8 Internet 控制报文协议(ICMP)1.8.1 ICMP 协议概念/作用ICMP（Internet Control Message Protocol）是因特网控制报文协议，主要是实现 IP 协议中未实现的部分功能，是一种网络层协议。该协议并不传输数据，只传输控制信息来辅助网络层通信。其主要的功能是验证网络是否畅通（确认接收方是否成功接收到 IP 数据包）以及辅助 IP 协议实现可靠传输（若发生 IP 丢包，ICMP 会通知发送方 IP 数据包被丢弃的原因，之后发送方会进行相应的处理）。 1.8.2 ICMP 的应用PingPing（Packet Internet Groper），即因特网包探测器，是一种工作在网络层的服务命令，主要用于测试网络连接量。本地主机通过向目的主机发送 ICMP Echo 请求报文，目的主机收到之后会发送 Echo 响应报文，Ping 会根据时间和成功响应的次数估算出数据包往返时间以及丢包率从而推断网络是否通常、运行是否正常等。 TraceRouteTraceRoute 是 ICMP 的另一个应用，其主要用来跟踪一个分组从源点耗费最少 TTL 到达目的地的路径。TraceRoute 通过逐渐增大 TTL 值并重复发送数据报来实现其功能，首先，TraceRoute 会发送一个 TTL 为 1 的 IP 数据报到目的地，当路径上的第一个路由器收到这个数据报时，它将 TTL 的值减 1，此时 TTL = 0，所以路由器会将这个数据报丢掉，并返回一个差错报告报文，之后源主机会接着发送一个 TTL 为 2 的数据报，并重复此过程，直到数据报能够刚好到达目的主机。此时 TTL = 0，因此目的主机要向源主机发送 ICMP 终点不可达差错报告报文，之后源主机便知道了到达目的主机所经过的路由器 IP 地址以及到达每个路由器的往返时间。 ICMPv6中的邻居发现协议。 1.8.3 两台电脑连起来后 ping 不通，你觉得可能存在哪些问题？ 首先看网络是否连接正常，检查网卡驱动是否正确安装。 局域网设置问题，检查 IP 地址是否设置正确。 看是否被防火墙阻拦（有些设置中防火墙会对 ICMP 报文进行过滤），如果是的话，尝试关闭防火墙 。 看是否被第三方软件拦截。 两台设备间的网络延迟是否过大（例如路由设置不合理），导致 ICMP 报文无法在规定的时间内收到。 1.8.4 ICMP报文的分为哪两类差错报文：有关IP数据报传递 查询/信息类报文：有关信息采集和配置 1.8.5 列举几个常见的差错报文目的不可达，主机不可达，端口不可达，重定向 1.8.6 列举几个常见的查询/信息类报文回显请求/应答(ping)，路由器请求和通告，组播侦听发现(MLD)，邻居请求和通告 1.9 广播和本地组播1.9.1 IPv4和IPv6对广播和组播的支持情况IPv4均支持，IPv6只支持组播。 1.9.2 TCP使用广播/组播吗不使用，使用单播。UDP, ICMPv4会使用广播/组播。 1.9.3 什么是IGMPIGMP（互联网组管理协议）是一种互联网协议，使得互联网上的主机向临近路由器报告它的广播组成员。 广播使得互联网上的一个主机向网上确认对，于源主机发送内容感兴趣的计算机发送信息。 IGMP提供了在转发组播数据包到目的地的最后阶段所需的信息，实现如下双向的功能： 主机通过IGMP通知路由器希望接收或离开某个特定组播组的信息。 路由器通过IGMP周期性地查询局域网内的组播组成员是否处于活动状态，实现所连网段组成员关系的收集与维护。 1.9.4 什么是MLD组播侦听者发现协议MLD（Multicast Listener Discovery）是负责IPv6组播成员管理的协议，用来在IPv6成员主机和与其直接相邻的组播路由器之间建立和维护组播组成员关系。MLD通过在成员主机和组播路由器之间交互MLD报文实现组成员管理功能，MLD报文封装在IPv6报文中。 1.10 用户数据报协议UDP1.10.1 什么是UDP一种保留消息边界的简单的无连接的面向数据包的传输层协议。不提供差错纠正、队列管理、重复消除、流量控制和拥塞控制，只提供差错检测。可靠性和保护性的缺失换来更少的开销。可应用组播/广播。 1.10.2 简述UDP头部的各个字段 源端口号：辨认发送进程 目的端口号：辨认接受进程 长度：头部加数据的总长度 校验和：第一个端到端的传输层校验和，覆盖头部、数据和伪头部。 头部后面紧跟数据 1.10.3 IP数据报何时会被分片，会被谁分片，何时重组若数据报大于MTU会被分片，可被主机或任何中间路由器分片，直到它到达目的地才会被重组(原因：可能每个分片经过不同路径)。任何一个分片丢失会导致整个数据报丢失。 1.10.4 关于分片的字段 标识：同一分组的不同分片具有相同标识，便于重组 分片偏移：用于重组 MF：指明该分片后面是否还有更多分片(是否是最后一个分片) 1.10.5 TCP经常被分片吗，UDP呢TCP尽量避免分片，UDP会被分片。互联网分片流量大多数都是UDP的，常见的被分片的流量类型都是基于UDP的多媒体流量，若分片丢失，可通过插值等方法恢复。 1.10.6 简述重组超时一个数据报的任何一个分片首先到达时，IP层就启动一个计时器，若不这样做，不能到达的分片可能会耗尽接收方的缓存。收到新分片时也不会重置计时器。若超时，则判定为数据报丢失。 1.10.7 UDP会被截断吗，TCP呢UDP具有消息边界，若API套接字指定大小较小，会截断UDP数据报。TCP是字节流协议，无消息边界，不会被截断。 1.10.8 UDP 为什么是不可靠的？bind 和 connect 对于 UDP 的作用是什么UDP 只有一个 socket 接收缓冲区，没有 socket 发送缓冲区，即只要有数据就发，不管对方是否可以正确接收。而在对方的 socket 接收缓冲区满了之后，新来的数据报无法进入到 socket 接受缓冲区，此数据报就会被丢弃，因此 UDP 不能保证数据能够到达目的地，此外，UDP 也没有流量控制和重传机制，故UDP的数据传输是不可靠的。 和 TCP 建立连接时采用三次握手不同，UDP 中调用 connect 只是把对端的 IP 和 端口号记录下来，并且 UDP 可多多次调用 connect 来指定一个新的 IP 和端口号，或者断开旧的 IP 和端口号（通过设置 connect 函数的第二个参数）。和普通的 UDP 相比，调用 connect 的 UDP 会提升效率，并且在高并发服务中会增加系统稳定性。 当 UDP 的发送端调用 bind 函数时，就会将这个套接字指定一个端口，若不调用 bind 函数，系统内核会随机分配一个端口给该套接字。当手动绑定时，能够避免内核来执行这一操作，从而在一定程度上提高性能。 1.11 域名系统DNS1.11.1 什么是DNSDomain Name System，域名系统，一种分布式的分层的客户机/服务器网络数据库，处于应用层，TCP/IP应用程序使用它来完成主机名称和IP地址之间的映射(反之亦然)。 1.11.2 为什么需要DNS通常我们有两种方式识别主机：通过主机名或者 IP 地址。人们喜欢便于记忆的主机名表示，而路由器则喜欢定长的、有着层次结构的 IP 地址。为了满足这些不同的偏好，我们就需要一种能够进行主机名到 IP 地址转换的目录服务，域名系统作为将域名和 IP 地址相互映射的一个分布式数据库，能够使人更方便地访问互联网。 1.11.3 简述DNS解析原理DNS 采用了分布式的设计方案，其域名空间采用一种树形的层次结构： 上图展示了 DNS 服务器的部分层次结构，从上到下依次为根域名服务器、顶级域名服务器和权威域名服务器。其实根域名服务器在因特网上有13个，大部分位于北美洲。第二层为顶级域服务器，这些服务器负责顶级域名（如 com、org、net、edu）和所有国家的顶级域名（如uk、fr、ca 和 jp）。在第三层为权威 DNS 服务器，因特网上具有公共可访问主机（例如 Web 服务器和邮件服务器）的每个组织机构必须提供公共可访问的 DNS 记录，这些记录由组织机构的权威 DNS 服务器负责保存，这些记录将这些主机的名称映射为 IP 地址。 除此之外，还有一类重要的 DNS 服务器，叫做本地 DNS 服务器。本地 DNS 服务器严格来说不在 DNS 服务器的层次结构中，但它对 DNS 层次结构是很重要的。一般来说，每个网络服务提供商（ISP） 都有一台本地 DNS 服务器。当主机与某个 ISP 相连时，该 ISP 提供一台主机的 IP 地址，该主机具有一台或多台其本地 DNS 服务器的 IP 地址。主机的本地 DNS 服务器通常和主机距离较近，当主机发起 DNS 请求时，该请求被发送到本地 DNS 服务器，它起着代理的作用，并将该请求转发到 DNS 服务器层次结构中。 我们以一个例子来了解 DNS 的工作原理，假设主机 A（IP 地址为 abc.xyz.edu） 想知道主机 B 的 IP 地址 （def.mn.edu），如下图所示，主机 A 首先向它的本地 DNS 服务器发送一个 DNS 查询报文。该查询报文含有被转换的主机名 def.mn.edu。本地 DNS 服务器将该报文转发到根 DNS 服务器，根 DNS 服务器注意到查询的 IP 地址前缀为 edu 后向本地 DNS 服务器返回负责 edu 的顶级域名服务器的 IP 地址列表。该本地 DNS 服务器则再次向这些 顶级域名服务器发送查询报文。该顶级域名服务器注意到 mn.edu 的前缀，并用权威域名服务器的 IP 地址进行响应。通常情况下，顶级域名服务器并不总是知道每台主机的权威 DNS 服务器的 IP 地址，而只知道中间的某个服务器，该中间 DNS 服务器依次能找到用于相应主机的 IP 地址，我们假设中间经历了权威服务器 ① 和 ②，最后找到了负责 def.mn.edu 的权威 DNS 服务器 ③，之后，本地 DNS 服务器直接向该服务器发送查询报文从而获得主机 B 的IP 地址。 1.11.4 简述两种解析查询方式 递归查询：如果主机所询问的本地域名服务器不知道被查询域名的 IP 地址，那么本地域名服务器就以 DNS 客户端的身份，向其他根域名服务器继续发出查询请求报文，即替主机继续查询，而不是让主机自己进行下一步查询，如上图步骤（1）和（10）。 迭代查询：当根域名服务器收到本地域名服务器发出的迭代查询请求报文时，要么给出所要查询的 IP 地址，要么告诉本地服务器下一步应该找哪个域名服务器进行查询，然后让本地服务器进行后续的查询，如上图步骤（2）~（9）。 1.11.5 每个区域只有一台拥有相同数据的DNS服务器吗至少2台，为了形成冗余：如果一台服务器不能工作，至少另一台可以使用。主服务器+多个从服务器。 1.11.6 DNS使用TCP还是UDPDNS 既使用 TCP 又使用 UDP。 当进行区域传送（主域名服务器向辅助域名服务器传送变化的那部分数据）时会使用 TCP，因为数据同步传送的数据量比一个请求和应答的数据量要多，而 TCP 允许的报文长度更长，因此为了保证数据的正确性，会使用基于可靠连接的 TCP。 当客户端向 DNS 服务器查询域名 ( 域名解析) 的时候，一般返回的内容不会超过 UDP 报文的最大长度，即 512 字节。用 UDP 传输时，不需要经过 TCP 三次握手的过程，从而大大提高了响应速度，但这要求域名解析器和域名服务器都必须自己处理超时和重传从而保证可靠性。 1.11.7 列举几种重要的DNS资源记录(RR)类型 A：IPv4地址记录(32位地址) AAAA：IPv6地址记录(128位地址) NS：Name Server，名称服务器，即提供区域授权名称服务器的名称 CNAME：Canonical Name，规范名称，可以建立公共服务的别名，指向其他RR。CNAME可以指向CNAME，形成CNAME链。通常用于内容交付网络(CDN)。 PTR：指针记录，用于逆向DNS查询 MX：邮件交换器 1.11.8 域名和 IP 的关系，一个 IP 可以对应多个域名吗IP 在同一个网络中是唯一的，用来标识每一个网络上的设备，其相当于一个人的身份证号；域名在同一个网络中也是唯一的，就像一个人的名字，绰号。假如你有多个不同的绰号，你的朋友可以用其中任何一个绰号叫你，但你的身份证号码却是唯一的。由此我们可以看出一个域名只能对应一个 IP 地址，是一对一的关系；而一个 IP 却可以对应多个域名，是一对多的关系。 1.12 TCP连接管理1.12.1 什么是TCP，它与IP有何区别一种带累积正向确认的滑动窗口协议，一种面向连接的、可靠的字节流协议（单播）。 重传机制，实现差错纠正、重复消除。 滑动窗口大小可变，实现流量控制和拥塞控制。 1.12.2 简述TCP Header的各个字段含义 源端口 目的端口 序列号(SEQ)：代表包含该序列号的报文段的数据中的第一个字节 确认号(ACK)：代表该确认号的发送方期待接受的下一个序列号 头部长度 CWR：拥塞窗口减 ECE：ECN回显 URG：紧急 ACK：确认 RST：重置连接 SYN：同步序列号 FIN：结束连接 窗口大小：指定窗口的字节数，用于流量控制 校验和：强制，头部+数据+伪头部 紧急指针：紧急数据用于告知紧急数据所在的位置，在URG标志位为 1 时才有效。当紧急数据存在时，TCP 必须通知接收方的上层实体，接收方会对紧急模式采取相应的处理。 （选项） 1.12.3 SYN、FIN、ACK都会消耗序列号吗SYN、FIN以及应用程序字节会，意味着使用重传进行可靠传输。 ACK不会。 1.12.4 如何标识一个TCP连接四元组（源IP，源端口，目的IP，目的端口） 1.12.5 ★ 如何开启一个TCP连接 三次握手是 TCP 连接的建立过程。在握手之前，主动打开连接的客户端结束 CLOSE 阶段，被动打开的服务器也结束 CLOSE 阶段，并进入 LISTEN 阶段。随后进入三次握手阶段： ① 首先客户端向服务器发送一个 SYN 包，并等待服务器确认，其中： 标志位为 SYN，表示请求建立连接；序号为 Seq = x（x 一般为 1）；随后客户端进入 SYN-SENT 阶段。② 服务器接收到客户端发来的 SYN 包后，对该包进行确认后结束 LISTEN 阶段，并返回一段 TCP 报文，其中： 标志位为 SYN 和 ACK，表示确认客户端的报文 Seq 序号有效，服务器能正常接收客户端发送的数据，并同意创建新连接；序号为 Seq = y；确认号为 Ack = x + 1，表示收到客户端的序号 Seq 并将其值加 1 作为自己确认号 Ack 的值，随后服务器端进入 SYN-RECV 阶段。③ 客户端接收到发送的 SYN + ACK 包后，明确了从客户端到服务器的数据传输是正常的，从而结束 SYN-SENT 阶段。并返回最后一段报文。其中： 标志位为 ACK，表示确认收到服务器端同意连接的信号；序号为 Seq = x + 1，表示收到服务器端的确认号 Ack，并将其值作为自己的序号值；确认号为 Ack= y + 1，表示收到服务器端序号 seq，并将其值加 1 作为自己的确认号 Ack 的值。随后客户端进入 ESTABLISHED。当服务器端收到来自客户端确认收到服务器数据的报文后，得知从服务器到客户端的数据传输是正常的，从而结束 SYN-RECV 阶段，进入 ESTABLISHED 阶段，从而完成三次握手。 1.12.6 ★ 如何关闭一个TCP连接四次挥手即 TCP 连接的释放，这里假设客户端主动释放连接。在挥手之前主动释放连接的客户端结束 ESTABLISHED 阶段，随后开始四次挥手： ① 首先客户端向服务器发送一段 TCP 报文表明其想要释放 TCP 连接，其中： 标记位为 FIN，表示请求释放连接；序号为 Seq = u；随后客户端进入 FIN-WAIT-1 阶段，即半关闭阶段，并且停止向服务端发送通信数据。② 服务器接收到客户端请求断开连接的 FIN 报文后，结束 ESTABLISHED 阶段，进入 CLOSE-WAIT 阶段并返回一段 TCP 报文，其中： 标记位为 ACK，表示接收到客户端释放连接的请求；序号为 Seq = v；确认号为 Ack = u + 1，表示是在收到客户端报文的基础上，将其序号值加 1 作为本段报文确认号 Ack 的值；随后服务器开始准备释放服务器端到客户端方向上的连接。客户端收到服务器发送过来的 TCP 报文后，确认服务器已经收到了客户端连接释放的请求，随后客户端结束 FIN-WAIT-1 阶段，进入 FIN-WAIT-2 阶段。 ③ 服务器端在发出 ACK 确认报文后，服务器端会将遗留的待传数据传送给客户端，待传输完成后即经过 CLOSE-WAIT 阶段，便做好了释放服务器端到客户端的连接准备，再次向客户端发出一段 TCP 报文，其中： 标记位为 FIN 和 ACK，表示已经准备好释放连接了；序号为 Seq = w；确认号 Ack = u + 1，表示是在收到客户端报文的基础上，将其序号 Seq 的值加 1 作为本段报文确认号 Ack 的值。随后服务器端结束 CLOSE-WAIT 阶段，进入 LAST-ACK 阶段。并且停止向客户端发送数据。 ④ 客户端收到从服务器发来的 TCP 报文，确认了服务器已经做好释放连接的准备，于是结束 FIN-WAIT-2 阶段，进入 TIME-WAIT 阶段，并向服务器发送一段报文，其中： 标记位为 ACK，表示接收到服务器准备好释放连接的信号；序号为 Seq= u + 1，表示是在已收到服务器报文的基础上，将其确认号 Ack 值作为本段序号的值；确认号为 Ack= w + 1，表示是在收到了服务器报文的基础上，将其序号 Seq 的值作为本段报文确认号的值。随后客户端开始在 TIME-WAIT 阶段等待 2 MSL。服务器端收到从客户端发出的 TCP 报文之后结束 LAST-ACK 阶段，进入 CLOSED 阶段。由此正式确认关闭服务器端到客户端方向上的连接。客户端等待完 2 MSL 之后，结束 TIME-WAIT 阶段，进入 CLOSED 阶段，由此完成「四次挥手」。 1.12.7 如果三次握手的时候每次握手信息对方没有收到会怎么样 若第一次握手服务器未接收到客户端请求建立连接的数据包时，服务器不会进行任何相应的动作，而客户端由于在一段时间内没有收到服务器发来的确认报文， 因此会等待一段时间后重新发送 SYN 同步报文，若仍然没有回应，则重复上述过程直到发送次数超过最大重传次数限制后，建立连接的系统调用会返回 -1。 若第二次握手客户端未接收到服务器回应的 ACK 报文时，客户端会采取第一次握手失败时的动作，这里不再重复，而服务器端此时将阻塞在 accept() 系统调用处等待 client 再次发送 ACK 报文。 若第三次握手服务器未接收到客户端发送过来的 ACK 报文，同样会采取类似于客户端的超时重传机制，若重传次数超过限制后仍然没有回应，则 accep() 系统调用返回 -1，服务器端连接建立失败。但此时客户端认为自己已经连接成功了，因此开始向服务器端发送数据，但是服务器端的 accept() 系统调用已返回，此时没有在监听状态。因此服务器端接收到来自客户端发送来的数据时会发送 RST 报文给 客户端，消除客户端单方面建立连接的状态。 1.12.8 为什么要进行三次握手？两次握手可以吗？三次握手的主要目的是确认自己和对方的发送和接收都是正常的，从而保证了双方能够进行可靠通信。若采用两次握手，当第二次握手后就建立连接的话，此时客户端知道服务器能够正常接收到自己发送的数据，而服务器并不知道客户端是否能够收到自己发送的数据。 我们知道网络往往是非理想状态的（存在丢包和延迟），当客户端发起创建连接的请求时，如果服务器直接创建了这个连接并返回包含 SYN、ACK 和 Seq 等内容的数据包给客户端，这个数据包因为网络传输的原因丢失了，丢失之后客户端就一直接收不到返回的数据包。由于客户端可能设置了一个超时时间，一段时间后就关闭了连接建立的请求，再重新发起新的请求，而服务器端是不知道的，如果没有第三次握手告诉服务器客户端能否收到服务器传输的数据的话，服务器端的端口就会一直开着，等到客户端因超时重新发出请求时，服务器就会重新开启一个端口连接。长此以往， 这样的端口越来越多，就会造成服务器开销的浪费。 1.12.9 第 2 次握手传回了 ACK，为什么还要传回 SYNACK 是为了告诉客户端发来的数据已经接收无误，而传回 SYN 是为了告诉客户端，服务端收到的消息确实是客户端发送的消息。 1.12.10 为什么要四次挥手释放 TCP 连接时之所以需要四次挥手，是因为 FIN 释放连接报文和 ACK 确认接收报文是分别在两次握手中传输的。 当主动方在数据传送结束后发出连接释放的通知，由于被动方可能还有必要的数据要处理，所以会先返回 ACK 确认收到报文。当被动方也没有数据再发送的时候，则发出连接释放通知，对方确认后才完全关闭TCP连接。 举个例子：A 和 B 打电话，通话即将结束后，A 说“我没啥要说的了”，B回答“我知道了”，但是 B 可能还会有要说的话，A 不能要求 B 跟着自己的节奏结束通话，于是 B 可能又巴拉巴拉说了一通，最后 B 说“我说完了”，A 回答“知道了”，这样通话才算结束。 1.12.11 什么是TCP半关闭 被动方收到FIN后，返回一个ACK，但继续发送数据给主动方，此时处于半关闭状态。发完数据后，再发一个FIN，等待对方确认后完全关闭连接。 1.12.12 什么是TCP半开状态在未告知另一端的情况下，通信的一端关闭，通常发生在主机崩溃/切断电源（不是正常关机）的情况下。即使服务器重启后，也会丢失连接信息，若接收到报文，则回复RST作为响应。 1.12.13 简述同时打开TCP连接的过程 4个报文段 双方各发出SYN与各自的SEQ 任一方收到对方的SYN后，都发送一个SYN+ACK 待收到对方的SYN+ACK后，连接建立 1.12.14 简述同时关闭TCP连接的过程 4个报文段 双方各发出FIN 任一方收到对方的FIN后，都发送一个ACK 待收到对方的ACK后，连接关闭 1.12.15 如何选择初始序列号半随机选择，为了避免连接实例间的序列号重叠问题，防止伪造的TCP报文段。 1.12.16 列举几个常用的TCP选项 最大段大小(MSS)：允许从对方接收到的最大报文段。TCP 连接初始化时，通信双方确认最大报文长度。 选择确认(SACK)：了解接收方当前的空洞，帮助对方有效地重传，而不是只重传序列号最小的未确认的数据报。 窗口缩放：在高速数据传输时，可使用该选项协商窗口扩大因子。 时间戳：提供一个 较为精准的 RTT，利于设置合适的RTO，为了更好的实现 TCP 流量控制协议。 数据：TCP 报文中的数据部分也是可选的，例如在 TCP 三次握手和四次挥手过程中，通信双方交换的报文只包含头部信息，数据部分为空，只有当连接成功建立后，TCP 包才真正携带数据。 1.12.17 画出TCP的状态转换图 1.12.18 ★ CLOSE-WAIT 和 TIME-WAIT 的状态和意义在服务器收到客户端关闭连接的请求并告诉客户端自己已经成功收到了该请求之后，服务器进入了 CLOSE-WAIT 状态，然而此时有可能服务端还有一些数据没有传输完成，因此不能立即关闭连接，而 CLOSE-WAIT 状态就是为了保证服务器在关闭连接之前将待发送的数据发送完成。 TIME-WAIT 发生在第四次挥手，当客户端向服务端发送 ACK 确认报文后进入该状态，若取消该状态，即客户端在收到服务端的 FIN 报文后立即关闭连接，此时服务端相应的端口并没有关闭，若客户端在相同的端口立即建立新的连接，则有可能接收到上一次连接中残留的数据包，可能会导致不可预料的异常出现。除此之外，假设客户端最后一次发送的 ACK 包在传输的时候丢失了，由于 TCP 协议的超时重传机制，服务端将重发 FIN 报文，若客户端并没有维持 TIME-WAIT 状态而直接关闭的话，当收到服务端重新发送的 FIN 包时，客户端就会用 RST 包来响应服务端，这将会使得对方认为是有错误发生，然而其实只是正常的关闭连接过程，并没有出现异常情况。 1.12.19 ★TIME-WAIT 为什么是 2MSL当客户端发出最后的 ACK 确认报文时，并不能确定服务器端能够收到该段报文。所以客户端在发送完 ACK 确认报文之后，会设置一个时长为 2 MSL 的计时器。MSL（Maximum Segment Lifetime），指一段 TCP 报文在传输过程中的最大生命周期。2 MSL 即是服务器端发出 FIN 报文和客户端发出的 ACK 确认报文所能保持有效的最大时长。 若服务器在 1 MSL 内没有收到客户端发出的 ACK 确认报文，再次向客户端发出 FIN 报文。如果客户端在 2 MSL 内收到了服务器再次发来的 FIN 报文，说明服务器由于一些原因并没有收到客户端发出的 ACK 确认报文。客户端将再次向服务器发出 ACK 确认报文，并重新开始 2 MSL 的计时。 若客户端在 2MSL 内没有再次收到服务器发送的 FIN 报文，则说明服务器正常接收到客户端 ACK 确认报文，客户端可以进入 CLOSE 阶段，即完成四次挥手。 所以客户端要经历 2 MSL 时长的 TIME-WAIT 阶段，为的是确认服务器能否接收到客户端发出的 ACK 确认报文。 MSL一般为2分钟。 1.12.20 ★TIME_WAIT 状态会导致什么问题，怎么解决我们考虑高并发短连接的业务场景，在高并发短连接的 TCP 服务器上，当服务器处理完请求后主动请求关闭连接，这样服务器上会有大量的连接处于 TIME_WAIT 状态，服务器维护每一个连接需要一个 socket，也就是每个连接会占用一个文件描述符，而文件描述符的使用是有上限的，如果持续高并发，会导致一些正常的 连接失败。 解决方案：服务器可以设置 SO_REUSEADDR 套接字选项来通知内核，如果端口被占用，但 TCP 连接位于 TIME_WAIT 状态时可以重用端口。如果你的服务器程序停止后想立即重启，而新的套接字依旧希望使用同一端口，此时 SO_REUSEADDR 选项就可以避免 TIME-WAIT 状态。 也可以采用长连接的方式减少 TCP 的连接与断开，在长连接的业务中往往不需要考虑 TIME-WAIT 状态，但其实在长连接的业务中并发量一般不会太高。 1.12.21 有很多 CLOSE-WAIT 怎么解决 首先检查是不是自己的代码问题（看是否服务端程序忘记关闭连接），如果是，则修改代码。 调整系统参数，包括句柄相关参数和 TCP/IP 的参数，一般一个 CLOSE_WAIT 会维持至少 2 个小时的时间，我们可以通过调整参数来缩短这个时间。 1.12.22 状态图中如何反映出同时打开TCP连接两端几乎同时发送SYN后，进入SYN_SENT状态。当接收到对方发来的SYN后，进入SYN_RCVD状态，发送新的SYN和ACK。当接收到对方的SYN和ACK后，进入ESTABLISHED状态。 1.12.23 状态图中如何反映出同时关闭TCP连接两端几乎同时发送FIN后，进入FIN_WAIT_1状态。当接收到对方发来的FIN后，进入CLOSING状态，发送最终的ACK。当接收到对方的ACK后，进入TIME_WAIT状态。 1.12.24 产生RST的三个条件 目的端口上无监听的服务器 TCP主动取消一个已有连接 TCP接收到一个根本不存在的连接上的数据报（服务器崩溃后重启） 1.12.25 有哪两种终止连接的方式 通过四次挥手，有序释放，优雅地关闭。在FIN之前，所有排队数据被发送，通常不会丢失数据。 通过RST，终止释放，任何排队数据都将被抛弃，RST会被立即发送。 1.2.26 如果服务器的连接队列已满，接受到新的连接请求后会发送RST吗不会，服务器暂忙是一种软错误，如果发送RST会让客户端认为服务器不存在。正确做法应该是忽略请求，等待客户端重传。 1.2.27 ★ TCP 和 UDP 的区别类型 是否面向连接 传输可靠性 传输形式 传输效率 所需资源 应用场景 首部字节TCP 是 可靠 字节流 慢 多 文件传输、邮件传输 20~60UDP 否 不可靠 数据报文段 快 少 即时通讯、域名转换 8个字节 1.2.28 ★ TCP如何保证可靠性 数据分块：应用数据被分割成 TCP 认为最适合发送的数据块。 序列号和确认应答：TCP 给发送的每一个包进行编号，在传输的过程中，每次接收方收到数据后，都会对传输方进行确认应答，即发送 ACK 报文，这个 ACK 报文当中带有对应的确认序列号，告诉发送方成功接收了哪些数据以及下一次的数据从哪里开始发。除此之外，接收方可以根据序列号对数据包进行排序，把有序数据传送给应用层，并丢弃重复的数据。 校验和： TCP 将保持它首部和数据部分的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到报文段的检验和有差错，TCP 将丢弃这个报文段并且不确认收到此报文段。 流量控制： TCP 连接的双方都有一个固定大小的缓冲空间，发送方发送的数据量不能超过接收端缓冲区的大小。当接收方来不及处理发送方的数据，会提示发送方降低发送的速率，防止产生丢包。TCP 通过滑动窗口协议来支持流量控制机制。 拥塞控制： 当网络某个节点发生拥塞时，减少数据的发送。 ARQ协议： 自动重复请求也是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。 超时重传： 当 TCP 发出一个报文段后，它启动一个定时器，等待目的端确认收到这个报文段。如果超过某个时间还没有收到确认，将重发这个报文段。 1.2.29 TCP 最大连接数限制Client 最大 TCP 连接数client 在每次发起 TCP 连接请求时，如果自己并不指定端口的话，系统会随机选择一个本地端口（local port），该端口是独占的，不能和其他 TCP 连接共享。TCP 端口的数据类型是 unsigned short，因此本地端口个数最大只有 65536，除了端口 0不能使用外，其他端口在空闲时都可以正常使用，这样可用端口最多有 65535 个。 Server最大 TCP 连接数server 通常固定在某个本地端口上监听，等待 client 的连接请求。不考虑地址重用（Unix 的 SO_REUSEADDR 选项）的情况下，即使 server 端有多个 IP，本地监听端口也是独占的，因此 server 端 TCP 连接 4 元组中只有客户端的 IP 地址和端口号是可变的，因此最大 TCP 连接为客户端 IP 数 × 客户端 port 数，对 IPV4，在不考虑 IP 地址分类的情况下，最大 TCP 连接数约为 2 的 32 次方（IP 数）× 2 的 16 次方（port 数），也就是 server 端单机最大 TCP 连接数约为 2 的 48 次方。 然而上面给出的是只是理论上的单机最大连接数，在实际环境中，受到明文规定（一些 IP 地址和端口具有特殊含义，没有对外开放）、机器资源、操作系统等的限制，特别是 sever 端，其最大并发 TCP 连接数远不能达到理论上限。对 server 端，通过增加内存、修改最大文件描述符个数等参数，单机最大并发 TCP 连接数超过 10 万 是没问题的。 1.2.30 ★ 高并发服务器客户端主动关闭连接和服务端主动关闭连接的区别服务端主动关闭连接在高并发场景下，当服务端主动关闭连接时，此时服务器上就会有大量的连接处于 TIME-WAIT 状态【详解见问题 7, 8, 9】 客户端主动关闭连接当客户端主动关闭连接时，我们并不需要关心 TIME-WAIT 状态过多造成的问题，但是需要关注服务端保持大量的 CLOSE-WAIT 状态时会产生的问题【见问题 10 的解决方法】 无论是客户端还是服务器主动关闭连接，从本质上来说，在高并发场景下主要关心的就是服务端的资源占用问题，而这也是采用 TCP 传输协议必须要面对的问题，其问题解决的出发点也是如何处理好服务质量和资源消耗之间的关系。 1.13 TCP超时与重传1.13.1 简述两种重传方式的原理 超时重传（基于时间）：发送方在发送一次数据后就开启一个定时器，在一定时间内如果没有得到发送数据包的 ACK 报文，那么就重新发送数据，在达到一定次数还没有成功的话就放弃重传并发送一个复位信号。其中超时时间的计算是超时的核心，而定时时间的确定往往需要进行适当的权衡，因为当定时时间过长会造成网络利用率不高，定时太短会造成多次重传，使得网络阻塞。在 TCP 连接过程中，会参考当前的网络状况从而找到一个合适的超时时间。 快速重传（基于确认信息的构成）：不超时的情况下，TCP累积确认无法返回新的ACK，或当前ACK包含的选择确认信息(SACK)表明出现失序报文段时，快速重传会推断出现丢包，决定发送新数据或重传。 TCP发送到在观察到至少dupthresh(通常为3)个dupACK后，即重传可能丢失的数据报，而不必出发超时重传。重传时也可以发送新数据。 不采用SACK，在接收到有效ACK前至多只能重传一个数据报。采用SACK（带选择确认的快速重传），ACK可包含额外信息，使得发送端在每个RTT内可以填补多个空缺。 1.13.2 如何设置重传超时RTO根据每个连接的RTT样本估计RTO 经典方法：平滑RTT估计值，指数加权移动平均EWMA $$SRTT=\\alpha(SRTT)+(1-\\alpha)RTT$$ 标准方法：结合平均值和平均偏差来估算 Karn算法：报文段每重传一次，就将重传时间增大一些：新的重传时间 = γ×(旧的重传时间)退避系数 γ 的典型值是2 。当不再发生报文段的重传时，才根据报文段的往返时延更新平均往返时延 RTT 和重传时间的数值。 1.13.3 触发超时重传后如何降低发送率 基于拥塞控制机制减小发送窗口大小 增大RTO退避因子 1.13.4 什么是伪重传，什么是伪超时，如何解决伪重传：没有出现数据丢失却可能引发重传，这种不必要的重传通常由伪超时造成。 伪超时导致的伪重传：网络拥堵时，已发送的报文其实已经被对方确认，ACK包还在传输中。但是由于发送端触发超时重传，又一次重传了其实已经被确认的包。发送端之后又继续重传从已确认包之后的包，导致“回退N”现象，产生更多的重复ACK。最终引发快速重传。 解决方法：DSACK，Eifel检测算法，前移RTO恢复，Eifel响应算法 1.13.5 TCP如何对丢包、失序、重复现象做出响应丢包：超时重传或快速重传 失序：快速重传，严重失序可能会触发伪快速重传 重复：可能会触发伪快速重传 1.13.6 TCP 的停止等待协议是什么停止等待协议是为了实现 TCP 可靠传输而提出的一种相对简单的协议，该协议指的是发送方每发完一组数据后，直到收到接收方的确认信号才继续发送下一组数据。我们通过四种情形来帮助理解停等协议是如何实现可靠传输的： ① 无差错传输 如上述左图所示，A 发送分组 Msg 1，发完就暂停发送，直到收到接收方确认收到 Msg 1 的报文后，继续发送 Msg 2，以此类推，该情形是通信中的一种理想状态。 ② 出现差错 如上述右图所示，发送方发送的报文出现差错导致接收方不能正确接收数据，出现差错的情况主要分为两种： 发送方发送的 Msg 1 在中途丢失了，接收方完全没收到数据。接收方收到 Msg 1 后检测出现了差错，直接丢弃 Msg 1。上面两种情形，接收方都不会回任何消息给发送方，此时就会触发超时传输机制，即发送方在等待一段时间后仍然没有收到接收方的确认，就认为刚才发送的数据丢失了，因此重传前面发送过的数据。 ③ 确认丢失 当接收方回应的 Msg 1 确认报文在传输过程中丢失，发送方无法接收到确认报文。于是发送方等待一段时间后重传 Msg 1，接收方将收到重复的 Msg1 数据包，此时接收方会丢弃掉这个重复报文并向发送方再次发送 Msg1 的确认报文。 ④ 确认迟到 当接收方回应的 Msg 1 确认报文由于网络各种原因导致发送方没有及时收到，此时发送方在超时重传机制的作用下再次发送了 Msg 数据包，接收方此时进行和确认丢失情形下相同的动作（丢弃重复的数据包并再次发送 Msg 1 确认报文）。发送方此时收到了接收方的确认数据包，于是继续进行数据发送。过了一段时间后，发送方收到了迟到的 Msg 1 确认包会直接丢弃。 上述四种情形即停止等待协议中所出现的所有可能情况。 1.13.7 TCP 协议中的定时器TCP中有七种计时器，分别为： 建立连接定时器：顾名思义，该定时器是在建立 TCP 连接的时候使用的，在 TCP 三次握手的过程中，发送方发送 SYN 时，会启动一个定时器（默认为 3 秒），若 SYN 包丢失了，那么 3 秒以后会重新发送 SYN 包，直到达到重传次数。 重传定时器：该计时器主要用于 TCP 超时重传机制中，当TCP 发送报文段时，就会创建特定报文的重传计时器，并可能出现两种情况： ① 若在计时器截止之前发送方收到了接收方的 ACK 报文，则撤销该计时器； ② 若计时器截止时间内并没有收到接收方的 ACK 报文，则发送方重传报文，并将计时器复位。 坚持计时器：我们知道 TCP 通过让接受方指明希望从发送方接收的数据字节数（窗口大小）来进行流量控制，当接收端的接收窗口满时，接收端会告诉发送端此时窗口已满，请停止发送数据。此时发送端和接收端的窗口大小均为0，直到窗口变为非0时，接收端将发送一个 确认 ACK 告诉发送端可以再次发送数据，但是该报文有可能在传输时丢失。若该 ACK 报文丢失，则双方可能会一直等待下去，为了避免这种死锁情况的发生，发送方使用一个坚持定时器来周期性地向接收方发送探测报文段，以查看接收方窗口是否变大。 延迟应答计时器：延迟应答也被称为捎带 ACK，这个定时器是在延迟应答的时候使用的，为了提高网络传输的效率，当服务器接收到客户端的数据后，不是立即回 ACK 给客户端，而是等一段时间，这样如果服务端有数据需要发送给客户端的话，就可以把数据和 ACK 一起发送给客户端了。 保活定时器：该定时器是在建立 TCP 连接时指定 SO_KEEPLIVE 时才会生效，当发送方和接收方长时间没有进行数据交互时，该定时器可以用于确定对端是否还活着。 FIN_WAIT_2 定时器：当主动请求关闭的一方发送 FIN 报文给接收端并且收到其对 FIN 的确认 ACK后进入 FIN_WAIT_2状态。如果这个时候因为网络突然断掉、被动关闭的一端宕机等原因，导致请求方没有收到接收方发来的 FIN，主动关闭的一方会一直等待。该定时器的作用就是为了避免这种情况的发生。当该定时器超时的时候，请求关闭方将不再等待，直接释放连接。 TIME_WAIT 定时器：我们知道在 TCP 四次挥手中，发送方在最后一次挥手之后会进入 TIME_WAIT 状态，不直接进入 CLOSE 状态的主要原因是被动关闭方万一在超时时间内没有收到最后一个 ACK，则会重发最后的 FIN，2 MSL（报文段最大生存时间）等待时间保证了重发的 FIN 会被主动关闭的一段收到且重新发送最后一个 ACK 。还有一个原因是在这 2 MSL 的时间段内任何迟到的报文段会被接收方丢弃，从而防止老的 TCP 连接的包在新的 TCP 连接里面出现。 1.14 TCP流量控制1.14.1 什么是流量控制，原理是什么所谓流量控制就是让发送方的发送速率不要太快，让接收方来得及接收。如果接收方来不及接收发送方发送的数据，那么就会有分组丢失。在 TCP 中利用可边长的滑动窗口机制可以很方便的在 TCP 连接上实现对发送方的流量控制。主要的方式是接收方返回的 ACK 中会包含自己的接收窗口大小，以控制发送方此次发送的数据量大小（发送窗口大小）。 1.14.2 如果接收方滑动窗口满了，发送方会怎么做基于 TCP 流量控制中的滑动窗口协议，我们知道接收方返回给发送方的 ACK 包中会包含自己的接收窗口大小，若接收窗口已满，此时接收方返回给发送方的接收窗口大小为 0，此时发送方会等待接收方发送的窗口大小直到变为非 0 为止，然而，接收方回应的 ACK 包是存在丢失的可能的，为了防止双方一直等待而出现死锁情况，此时就需要坚持计时器来辅助发送方周期性地向接收方查询，以便发现窗口是否变大【坚持计时器参考问题】，当发现窗口大小变为非零时，发送方便继续发送数据。（窗口探测） 1.14.3 TCP 粘包问题为什么会发生TCP粘包和拆包? ① 发送方写入的数据大于套接字缓冲区的大小，此时将发生拆包。 ② 发送方写入的数据小于套接字缓冲区大小，由于 TCP 默认使用 Nagle 算法，只有当收到一个确认后，才将分组发送给对端，当发送方收集了多个较小的分组，就会一起发送给对端，这将会发生粘包。 ③ 进行 MSS （最大报文长度）大小的 TCP 分段，当 TCP 报文的数据部分大于 MSS 的时候将发生拆包。 ④ 发送方发送的数据太快，接收方处理数据的速度赶不上发送端的速度，将发生粘包。 常见解决方法 ① 在消息的头部添加消息长度字段，服务端获取消息头的时候解析消息长度，然后向后读取相应长度的内容。 ② 固定消息数据的长度，服务端每次读取既定长度的内容作为一条完整消息，当消息不够长时，空位补上固定字符。但是该方法会浪费网络资源。 ③ 设置消息边界，也可以理解为分隔符，服务端从数据流中按消息边界分离出消息内容，一般使用换行符。 什么时候需要处理粘包问题？ 当接收端同时收到多个分组，并且这些分组之间毫无关系时，需要处理粘包；而当多个分组属于同一数据的不同部分时，并不需要处理粘包问题。 1.15 TCP拥塞控制1.15.1 什么是拥塞控制，它与流量控制有何区别拥塞：路由器无法处理高速率到达的流量而被迫丢弃数据。 在实际的网络通信系统中，除了发送方和接收方外，还有路由器，交换机等复杂的网络传输线路，此时就需要拥塞控制。拥塞控制是作用于网络的，它是防止过多的数据注入到网络中，避免出现网络负载过大的情况。常用的解决方法有：慢开始和拥塞避免、快重传和快恢复。 拥塞控制往往是一种全局的，防止过多的数据注入到网络之中，而TCP连接的端点只要不能收到对方的确认信息，猜想在网络中发生了拥塞，但并不知道发生在何处，因此，流量控制往往指点对点通信量的控制，是端到端的问题。 1.15.2 简述基于丢包的几种拥塞控制算法 慢开始当发送方开始发送数据时，由于一开始不知道网络负荷情况，如果立即将大量的数据字节传输到网络中，那么就有可能引起网络拥塞。一个较好的方法是在一开始发送少量的数据先探测一下网络状况，即由小到大的增大发送窗口（拥塞窗口 cwnd）。慢开始的慢指的是初始时令 cwnd为 1，即一开始发送一个报文段。如果收到确认，则 cwnd = 2，之后每收到一个确认报文，就令 cwnd = cwnd* 2。 但是，为了防止拥塞窗口增长过大而引起网络拥塞，另外设置了一个慢开始门限 ssthresh。 ① 当 cwnd &lt; ssthresh 时，使用上述的慢开始算法； ② 当 cwnd &gt; ssthresh 时，停止使用慢开始，转而使用拥塞避免算法； ③ 当 cwnd == ssthresh 时，两者均可。 拥塞避免拥塞控制是为了让拥塞窗口 cwnd 缓慢地增大，即每经过一个往返时间 RTT （往返时间定义为发送方发送数据到收到确认报文所经历的时间）就把发送方的 cwnd 值加 1，通过让 cwnd 线性增长，防止很快就遇到网络拥塞状态。 当网络拥塞发生时，让新的慢开始门限值变为发生拥塞时候的值的一半,并将拥塞窗口置为 1 ,然后再次重复两种算法（慢开始和拥塞避免）,这时一瞬间会将网络中的数据量大量降低。 快重传快重传算法要求接收方每收到一个失序的报文就立即发送重复确认，而不要等到自己发送数据时才捎带进行确认，假定发送方发送了 Msg 1 ~ Msg 4 这 4 个报文，已知接收方收到了 Msg 1，Msg 3 和 Msg 4 报文，此时因为接收到收到了失序的数据包，按照快重传的约定，接收方应立即向发送方发送 Msg 1 的重复确认。 于是在接收方收到 Msg 4 报文的时候，向发送方发送的仍然是 Msg 1 的重复确认。这样，发送方就收到了 3 次 Msg 1 的重复确认，于是立即重传对方未收到的 Msg 报文。由于发送方尽早重传未被确认的报文段，因此，快重传算法可以提高网络的吞吐量。 快恢复快恢复算法是和快重传算法配合使用的，该算法主要有以下两个要点： ① 当发送方连续收到三个重复确认，执行乘法减小，慢开始门限 ssthresh 值减半； ② 由于发送方可能认为网络现在没有拥塞，因此与慢开始不同，把 cwnd 值设置为 ssthresh 减半之后的值，然后执行拥塞避免算法，线性增大 cwnd。 1.15.3 画出拥塞控制状态转换图 1.15.4 列举几种基于延迟的拥塞控制算法不断增长的RTT值可以作为拥塞形成的信号。 Vegas算法，FAST算法，Westwood算法 1.15.5 什么是ECN显示拥塞通知，对经过路由器的数据包进行标记（设置IP头部的ECN标志位），可以让主机得知拥塞状况。 1.16 HTTP协议1.16.1 HTTP 头部包含哪些信息HTTP 头部本质上是一个传递额外重要信息的键值对。主要分为：通用头部，请求头部，响应头部和实体头部。 通用头：是客户端和服务器都可以使用的头部，可以在客户端、服务器和其他应用程序之间提供一些非常有用的通用功能，如Date头部。请求头：是请求报文特有的，它们为服务器提供了一些额外信息，比如客户端希望接收什么类型的数据，如Accept头部。响应头：便于客户端提供信息，比如，客服端在与哪种类型的服务器进行交互，如Server头部。实体头：指的是用于应对实体主体部分的头部，比如，可以用实体头部来说明实体主体部分的数据类型，如Content-Type头部。 通用头部 协议头 说明 举例 Cache-Control 用来指定当前的请求/回复中是否使用缓存机制 Cache-Control: no-store Connection 客户端（浏览器）想要优先使用的连接类型 Connection: keep-alive (Upgrade) Date 报文创建时间 Date: Dec, 26 Dec 2015 17: 30: 00 GMT Trailer 会实现说明在报文主体后记录哪些首部字段，该首部字段可以使用在 HTTP/1.1 版本分块传输编码时 Trailer: Expiress Transfer-Encoding 用来改变报文格式 Transfer-Encoding: chunked Upgrade 要求服务器升级到一个高版本协议 Upgrade: HTTP/2.0, SHTTP/1.3, IRC/6.9, RTA/x11 Via 告诉服务器，这个请求是由哪些代理发出的 Via: 1.0 fred, 1.1 itbilu.com.com (Apache/1.1) Warning 一个一般性的警告，表示在实体内容中可能存在错误 Warning: 199 Miscellaneous warning 请求头部 协议头 说明 举例 Accept 告诉服务器自己允许哪些媒体类型 Accept: text/plain Accept-Charset 浏览器申明可接受的字符集 Accept-Charset: utf-8 Accept-Encoding 浏览器申明自己接收的编码方法 Accept-Encoding: gzip, deflate Accept-Language 浏览器可接受的响应内容语言列表 Accept-Language: en-US Authorization 用于表示 HTTP 协议中需要认证资源的认证信息 Authorization: Basic OSdjJGRpbjpvcGVul ANIc2SdDE== Expect 表示客户端要求服务器做出特定的行为 Expect: 100-continue From 发起此请求的用户的邮件地址 From: user@itbilu.com Host 表示服务器的域名以及服务器所监听的端口号 Host: www.itbilu.com:80 If-XXX 条件请求 If-Modified-Since: Dec, 26 Dec 2015 17:30:00 GMT Max-Forwards 限制该消息可被代理及网关转发的次数 Max-Forwards: 10 Range 表示请求某个实体的一部分，字节偏移以 0 开始 Range: bytes=500-999 Referer 表示浏览器所访问的前一个页面，可以认为是之前访问页面的链接将浏览器带到了当前页面 Referer: http://itbilu.com/nodejs User-Agent 浏览器的身份标识字符串 User-Agent: Mozilla/…… 响应头部 协议头 说明 举例 Accept-Ranges 字段的值表示可用于定义范围的单位 Accept-Ranges: bytes Age 创建响应的时间 Age：5744337 ETag 唯一标识分配的资源 Etag：W/“585cd998-7c0f” Location 表示重定向后的 URL Location: http://www.zcmhi.com/archives/94.html Retry-After 告知客户端多久后再发送请求 Retry-After: 120 Server 告知客户端服务器信息 Server: Apache/1.3.27 (Unix) (Red-Hat/Linux) Vary 缓存控制 Vary: Origin 实体头部 协议头 说明 举例 Allow 对某网络资源的有效的请求行为，不允许则返回405 Allow: GET, HEAD Content-encoding 返回内容的编码方式 Content-Encoding: gzip Content-Length 返回内容的字节长度 Content-Length: 348 Content-Language 响应体的语言 Content-Language: en,zh Content-Location 请求资源可替代的备用的另一地址 Content-Location: /index.htm Content-MD5 返回资源的MD5校验值 Content-MD5: Q2hlY2sgSW50ZWdyaXR5IQ== Content-Range 在整个返回体中本部分的字节位置 Content-Range: bytes 21010-47021/47022 Content-Type 返回内容的MIME类型 Content-Type: text/html; charset=utf-8 Expires 响应过期的日期和时间 Expires: Thu, 01 Dec 2010 16:00:00 GMT Last-Modified 请求资源的最后修改时间 Last-Modified: Tue, 15 Nov 2010 12:45:26 GMT 1.16.2 Keep-Alive 和非 Keep-Alive 区别，对服务器性能有影响吗在早期的 HTTP/1.0 中，浏览器每次 发起 HTTP 请求都要与服务器创建一个新的 TCP 连接，服务器完成请求处理后立即断开 TCP 连接，服务器不跟踪每个客户也不记录过去的请求。然而创建和关闭连接的过程需要消耗资源和时间，为了减少资源消耗，缩短响应时间，就需要重用连接。在 HTTP/1.1 版本中默认使用持久连接，在此之前的 HTTP 版本的默认连接都是使用非持久连接，如果想要在旧版本的 HTTP 协议上维持持久连接，则需要指定 connection 的首部字段的值为 Keep-Alive 来告诉对方这个请求响应完成后不要关闭，下一次咱们还用这个请求继续交流，我们用一个示意图来更加生动的表示两者的区别： 对于非 Keep=Alive 来说，必须为每一个请求的对象建立和维护一个全新的连接。对于每一个这样的连接，客户机和服务器都要分配 TCP 的缓冲区和变量，这给服务器带来的严重的负担，因为一台 Web 服务器可能同时服务于数以百计的客户机请求。在 Keep-Alive 方式下，服务器在响应后保持该 TCP 连接打开，在同一个客户机与服务器之间的后续请求和响应报文可通过相同的连接进行传送。甚至位于同一台服务器的多个 Web 页面在从该服务器发送给同一个客户机时，可以在单个持久 TCP 连接上进行。 然而，Keep-Alive 并不是没有缺点的，当长时间的保持 TCP 连接时容易导致系统资源被无效占用，若对 Keep-Alive 模式配置不当，将有可能比非 Keep-Alive 模式带来的损失更大。因此，我们需要正确地设置 keep-alive timeout 参数，当 TCP 连接在传送完最后一个 HTTP 响应，该连接会保持 keepalive_timeout 秒，之后就开始关闭这个链接。 1.16.3 HTTP 长连接短连接使用场景是什么长连接：多用于操作频繁，点对点的通讯，而且客户端连接数目较少的情况。例如即时通讯、网络游戏等。 短连接：用户数目较多的Web网站的 HTTP 服务一般用短连接。例如京东，淘宝这样的大型网站一般客户端数量达到千万级甚至上亿，若采用长连接势必会使得服务端大量的资源被无效占用，所以一般使用的是短连接。 1.16.4 怎么知道 HTTP 的报文长度当响应消息中存在 Content-Length 字段时，我们可以直接根据这个值来判断数据是否接收完成，例如客户端向服务器请求一个静态页面或者一张图片时，服务器能够很清楚的知道请求内容的大小，因此可以通过消息首部字段 Content- Length 来告诉客户端需要接收多少数据，但是如果服务器预先不知道请求内容的大小，例如加载动态页面的时候，就需要使用 Transfer-Encoding: chunked 的方式来代替 Content-Length。 分块传输编码（Chunked transfer encoding）是 HTTP/1.1 中引入的一种数据传输机制，其允许 HTTP 由服务器发送给客户端的数据可以分成多个部分，当数据分解成一系列数据块发送时，服务器就可以发送数据而不需要预先知道发送内容的总大小，每一个分块包含十六进制的长度值和数据，最后一个分块长度值为0，表示实体结束，客户机可以以此为标志确认数据已经接收完毕。 1.16.5 HTTP 方法了解哪些HTTP/1.0 定义了三种请求方法：GET, POST 和 HEAD 方法。 HTTP/1.1 增加了六种请求方法：OPTIONS, PUT, PATCH, DELETE, TRACE 和 CONNECT 方法。 方法 描述 GET 请求指定的页面信息，并返回具体内容，通常只用于读取数据。 HEAD 类似于 GET 请求，只不过返回的响应中没有具体的内容，用于获取报头。 POST 向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST 请求可能会导致新的资源的建立或已有资源的更改。 PUT 替换指定的资源，没有的话就新增。 DELETE 请求服务器删除 URL 标识的资源数据。 CONNECT 将服务器作为代理，让服务器代替用户进行访问。 OPTIONS 向服务器发送该方法，会返回对指定资源所支持的 HTTP 请求方法。 TRACE 回显服务器收到的请求数据，即服务器返回自己收到的数据，主要用于测试和诊断。 PATCH 是对 PUT 方法的补充，用来对已知资源进行局部更新。 1.16.6 GET 和 POST 的区别 get 提交的数据会放在 URL 之后，并且请求参数会被完整的保留在浏览器的记录里，由于参数直接暴露在 URL 中，可能会存在安全问题，因此往往用于获取资源信息。而 post 参数放在请求主体中，并且参数不会被保留，相比 get 方法，post 方法更安全，主要用于修改服务器上的资源。 get 请求只支持 URL 编码，post 请求支持多种编码格式。 get 只支持 ASCII 字符格式的参数，而 post 方法没有限制。 get 提交的数据大小有限制（这里所说的限制是针对浏览器而言的），而 post 方法提交的数据没限制 get 方式需要使用 Request.QueryString 来取得变量的值，而 post 方式通过 Request.Form 来获取。 get 方法产生一个 TCP 数据包，post 方法产生两个（并不是所有的浏览器中都产生两个）。 1.16.7 GET 的长度限制是多少HTTP 中的 GET 方法是通过 URL 传递数据的，而 URL 本身并没有对数据的长度进行限制，真正限制 GET 长度的是浏览器，例如 IE 浏览器对 URL 的最大限制为 2000多个字符，大概 2KB左右，像 Chrome, FireFox 等浏览器能支持的 URL 字符数更多，其中 FireFox 中 URL 最大长度限制为 65536 个字符，Chrome 浏览器中 URL 最大长度限制为 8182 个字符。并且这个长度不是只针对数据部分，而是针对整个 URL 而言，在这之中，不同的服务器同样影响 URL 的最大长度限制。因此对于特定的浏览器，GET的长度限制不同。 由于 POST 方法请求参数在请求主体中，理论上讲，post 方法是没有大小限制的，而真正起限制作用的是服务器处理程序的处理能力。 1.16.8 HTTP 与 HTTPs 的工作方式【建立连接的过程】HTTP HTTP（Hyper Text Transfer Protocol: 超文本传输协议） 是一种简单的请求 - 响应协议，被用于在 Web 浏览器和网站服务器之间传递消息。HTTP 使用 TCP（而不是 UDP）作为它的支撑运输层协议。其默认工作在 TCP 协议 80 端口，HTTP 客户机发起一个与服务器的 TCP 连接，一旦连接建立，浏览器和服务器进程就可以通过套接字接口访问 TCP。客户机从套接字接口发送 HTTP 请求报文和接收 HTTP 响应报文。类似地，服务器也是从套接字接口接收 HTTP 请求报文和发送 HTTP 响应报文。其通信内容以明文的方式发送，不通过任何方式的数据加密。当通信结束时，客户端与服务器关闭连接。 HTTPS HTTPS（Hyper Text Transfer Protocol over Secure Socket Layer）是以安全为目标的 HTTP 协议，在 HTTP 的基础上通过传输加密和身份认证的方式保证了传输过程的安全性。其工作流程如下： ① 客户端发起一个 HTTPS 请求，并连接到服务器的 443 端口，发送的信息主要包括自身所支持的算法列表和密钥长度等； ② 服务端将自身所支持的所有加密算法与客户端的算法列表进行对比并选择一种支持的加密算法，然后将它和其它密钥组件一同发送给客户端。 ③ 服务器向客户端发送一个包含数字证书的报文，该数字证书中包含证书的颁发机构、过期时间、服务端的公钥等信息。 ④ 最后服务端发送一个完成报文通知客户端 SSL 的第一阶段已经协商完成。 ⑤ SSL 第一次协商完成后，客户端发送一个回应报文，报文中包含一个客户端生成的随机密码串，称为 pre_master_secre，并且该报文是经过证书中的公钥加密过的。 ⑥ 紧接着客户端会发送一个报文提示服务端在此之后的报文是采用pre_master_secre 加密的。 ⑦ 客户端向服务端发送一个 finish 报文，这次握手中包含第一次握手至今所有报文的整体校验值，最终协商是否完成取决于服务端能否成功解密。 ⑧ 服务端同样发送与第 ⑥ 步中相同作用的报文，已让客户端进行确认，最后发送 finish 报文告诉客户端自己能够正确解密报文。 当服务端和客户端的 finish 报文交换完成之后，SSL 连接就算建立完成了，之后就进行和 HTTP 相同的通信过程，唯一不同的是在 HTTP 通信过程中并不是采用明文传输，而是采用对称加密的方式，其中对称密钥已经在 SSL 的建立过程中协商好了。 1.16.9 HTTPS 和 HTTP 的区别 HTTP 协议以明文方式发送内容，数据都是未加密的，安全性较差。HTTPS 数据传输过程是加密的，安全性较好。 HTTP 和 HTTPS 使用的是完全不同的连接方式，用的端口也不一样，前者是 80 端口，后者是 443 端口。 HTTPS 协议需要到数字认证机构（Certificate Authority, CA）申请证书，一般需要一定的费用。 HTTP 页面响应比 HTTPS 快，主要因为 HTTP 使用 3 次握手建立连接，客户端和服务器需要握手 3 次，而 HTTPS 除了 TCP 的 3 次握手，还需要经历一个 SSL 协商过程。 1.16.10 HTTPS 的加密方式HTTPS 采用对称加密和非对称加密相结合的方式，首先使用 SSL/TLS 协议进行加密传输，为了弥补非对称加密的缺点，HTTPS 采用证书来进一步加强非对称加密的安全性，通过非对称加密，客户端和服务端协商好之后进行通信传输的对称密钥，后续的所有信息都通过该对称秘钥进行加密解密，完成整个 HTTPS 的流程。 1.16.11 客户端为什么信任第三方证书假设中间人篡改了证书原文，由于他没有 CA 机构的私钥，所以无法得到此时加密后的签名，因此无法篡改签名。客户端浏览器收到该证书后会发现原文和签名解密后的值不一致，则说明证书被中间人篡改，证书不可信，从而终止向服务器传输信息。 上述过程说明证书无法被篡改，我们考虑更严重的情况，例如中间人拿到了 CA 机构认证的证书，它想窃取网站 A 发送给客户端的信息，于是它成为中间人拦截到了 A 传给客户端的证书，然后将其替换为自己的证书。此时客户端浏览器收到的是被中间人掉包后的证书，但由于证书里包含了客户端请求的网站信息，因此客户端浏览器只需要把证书里的域名与自己请求的域名比对一下就知道证书有没有被掉包了。 1.16.12 HTTP 是不保存状态的协议,如何保存用户状态我们知道，假如某个特定的客户机在短时间内两次请求同一个对象，服务器并不会因为刚刚为该用户提供了该对象就不再做出反应，而是重新发送该对象，就像该服务器已经完全忘记不久之前所做过的是一样。因为一个 HTTP 服务器并不保存关于客户机的任何信息，所以我们说 HTTP 是一个无状态协议。 通常有两种解决方案： ① 基于 Session 实现的会话保持 在客户端第一次向服务器发送 HTTP 请求后，服务器会创建一个 Session 对象并将客户端的身份信息以键值对的形式存储下来，然后分配一个会话标识（SessionId）给客户端，这个会话标识一般保存在客户端 Cookie 中，之后每次该浏览器发送 HTTP 请求都会带上 Cookie 中的 SessionId 到服务器，服务器根据会话标识就可以将之前的状态信息与会话联系起来，从而实现会话保持。 优点：安全性高，因为状态信息保存在服务器端。 缺点：由于大型网站往往采用的是分布式服务器，浏览器发送的 HTTP 请求一般要先通过负载均衡器才能到达具体的后台服务器，倘若同一个浏览器两次 HTTP 请求分别落在不同的服务器上时，基于 Session 的方法就不能实现会话保持了。 【解决方法：采用中间件，例如 Redis，我们通过将 Session 的信息存储在 Redis 中，使得每个服务器都可以访问到之前的状态信息】 ② 基于 Cookie 实现的会话保持 当服务器发送响应消息时，在 HTTP 响应头中设置 Set-Cookie 字段，用来存储客户端的状态信息。客户端解析出 HTTP 响应头中的字段信息，并根据其生命周期创建不同的 Cookie，这样一来每次浏览器发送 HTTP 请求的时候都会带上 Cookie 字段，从而实现状态保持。基于 Cookie 的会话保持与基于 Session 实现的会话保持最主要的区别是前者完全将会话状态信息存储在浏览器 Cookie 中。 优点：服务器不用保存状态信息， 减轻服务器存储压力，同时便于服务端做水平拓展。 缺点：该方式不够安全，因为状态信息存储在客户端，这意味着不能在会话中保存机密数据。除此之外，浏览器每次发起 HTTP 请求时都需要发送额外的 Cookie 到服务器端，会占用更多带宽。 拓展：Cookie被禁用了怎么办？ 若遇到 Cookie 被禁用的情况，则可以通过重写 URL 的方式将会话标识放在 URL 的参数里，也可以实现会话保持。 1.16.13 状态码HTTP 状态码由三个十进制数字组成，第一个数字定义了状态码的类型，后两个并没有起到分类的作用。HTTP 状态码共有 5 种类型： 分类 分类描述 1XX 指示信息–表示请求正在处理 2XX 成功–表示请求已被成功处理完毕 3XX 重定向–要完成的请求需要进行附加操作 4XX 客户端错误–请求有语法错误或者请求无法实现，服务器无法处理请求 5XX 服务器端错误–服务器处理请求出现错误 常用： 200 请求成功204 请求成功但无内容返回206 范围请求成功 301 永久重定向； 30(2|3|7)临时重定向，语义和实现有略微区别；304 带if-modified-since 请求首部的条件请求，条件没有满足 400 语法错误401 需要认证信息403 拒绝访问404 找不到资源412 除if-modified-since 以外的条件请求，条件未满足 500 服务器错误503 服务器宕机 1.16.14 HTTP/1.1 和 HTTP/1.0 的区别主要区别如下： 缓存处理：在 HTTP/1.0 中主要使用 header 里的 if-modified-Since, Expries 来做缓存判断的标准。而 HTTP/1.1 请求头中添加了更多与缓存相关的字段，从而支持更为灵活的缓存策略，例如 Entity-tag, If-Unmodified-Since, If-Match, If-None-Match 等可供选择的缓存头来控制缓存策略。 节约带宽： 当客户端请求某个资源时，HTTP/1.0 默认将该资源相关的整个对象传送给请求方，但很多时候可能客户端并不需要对象的所有信息。而在 HTTP/1.1 的请求头中引入了 range 头域，它允许只请求部分资源，其使得开发者可以多线程请求某一资源，从而充分的利用带宽资源，实现高效并发。 错误通知的管理：HTTP/1.1 在 1.0 的基础上新增了 24 个错误状态响应码，例如 414 表示客户端请求中所包含的 URL 地址太长，以至于服务器无法处理；410 表示所请求的资源已经被永久删除。 Host 请求头：早期 HTTP/1.0 中认为每台服务器都绑定一个唯一的 IP 地址并提供单一的服务，请求消息中的 URL 并没有传递主机名。而随着虚拟主机的出现，一台物理服务器上可以存在多个虚拟主机，并且它们共享同一个 IP 地址。为了支持虚拟主机，HTTP/1.1 中添加了 host 请求头，请求消息和响应消息中应声明这个字段，若请求消息中缺少该字段时服务端会响应一个 404 错误状态码。 长连接：HTTP/1.0 默认浏览器和服务器之间保持短暂连接，浏览器的每次请求都需要与服务器建立一个 TCP 连接，服务器完成后立即断开 TCP 连接。HTTP/1.1 默认使用的是持久连接，其支持在同一个 TCP 请求中传送多个 HTTP 请求和响应。此之前的 HTTP 版本的默认连接都是使用非持久连接，如果想要在旧版本的 HTTP 协议上维持持久连接，则需要指定 Connection 的首部字段的值为 Keep-Alive。 1.16.15 HTTP/1.X 和 HTTP/2.0 的区别相比于 HTTP/1.X 的文本（字符串）传送， HTTP/2.0 采用二进制传送。客户端和服务器传输数据时把数据分成帧，帧组成了数据流，流具有流 ID 标识和优先级，通过优先级以及流依赖能够一定程度上解决关键请求被阻塞的问题。HTTP/2.0 支持多路复用。因为流 ID 的存在， 通过同一个 HTTP 请求可以实现多个 HTTP 请求传输，客户端和服务器可以通过流 ID 来标识究竟是哪个流从而定位到是哪个 HTTP 请求。HTTP/2.0 头部压缩。HTTP/2.0 通过 gzip 和 compress 压缩头部然后再发送，同时通信双方会维护一张头信息表，所有字段都记录在这张表中，在每次 HTTP 传输时只需要传头字段在表中的索引即可，大大减小了重传次数和数据量。HTTP/2.0 支持服务器推送。 服务器在客户端未经请求许可的情况下，可预先向客户端推送需要的内容，客户端在退出服务时可通过发送复位相关的请求来取消服务端的推送。 1.16.16 URI（统一资源标识符）和 URL（统一资源定位符）之间的区别URL，即统一资源定位符 (Uniform Resource Locator )，URL 其实就是我们平时上网时输入的网址，它标识一个互联网资源，并指定对其进行操作或获取该资源的方法。例如 https://leetcode-cn.com/problemset/all/ 这个 URL，标识一个特定资源并表示该资源的某种形式是可以通过 HTTP 协议从相应位置获得。 从定义即可看出，URL 是 URI 的一个子集，两者都定义了资源是什么，而 URL 还定义了如何能访问到该资源。URI 是一种语义上的抽象概念，可以是绝对的，也可以是相对的，而URL则必须提供足够的信息来定位，是绝对的。简单地说，只要能唯一标识资源的就是 URI，在 URI 的基础上给出其资源的访问方式的就是 URL。 1.16.17 为什么 fidder，charles 能抓到你的包【抓取数据包的过程】假如我们需要抓取客户端的数据包，需要监控客户端与服务器交互之间的网络节点，监控其中任意一个网络节点（网卡），获取所有经过网卡中的数据，对这些数据按照网络协议进行解析，这就是抓包的基本原理。而中间的网络节点不受我们控制，是基本无法实现抓包的，因此只能在客户端与服务器之间进行抓包。 ① 当采用抓包工具抓取 HTTP 数据包时，过程较为简单： 首先抓包工具会提出代理服务，客户端需要连接该代理； 客户端发出 HTTP 请求时，会经过抓包工具的代理，抓包工具将请求的原文进行展示； 抓包工具使用该原文将请求发送给服务器； 服务器返回结果给抓包工具，抓包工具将返回结果进行展示； 抓包工具将服务器返回的结果原样返回给客户端。 这里抓包工具相当于透明人，数据经过的时候它一只手接到数据，然后另一只手把数据传出去。 ② 当抓取 HTTPS 数据包时： 客户端连接抓包工具提供的代理服务，并安装抓包工具的根证书； 客户端发出 HTTPS 请求，抓包工具模拟服务器与客户端进行 TLS 握手交换密钥等流程； 抓包工具发送一个 HTTPS 请求给客户端请求的目标服务器，并与目标服务器进行 TLS 握手交换密钥等流程； 客户端使用与抓包工具协定好的密钥加密数据后发送给抓包工具； 抓包工具使用与客户端协定好的密钥解密数据，并将结果进行展示； 抓包工具将解密后的客户端数据，使用与服务器协定好的密钥进行加密后发送给目标服务器； 服务器解密数据后，做对应的逻辑处理，然后将返回结果使用与抓包工具协定好的密钥进行加密发送给抓包工具； 抓包工具将服务器返回的结果，用与服务器协定好的密钥解密，并将结果进行展示； 抓包工具将解密后的服务器返回数据，使用与客户端协定好的密钥进行加密后发送给客户端； 客户端解密数据。 这个时候抓包工具对客户端来说相当于服务器，对服务器来说相当于客户端。在这个传输过程中，客户端会以为它就是目标服务器，服务器也会以为它就是请求发起的客户端。 1.16.18 如果你访问一个网站很慢，怎么排查和解决网页打开速度慢的原因有很多，这里列举出一些较常出现的问题： ① 首先最直接的方法是查看本地网络是否正常，可以通过网络测速软件例如电脑管家等对电脑进行测速，若网速正常，我们查看网络带宽是否被占用，例如当你正在下载电影时并且没有限速，是会影响你打开网页的速度的，这种情况往往是处理器内存小导致的； ② 当网速测试正常时，我们对网站服务器速度进行排查，通过 ping 命令查看链接到服务器的时间和丢包等情况，一个速度好的机房，首先丢包率不能超过 1%，其次 ping 值要小，最后是 ping 值要稳定，如最大和最小差值过大说明路由不稳定。或者我们也可以查看同台服务器上其他网站的打开速度，看是否其他网站打开也慢。 ③ 如果网页打开的速度时快时慢，甚至有时候打不开，有可能是空间不稳定的原因。当确定是该问题时，就要找你的空间商解决或换空间商了，如果购买空间的话，可选择购买购买双线空间或多线空间；如果是在有的地方打开速度快，有的地方打开速度慢，那应该是网络线路的问题。电信线路用户访问放在联通服务器的网站，联通线路用户访问放在电信服务器上的网站，相对来说打开速度肯定是比较慢。 ④ 从网站本身找原因。网站的问题主要包括网站程序设计、网页设计结构和网页内容三个部分。 网站程序设计：当访问网页中有拖慢网站打开速度的代码，会影响网页的打开速度，例如网页中的统计代码，我们最好将其放在网站的末尾。因此我们需要查看网页程序的设计结构是否合理； 网页设计结构：如果是 table 布局的网站，查看是否嵌套次数太多，或是一个大表格分成多个表格这样的网页布局，此时我们可以采用 div 布局并配合 css 进行优化。 网页内容：查看网页中是否有许多尺寸大的图片或者尺寸大的 flash 存在，我们可以通过降低图片质量，减小图片尺寸，少用大型 flash 加以解决。此外，有的网页可能过多地引用了其他网站的内容，若某些被引用的网站访问速度慢，或者一些页面已经不存在了，打开的速度也会变慢。一种直接的解决方法是去除不必要的加载项。 1.16.19 用户输入网址到显示对应页面的全过程(八股文) ① DNS 解析：当用户输入一个网址并按下回车键的时候，浏览器获得一个域名，而在实际通信过程中，我们需要的是一个 IP 地址，因此我们需要先把域名转换成相应 IP 地址。 ② TCP 连接：浏览器通过 DNS 获取到 Web 服务器真正的 IP 地址后，便向 Web 服务器发起 TCP 连接请求，通过 TCP 三次握手建立好连接后，浏览器便可以将 HTTP 请求数据发送给服务器了。【三次握手放在传输层详细讲解】 ③ 发送 HTTP 请求：浏览器向 Web 服务器发起一个 HTTP 请求，HTTP 协议是建立在 TCP 协议之上的应用层协议，其本质是在建立起的TCP连接中，按照HTTP协议标准发送一个索要网页的请求。在这一过程中，会涉及到负载均衡等操作。 ④ 处理请求并返回：服务器获取到客户端的 HTTP 请求后，会根据 HTTP 请求中的内容来决定如何获取相应的文件，并将文件发送给浏览器。 ⑤ 浏览器渲染：浏览器根据响应开始显示页面，首先解析 HTML 文件构建 DOM 树，然后解析 CSS 文件构建渲染树，等到渲染树构建完成后，浏览器开始布局渲染树并将其绘制到屏幕上。 ⑥ 断开连接：客户端和服务器通过四次挥手终止 TCP 连接。【其中的细节放在传输层详细讲解】 1.16.20 什么是负载均衡负载均衡，英文名为 Load Balance，其含义是指将负载（工作任务）进行平衡、分摊到多个操作单元上进行运行，例如 FTP 服务器、Web 服务器、企业核心服务器和其他主要任务服务器等，从而协同完成工作任务。负载均衡建立在现有的网络之上，它提供了一种透明且廉价有效的方法扩展服务器和网络设备的带宽、增加吞吐量、加强网络处理能力并提高网络的灵活性和可用性。 负载均衡是分布式系统架构设计中必须考虑的因素之一，例如天猫、京东等大型用户网站中为了处理海量用户发起的请求，其往往采用分布式服务器，并通过引入反向代理等方式将用户请求均匀分发到每个服务器上，而这一过程所实现的就是负载均衡。 1.17 其他协议FTPFTP（File Transfer Protocol，文件传输协议）是用于在网络上进行文件传输的一套标准协议，使用客户/服务器模式，使用 TCP 数据报，提供交互式访问，双向传输。TFTP（Trivial File Transfer Protocol，简单文件传输协议）一个小且易实现的文件传输协议，也使用客户/服务器方式，使用 UDP 数据报，只支持文件传输而不支持交互，没有列目录，不能对用户进行身份鉴定。 SMTPSMTP（Simple Main Transfer Protocol，简单邮件传输协议）是在 Internet 传输 Email 的标准，是一个相对简单的基于文本的协议。在其之上指定了一条消息的一个或多个接收者（在大多数情况下被确认是存在的），然后消息文本会被传输。可以很简单地通过 Telnet 程序来测试一个 SMTP 服务器。SMTP 使用 TCP 端口 25。 SNMPSNMP（Simple Network Management Protocol，简单网络管理协议）构成了互联网工程工作小组（IETF，Internet Engineering Task Force）定义的 Internet 协议族的一部分。该协议能够支持网络管理系统，用以监测连接到网络上的设备是否有任何引起管理上关注的情况。 1.18 网络安全1.18.1 安全攻击的分类网络安全攻击主要分为被动攻击和主动攻击两类： 被动攻击：攻击者窃听和监听数据传输，从而获取到传输的数据信息，被动攻击主要有两种形式：消息内容泄露攻击和流量分析攻击。由于攻击者并没有修改数据，使得这种攻击类型是很难被检测到的。 主动攻击：攻击者修改传输的数据流或者故意添加错误的数据流，例如假冒用户身份从而得到一些权限，进行权限攻击，除此之外，还有重放、改写和拒绝服务等主动攻击的方式。 1.18.2 简述ARP攻击在 ARP 的解析过程中，局域网上的任何一台主机如果接收到一个 ARP 应答报文，并不会去检测这个报文的真实性，而是直接记入自己的 ARP 缓存表中。并且这个 ARP 表是可以被更改的，当表中的某一列长时间不适使用，就会被删除。ARP 攻击就是利用了这一点，攻击者疯狂发送 ARP 报文，其源 MAC 地址为攻击者的 MAC 地址，而源 IP 地址为被攻击者的 IP 地址。通过不断发送这些伪造的 ARP 报文，让网络内部的所有主机和网关的 ARP 表中被攻击者的 IP 地址所对应的 MAC 地址为攻击者的 MAC 地址。这样所有发送给被攻击者的信息都会发送到攻击者的主机上，从而产生 ARP 欺骗。通常可以把 ARP 欺骗分为以下几种： 洪泛攻击攻击者恶意向局域网中的网关、路由器和交换机等发送大量 ARP 报文，设备的 CPU 忙于处理 ARP 协议，而导致难以响应正常的服务请求。其表现通常为：网络中断或者网速很慢。 欺骗主机这种攻击方式也叫仿冒网关攻击。攻击者通过 ARP 欺骗使得网络内部被攻击主机发送给网关的信息实际上都发送给了攻击者，主机更新的 ARP 表中对应的 MAC 地址为攻击者的 MAC。当用户主机向网关发送重要信息使，该攻击方式使得用户的数据存在被窃取的风险。 欺骗网关该攻击方式和欺骗主机的攻击方式类似，不过这种攻击的欺骗对象是局域网的网关，当局域网中的主机向网关发送数据时，网关会把数据发送给攻击者，这样攻击者就会源源不断地获得局域网中用户的信息。该攻击方式同样会造成用户数据外泄。 中间人攻击攻击者同时欺骗网关和主机，局域网的网关和主机发送的数据最后都会到达攻击者这边。这样，网关和用户的数据就会泄露。 IP 地址冲突攻击者对局域网中的主机进行扫描，然后根据物理主机的 MAC 地址进行攻击，导致局域网内的主机产生 IP 冲突，使得用户的网络无法正常使用。 1.18.3 对称加密和非对称的区别，非对称加密有哪些 加密和解密的过程不同：对称加密和解密过程使用同一个密钥；非对称加密中加密和解密采用公钥和私钥两个密钥，一般使用公钥进行加密，使用私钥进行解密。 加密和解密的速度不同：对称加密和解密速度较快，当数据量比较大时适合使用；非对称加密和解密时间较长，速度相对较慢，适合少量数据传输的场景。 传输的安全性不同：采用对称加密方式进行通信时，收发双方在数据传送前需要协定好密钥，而这个密钥还有可能被第三方窃听到的，一旦密钥泄漏，之后的通信就完全暴漏给攻击者了；非对称加密采用公钥加密和私钥解密的方式，其中私钥是基于不同的算法生成的随机数，公钥可以通过私钥通过一定的算法推导得出，并且私钥到公钥的推导过程是不可逆的，也就是说公钥无法反推导出私钥，即使攻击者窃听到传输的公钥，也无法正确解出数据，所以安全性较高。 常见的非对称加密算法主要有：RSA、Elgamal、背包算法、Rabin、D-H 算法等等。 1.18.4 AES 的过程AES（Advanced Encryption Standard）即密码学的高级加密标准，也叫做 Rijndeal 加密法，是为最为常见的一种对称加密算法，和传统的对称加密算法大致的流程类似，在发送端需要采用加密算法对明文进行加密，在接收端需要采用与加密算法相同的算法进行解密，不同的是， AES 采用分组加密的方式，将明文分成一组一组的，每组长度相等，每次加密一组数据，直到加密完整个明文。在 AES 标准中，分组长度固定为 128 位，即每个分组为 16 个字节（每个字节有 8 位）。而密钥的长度可以是 128 位，192 位或者 256 位。并且密钥的长度不同，推荐加密的轮数也不同。 我们以 128 位密钥为例（加密轮次为 10），已知明文首先需要分组，每一组大小为16个字节并形成 4 × 4 的状态矩阵（矩阵中的每一个元素代表一个字节）。类似地，128 位密钥同样用 4 × 4 的字节矩阵表示，矩阵中的每一列称为 1 个 32 位的比特字。通过密钥编排函数该密钥矩阵被扩展成一个由 44 个字组成的序列，该序列的前四个字是原始密钥，用于 AES 的初始密钥加过程，后面 40 个字分为 10 组，每组 4 个字分别用于 10 轮加密运算中的轮密钥加。在每轮加密过程中主要包括四个步骤： ① 字节代换：AES 的字节代换其实是一个简易的查表操作，在 AES 中定义了一个 S-box 和一个逆 S-box，我们可以将其简单地理解为两个映射表，在做字节代换时，状态矩阵中的每一个元素（字节）的高四位作为行值，低四位作为列值，取出 S-box 或者逆 S-box 中对应的行或者列作为输出。 ② 行位移：顾名思义，就是对状态矩阵的每一行进行位移操作，其中状态矩阵的第 0 行左移 0 位，第 1 行左移 1 位，以此类推。 ③ 列混合：列混合变换是通过矩阵相乘来实现的，经唯一后的状态矩阵与固定的矩阵相乘，从而得到混淆后的状态矩阵。其中矩阵相乘中涉及到的加法等价于两个字节的异或运算，而乘法相对复杂一些，对于状态矩阵中的每一个 8 位二进制数来说，首先将其与 00000010 相乘，其等效为将 8 位二进制数左移一位，若原二进制数的最高位是 1 的话再将左移后的数与 00011011 进行异或运算。 ④ 轮密相加：在开始时我们提到，128 位密钥通过密钥编排函数被扩展成 44 个字组成的序列，其中前 4 个字用于加密过程开始时对原始明文矩阵进行异或运算，而后 40 个字中每四个一组在每一轮中与状态矩阵进行异或运算（共计 10 轮）。 上述过程即为 AES 加密算法的主要流程，在我们的例子中，上述过程需要经过 10 轮迭代。而 AES 的解密过程的各个步骤和加密过程是一样的，只是用逆变换取代原来的变换。 1.18.5 RSA 和 AES 算法有什么区别RSA采用非对称加密的方式，采用公钥进行加密，私钥解密的形式。其私钥长度一般较长，除此之外，由于需要大数的乘幂求模等运算，其运算速度较慢，不适合大量数据文件加密。 AES采用对称加密的方式，其密钥长度最长只有 256 个比特，加密和解密速度较快，易于硬件实现。由于是对称加密，通信双方在进行数据传输前需要获知加密密钥。 基于上述两种算法的特点，一般使用 RSA 传输密钥给对方，之后使用 AES 进行加密通信。 1.18.6 DDoS 有哪些，如何防范 DDoS 为分布式拒绝服务攻击，是指处于不同位置的多个攻击者同时向一个或数个目标发动攻击，或者一个攻击者控制了不同位置上的多台机器并利用这些机器对受害者同时实施攻击。和单一的 DoS 攻击相比，DDoS 是借助数百台或者数千台已被入侵并添加了攻击进程的主机一起发起网络攻击。 DDoS 攻击主要有两种形式：流量攻击和资源耗尽攻击。前者主要针对网络带宽，攻击者和已受害主机同时发起大量攻击导致网络带宽被阻塞，从而淹没合法的网络数据包；后者主要针对服务器进行攻击，大量的攻击包会使得服务器资源耗尽或者 CPU 被内核应用程序占满从而无法提供网络服务。 常见的 DDos 攻击主要有：TCP 洪水攻击（SYN Flood）、放射性攻击（DrDos）、CC 攻击（HTTP Flood）等。 针对 DDoS 中的流量攻击，最直接的方法是增加带宽，理论上只要带宽大于攻击流量就可以了，但是这种方法成本非常高。在有充足网络带宽的前提下，我们应尽量提升路由器、网卡、交换机等硬件设施的配置。 针对资源耗尽攻击，我们可以升级主机服务器硬件，在网络带宽得到保证的前提下，使得服务器能有效对抗海量的 SYN 攻击包。我们也可以安装专业的抗 DDoS 防火墙，从而对抗 SYN Flood等流量型攻击。此外，负载均衡，CDN 等技术都能够有效对抗 DDoS 攻击 1.18.7 SYN FLOOD 是什么SYN Flood 是种典型的 DoS（拒绝服务）攻击，其目的是通过消耗服务器所有可用资源使服务器无法用于处理合法请求。通过重复发送初始连接请求（SYN）数据包，攻击者能够压倒目标服务器上的所有可用端口，导致目标设备根本不响应合法请求。 1.18.8 为什么服务端易受到 SYN 攻击在 TCP 建立连接的过程中，因为服务端不确定自己发给客户端的 SYN-ACK 消息或客户端反馈的 ACK 消息是否会丢在半路，所以会给每个待完成的半开连接状态设一个定时器，如果超过时间还没有收到客户端的 ACK 消息，则重新发送一次 SYN-ACK 消息给客户端，直到重试超过一定次数时才会放弃。 服务端为了维持半开连接状态，需要分配内核资源维护半开连接。当攻击者伪造海量的虚假 IP 向服务端发送 SYN 包时，就形成了 SYN FLOOD 攻击。攻击者故意不响应 ACK 消息，导致服务端被大量注定不能完成的半开连接占据，直到资源耗尽，停止响应正常的连接请求。 解决方法： 直接的方法是提高 TCP 端口容量的同时减少半开连接的资源占用时间，然而该方法只是稍稍提高了防御能力；部署能够辨别恶意 IP 的路由器，将伪造 IP 地址的发送方发送的 SYN 消息过滤掉，该方案作用一般不是太大；上述两种方法虽然在一定程度上能够提高服务器的防御能力，但是没有从根本上解决服务器资源消耗殆尽的问题，而以下几种方法的出发点都是在发送方发送确认回复后才开始分配传输资源，从而避免服务器资源消耗殆尽。 SYN Cache：该方法首先构造一个全局 Hash Table，用来缓存系统当前所有的半开连接信息。在 Hash Table 中的每个桶的容量大小是有限制的，当桶满时，会主动丢掉早来的信息。当服务端收到一个 SYN 消息后，会通过一个映射函数生成一个相应的 Key 值，使得当前半连接信息存入相应的桶中。当收到客户端正确的确认报文后，服务端才开始分配传输资源块，并将相应的半开连接信息从表中删除。和服务器传输资源相比，维护表的开销要小得多。 SYN Cookies：该方案原理和 HTTP Cookies 技术类似，服务端通过特定的算法将半开连接信息编码成序列号或者时间戳，用作服务端给客户端的消息编号，随 SYN-ACK 消息一同返回给连接发起方，这样在连接建立完成前服务端不保存任何信息，直到发送方发送 ACK 确认报文并且服务端成功验证编码信息后，服务端才开始分配传输资源。若请求方是攻击者，则不会向服务端会 ACK 消息，由于未成功建立连接，因此服务端并没有花费任何额外的开销。 然而该方案也存在一些缺点，由于服务端并不保存半开连接状态，因此也就丧失了超时重传的能力，这在一定程度上降低了正常用户的连接成功率。此外，客户端发送给服务端的确认报文存在传输丢失的可能，当 ACK 确认报文丢失时，服务端和客户端会对连接的成功与否产生歧义，此时就需要上层应用采取相应的策略进行处理了。 SYN Proxy：在客户端和服务器之间部署一个代理服务器，类似于防火墙的作用。通过代理服务器与客户端进行建立连接的过程，之后代理服务器充当客户端将成功建立连接的客户端信息发送给服务器。这种方法基本不消耗服务器的资源，但是建立连接的时间变长了（总共需要 6 次握手）。 （未整理完~） 2 套接字编程2.1 套接字基础2.1.1 简述IPv4套接字结构地址1234567891011struct in_addr { in_addr_t s_addr; // 32-bit IPv4地址，网络字节序};struct sockaddr_in { uint8_t sin_len; // 套接字地址长度 sa_family_t sin_family; // AF_INET，套接字地址结构的地址族 in_port_t sin_port; // 16-bit 端口号，网络字节序 struct in_addr sin_addr; // 32-bit IPv4地址，网络字节序 char sin_zero[8] // 未使用}; 其余类型套接字地址结构类似： 2.1.2 什么是值-结果参数当函数参数是从内核到进程时，函数被调用时参数大小是一个值，它告诉内核该参数的结构大小避免内核写操作越界，函数返回时，参数的结构大小又是一个结果，它告诉进程内核写进数据的多少，这种参数叫做值-结果参数。 2.1.3 简述大端模式、小端模式和网络字节序 “大端”和”小端”表示多字节值的哪一端存储在该值的起始地址处;小端存储在起始地址处,即是小端字节序;大端存储在起始地址处,即是大端字节序;具体的说：①大端字节序（Big Endian）：最高有效位存于最低内存地址处，最低有效位存于最高内存处；②小端字节序（Little Endian）：最高有效位存于最高内存地址，最低有效位存于最低内存处。 网络字节序 UDP/TCP/IP协议规定:把接收到的第一个字节当作高位字节看待,这就要求发送端发送的第一个字节是高位字节;而在发送端发送数据时,发送的第一个字节是该数值在内存中的起始地址处对应的那个字节,也就是说,该数值在内存中的起始地址处对应的那个字节就是要发送的第一个高位字节(即:高位字节存放在低地址处);由此可见,多字节数值在发送之前,在内存中因该是以大端法存放的;所以说,网络字节序是大端字节序。在实际中，当在两个存储方式不同的主机上传输时，需要借助字节序转换函数。 2.1.4 列举几种字节操纵函数123456789// 字节序转换函数，h代表host，n代表network，s代表short，l代表longuint16_t htons(uint16_t host16bitvalue);uint32_t htonl(uint32_t host32bitvalue);uint16_t ntohs(uint16_t net16bitvalue);uint32_t ntohl(uint32_t net32bitvalue);// IP地址的数值形式(n, addrptr)和表达形式(p, strptr)的互相转化，如 1111 1111 1111 1111 1111 1111 1111 1111 &lt;=&gt; 255.255.255.255int inet_pton(int family, const char *strptr, void *addrptr);const char *inet_ntop(int family, const void *addrptr, char *strptr, size_t len); 2.1.5 字节流套接字上调用read()和write()总是能读取到指定字节数吗不能，它与文件I/O不同。调用read()和write()函数输入或输出的字节数可能比请求的数量少，由于内核中用于套接字的缓冲区已经达到极限。需要再次调用直到达到指定字节数。 解决方法：编写readn()和writen()，将原函数放在循环中，直到输入/输出指定字节数后再跳出循环。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748ssize_t /* Read &quot;n&quot; bytes from a descriptor. */readn(int fd, void *vptr, size_t n){ size_t nleft; ssize_t nread; char *ptr; ptr = vptr; nleft = n; while (nleft &gt; 0) { if ( (nread = read(fd, ptr, nleft)) &lt; 0) { if (errno == EINTR) nread = 0; /* and call read() again */ else return(-1); } else if (nread == 0) break; /* EOF */ nleft -= nread; ptr += nread; } return(n - nleft); /* return &gt;= 0 */}/* end readn */ssize_t /* Write &quot;n&quot; bytes to a descriptor. */writen(int fd, const void *vptr, size_t n){ size_t nleft; ssize_t nwritten; const char *ptr; ptr = vptr; nleft = n; while (nleft &gt; 0) { if ( (nwritten = write(fd, ptr, nleft)) &lt;= 0) { if (nwritten &lt; 0 &amp;&amp; errno == EINTR) nwritten = 0; /* and call write() again */ else return(-1); /* error */ } nleft -= nwritten; ptr += nwritten; } return(n);}/* end writen */ 2.1.6 如何设置套接字选项12int getsockopt(int sockfd, int level, int optname, void *optval, socklen_t *optlen);int setsockopt(int sockfd, int level, int optname, const void *optval, socklen_t optlen); sockfd指向一个打开的套接字描述符，level指定解释选项的代码，optval指向某个变量，包含选项信息。 2.1.7 列举几个常用的套接字选项 SO_BROADCAST: 开启或禁止进程发送广播消息的能力。只有数据报套接字(UDP)支持广播，且网络也必须支持广播。 SO_ERROR: 获取内核设置的so_error值。 SO_KEEPALIVE: 保持存活选项，若两小时内该套接字上任一方都没有数据交换，TCP自动给对端发送一个保持存活探测分节。 对端响应ACK：一切正常。 对端响应RST：对端崩溃后重新启动，套接字被关闭。 对端无响应：隔一段时间再发，若一直无响应则套接字关闭。 本选项一般供服务器使用，检测出半开连接并终止 它们。 SO_REUSEADDR: 允许启动一个监听服务器并捆绑众所周知端口，即使以前建立的以该端口作为本地端口的连接仍然存在。所有服务器均应该启用本选项，允许服务器重启后依然能正常绑定端口。 允许在同一端口上启动同一服务器的多个实例，需要每个实例捆绑不同的本地IP（IP别名，HTTP） 允许单个进程捆绑同一端口到多个套接字上，需要每次捆绑不同的IP。 允许完全重复的捆绑：仅支持UDP套接字。（捆绑相同IP和端口号的多个服务器） 2.1.8 如何改变套接字的属性（是否阻塞，属主等）1int fcntl(int fd, int cmd, ...); file control函数，执行各种描述符控制操作。O_NONBLOCK使套接字变为非阻塞。 2.2 TCP套接字2.2.1 简述TCP客户机/服务器的工作模型 2.2.2 如何创建一个套接字1234// family: 协议族，如AF_INET(IPv4), AF_INET6(IPv6), AF_LOCAL(UNIX)...// type: 套接字类型，如SOCK_STREAM(字节流TCP), SOCK_DGRAM(数据报UDP), SOCK_SEQPACKET(有序分组SCTP), SOCK_RAW(原始)// protocol: 某个协议类型常值，如IPPROTO_TCP, IPPROTO_UDP, IPPROTO_SCTPint socket(int family, int type, int protocol); socket()的返回值是一个非负整数值sockfd，可以把它当作文件描述符(fd, file descriptor)。 通过type可以创建不同种类的套接字：TCP、UDP、SCTP… 2.2.3 TCP客户如何与服务器建立连接1234// sockfd: 套接字描述符// servaddr: 服务器的套接字地址结构，包含服务器的IP和端口号// addrlen: 该地址结构的大小int connect(int sockfd, const struct sockaddr *servaddr, socklen_t addrlen); 调用connect()将激发TCP三次握手过程，客户端会发送一个SYN。客户机从CLOSED状态转换到SYN_SENT状态。 接收到服务器的SYN+ACK后，connect()返回。 若函数调用失败，该套接字不再可用，必须使用close()关闭。 2.2.4 客户机和服务器都需要调用bind()绑定IP和端口吗1int bind(int sockfd, const struct sockaddr *myaddr, socklen_t addrlen); 对于服务器： 捆绑IP：限定该套接字只接收那些目的地为此IP的客户连接。 不捆绑IP：使用通配地址，内核把客户发送的SYN的目的IP作为服务器的源IP。（多宿主机） 捆绑端口：需要，服务器通过众所周知的端口被客户机认识。 不捆绑端口：不会这样做。内核会分配一个临时端口。 对于客户机： 捆绑IP：通常不这样做。指派源IP地址。 不捆绑IP：需要，内核将根据所用外出网络接口选择源IP。 捆绑端口：通常不需要。除非应用需要预留端口。 不捆绑端口：需要，让内核来选择临死端口。 2.2.5 TCP服务器如何监听到达的连接12// backlog：未完成连接队列和已完成连接队列的连接数之和的最大值。(排队的最大连接个数)int listen(int sockfd, int backlog); listen()将一个主动套接字(由socket()创建)转换为被动套接字（监听套接字），指示内核应该接收指向该套接字的连接请求。该套接字再服务器的生命周期内一直存在。套接字从CLOSED状态转换到LISTEN状态。 2.2.6 服务器如何获得已完成三次握手的连接1234// sockfd: 监听套接字// cliaddr: 返回已连接的客户机的协议地址，不感兴趣时可传入空指针// addrlen: 返回的协议地址大小int accept(int sockfd, struct sockaddr *cliaddr, socklen_t *addrlen); 从已完成连接队列头返回下一个已完成连接的套接字描述符。可以向该套接字中写入或读取数据。 2.2.7 如何关闭一个连接1int close(int sockfd); TCP将尝试发送已排队等待发送到对端的任何数据，然后发送FIN，产生正常终止序列。 2.2.8 若TCP客户机没有绑定IP和端口，如何知道自己发起连接的本地IP和端口号；同理，若一个多宿TCP服务器绑定了通配IP地址，如何知道当前连接的本地IP1int getsockname(int sockfd, struct sockaddr *localaddr, socklen_t *addrlen); 返回与某个套接字关联的本地协议地址。 2.2.9 服务器accept连接后，通过调用exec()执行程序，内存映像被替换，如何获得客户机的套接字地址1int getpeername(int sockfd, struct sockaddr *peeraddr, socklen_t *addrlen); 返回与某个套接字关联的外地协议地址。虽然丢失内存映像，但已连接套接字描述符可以跨exec继续保持开发。 2.2.10 实现一个CP并发回射服务器程序（多进程）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647voidstr_echo(int sockfd){ ssize_t n; char buf[MAXLINE];again: while ( (n = read(sockfd, buf, MAXLINE)) &gt; 0) Writen(sockfd, buf, n); if (n &lt; 0 &amp;&amp; errno == EINTR) goto again; else if (n &lt; 0) err_sys(&quot;str_echo: read error&quot;);}intmain(int argc, char **argv){ int listenfd, connfd; pid_t childpid; socklen_t clilen; struct sockaddr_in cliaddr, servaddr; listenfd = Socket(AF_INET, SOCK_STREAM, 0); bzero(&amp;servaddr, sizeof(servaddr)); servaddr.sin_family = AF_INET; servaddr.sin_addr.s_addr = htonl(INADDR_ANY); servaddr.sin_port = htons(SERV_PORT); Bind(listenfd, (SA *) &amp;servaddr, sizeof(servaddr)); Listen(listenfd, LISTENQ); for ( ; ; ) { clilen = sizeof(cliaddr); connfd = Accept(listenfd, (SA *) &amp;cliaddr, &amp;clilen); if ( (childpid = Fork()) == 0) { /* child process */ Close(listenfd); /* close listening socket */ str_echo(connfd); /* process the request */ exit(0); } Close(connfd); /* parent closes connected socket */ }} 2.2.11 实现一个TCP回射客户程序123456789101112131415161718192021222324252627282930313233343536373839voidstr_cli(FILE *fp, int sockfd){ char sendline[MAXLINE], recvline[MAXLINE]; while (Fgets(sendline, MAXLINE, fp) != NULL) { Writen(sockfd, sendline, strlen(sendline)); if (Readline(sockfd, recvline, MAXLINE) == 0) err_quit(&quot;str_cli: server terminated prematurely&quot;); Fputs(recvline, stdout); }}intmain(int argc, char **argv){ int sockfd; struct sockaddr_in servaddr; if (argc != 2) err_quit(&quot;usage: tcpcli &lt;IPaddress&gt;&quot;); sockfd = Socket(AF_INET, SOCK_STREAM, 0); bzero(&amp;servaddr, sizeof(servaddr)); servaddr.sin_family = AF_INET; servaddr.sin_port = htons(SERV_PORT); Inet_pton(AF_INET, argv[1], &amp;servaddr.sin_addr); Connect(sockfd, (SA *) &amp;servaddr, sizeof(servaddr)); str_cli(stdin, sockfd); /* do it all */ exit(0);} 2.2.12 服务器子进程终止时若父进程不处理，会变成僵死进程，如何处理子进程终止时，会给父进程发送SIGCHLD信号。使用signal()系统调用，为父进程设置信号处理函数： 在循环中调用waitpid(-1)，设置不阻塞选项，等待任意子进程终止，获取它们的状态，以免留下僵死进程。 2.2.13 若服务器阻塞在某慢系统调用中，执行信号处理函数，返回后会发生什么情况系统调用可能会返回EINTR错误，导致服务器程序退出。 解决方法：将accept()系统调用放在循环中，若接收到EINTR错误则自动重启。对于read(), write(), select(), open()同样适用。 2.2.14 若客户程序阻塞read()上，服务器发来FIN怎么办使用I/O复用，使客户机阻塞在任何一个源的输入上，而不仅仅是某一个源，否则会接收不到其他源的输入。 2.2.15 服务器崩溃后，客户机依然阻塞在read()上，怎么办为某些慢系统调用设置超时。或者设置SO_KEEPALIVE选项，检测出服务器的崩溃。 2.2.16 服务器崩溃后又重启，客户机依然正常发送数据，会发生什么服务器丢失所有连接信息，对接收到的数据均响应RST。可设置SO_KEEPALIVE选项，检测出服务器的崩溃。 2.2.17 服务器正常关机（进程正常终止）会发生什么杀死所有子进程，关闭所有打开的描述符，向客户机发送一个FIN。 2.2.18 并发服务器模型中，父进程关闭lconnfd为何不会导致子进程连接终止close()把描述符的引用计数减1，仅在该计数变为0时才关闭套接字。fork()子进程之后，所有描述符都被复制，引用计数也增加了。只要子进程不关闭connfd，连接就不会终止。 2.2.19 设计一个TCP并发回射服务器程序（多线程）12345678910111213141516171819202122232425262728293031323334353637383940static void *doit(void *); /* each thread executes this function */intmain(int argc, char **argv){ int listenfd, *iptr; thread_t tid; socklen_t addrlen, len; struct sockaddr *cliaddr; if (argc == 2) listenfd = Tcp_listen(NULL, argv[1], &amp;addrlen); else if (argc == 3) listenfd = Tcp_listen(argv[1], argv[2], &amp;addrlen); else err_quit(&quot;usage: tcpserv01 [ &lt;host&gt; ] &lt;service or port&gt;&quot;); cliaddr = Malloc(addrlen); for ( ; ; ) { len = addrlen; iptr = Malloc(sizeof(int)); *iptr = Accept(listenfd, cliaddr, &amp;len); Pthread_create(&amp;tid, NULL, &amp;doit, iptr); }}static void *doit(void *arg){ int connfd; connfd = *((int *) arg); free(arg); Pthread_detach(pthread_self()); str_echo(connfd); /* same function as before */ Close(connfd); /* done with connected socket */ return(NULL);} 2.2.20 设计一个TCP并发回射客户端程序（多线程分离读写）123456789101112131415161718192021222324252627282930313233void *copyto(void *);static int sockfd; /* global for both threads to access */static FILE *fp;voidstr_cli(FILE *fp_arg, int sockfd_arg){ char recvline[MAXLINE]; pthread_t tid; sockfd = sockfd_arg; /* copy arguments to externals */ fp = fp_arg; Pthread_create(&amp;tid, NULL, copyto, NULL); while (Readline(sockfd, recvline, MAXLINE) &gt; 0) Fputs(recvline, stdout);}void *copyto(void *arg){ char sendline[MAXLINE]; while (Fgets(sendline, MAXLINE, fp) != NULL) Writen(sockfd, sendline, strlen(sendline)); Shutdown(sockfd, SHUT_WR); /* EOF on stdin, send FIN */ return(NULL); /* 4return (i.e., thread terminates) when EOF on stdin */} 2.3 I/O模型2.3.1 简述5种I/O模型 阻塞式I/O：默认状态下，所有套接字都是阻塞的。系统调用直到数据报到达且被复制到应用程序缓冲区中或发送错误才返回。最常见的错误是被信号中断。 非阻塞式I/O：若系统调用即将阻塞进程，改为立即返回一个错误。循环调用系统调用被称为成为轮询，会耗费大量CPU时间。 I/O复用：只阻塞在select()或poll()上，而不是系统调用上。当有套接字可读/写时，进入相应系统调用处理数据。优势在于可用等待多个描述符就绪。 信号驱动式I/O模型：使用信号，让内核在描述符就绪时发送SIGIO信号通知我们，执行事先安装好的信号处理函数，进入系统调用处理数据。优势在于等待数据报期间进程不被阻塞。 异步I/O：告诉内核去启动某个操作，内核完成后通知我们。只有异步I/O完全不被系统调用阻塞，符合异步的标准。 前4种模型都属于同步I/O操作：会导致请求进程阻塞，直到I/O操作完成。最后1种属于异步I/O操作，不导致请求进程被阻塞。 2.3.2 什么时候使用I/O复用比较合适 客户处理多个描述符（交互式输入+网络套接字） 服务器既要处理监听套接字又要处理已连接套接字 服务器既要处理UDP又要处理TCP（多服务，多协议） 2.3.3 ★ 简述select()和poll()和epoll()函数的使用，它们有什么区别12345678910// timeout: 指定等待时间，可以无限等待// XXXset: 让内核测试读、写和异常条件的描述符，通常是一个描述符数组(描述符集)，使用系统的宏设定。// maxfdp1: 指定待测试的描述符个数int select(int maxfdp1, fd_set *readset, fd_set *writeset, fd_set *exceptset, const struct timeval *timeout);// 用户分配一个fd_set结构的描述符集， 用下面的宏设置或测试该集合中的每一位void FD_ZERO(fd_set *fdset); // 初始化描述符集，所有位关闭void FD_SET(int fd, fd_set *fdset); // 在描述符集中设置fd对应的位void FD_CLR(int fd, fd_set *fdset); // 在描述符集中清空fd对应的位int FD_SET(int fd, fd_set *fdset); // 测试该描述符集fd对应的位是否设置 select()允许指示内核等待多个事件种的任何一个发生，并且只有在1个或多个事件发生或经历一段指定时间后才返回。 返回值表示跨所有描述符集已就绪描述符的总个数。 三个描述符集都是值-结果参数，返回后只有就绪的描述符对应位被设置，其余都被清空。故每次重新调用select()时，都得再次把描述符集中关心的位设置。 什么时候套接字准备好读： 接收缓冲区字节数大于等于最低水位 接收到FIN，读半部被关闭 监听套接字监听到新的连接（还未完成连接） 有套接字错误待处理 什么时候套接字准备好写： 发送缓冲区字节数大于等于最低水位 写半部被关闭。如果写则产生SIGPIPE信号。 connect套接字已建立连接 有套接字错误待处理 什么时候套接字有异常条件待处理：存在带外数据或仍处于带外标记 123456789// fdarray: 指向一个结构数组的第一个元素，指定测试某个给定描述符fd的条件// nfds: 结构数组中元素的个数int poll(struct pollfd *fdarray, unsigned long nfds, int timeout);struct pollfd{ int fd; // 要检查的描述符 short events; // 在该描述符上感兴趣的事件(要测试的条件) short revents; // 返回该描述符的状态，避免了值-结果参数} poll()与select()类似，在处理流设备时能提供额外信息。能识别三类数据：普通，优先级带，高优先级 1234567891011121314151617181920212223242526// 函数创建一个epoll句柄，参数size表明内核要监听的描述符数量。调用成功时返回一个epoll句柄描述符，失败时返回-1。int epoll_create(int size);// 注册要监听的事件类型// epfd: epoll句柄// op: fd的操作类型// fd: 要监听的描述符// event: 要监听的事件int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);struct epoll_event { __uint32_t events; /* Epoll events */ epoll_data_t data; /* User data variable */};typedef union epoll_data { void *ptr; int fd; __uint32_t u32; __uint64_t u64;} epoll_data_t;// 等待事件的就绪，成功时返回就绪的事件数目，调用失败时返回 -1，等待超时返回 0。// epfd: epoll句柄// events: 从内核得到的就绪事件集合// maxevents: 告诉内核events的大小// timeout: 等到的超时事件int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout); epoll()是基于事件驱动的I/O方式，相对于select来说，epoll没有描述符个数限制，使用一个文件描述符管理多个描述符，将用户关心的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。 优点：它能显著提高程序在大量并发连接中只有少量活跃的情况下的系统CPU利用率。原因就是获取事件的时候，它无须遍历整个被侦听的描述符集，只要遍历那些被内核IO事件异步唤醒而加入Ready队列的描述符集合就行了。 epoll除了提供select/poll那种IO事件的水平触发（Level Triggered）外，还提供了边缘触发（Edge Triggered），这就使得用户空间程序有可能缓存IO状态，减少epoll_wait/epoll_pwait的调用，提高应用程序效率。 水平触发（LT）：默认工作模式，即当epoll_wait检测到某描述符事件就绪并通知应用程序时，应用程序可以不立即处理该事件；下次调用epoll_wait时，会再次通知此事件 边缘触发（ET）： 当epoll_wait检测到某描述符事件就绪并通知应用程序时，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次通知此事件。（直到你做了某些操作导致该描述符变成未就绪状态了，也就是说边缘触发只在状态由未就绪变为就绪时只通知一次）。 LT和ET原本应该是用于脉冲信号的，可能用它来解释更加形象。Level和Edge指的就是触发点，Level为只要处于水平，那么就一直触发，而Edge则为上升沿和下降沿的时候触发。比如：0-&gt;1 就是Edge，1-&gt;1 就是Level。ET模式很大程度上减少了epoll事件的触发次数，因此效率比LT模式下高。 epoll是Linux目前大规模网络并发程序开发的首选模型。在绝大多数情况下性能远超select和poll。目前流行的高性能web服务器Nginx正式依赖于epoll提供的高效网络套接字轮询服务。但是，在并发连接不高的情况下，多线程+阻塞I/O方式可能性能更好。 三者区别： select poll epoll 操作方式 遍历 遍历 回调 底层实现 数组 链表 红黑树 IO效率 每次调用都进行线性遍历，时间复杂度为O(n) 每次调用都进行线性遍历，时间复杂度为O(n) 事件通知方式，每当fd就绪，系统注册的回调函数就会被调用，将就绪fd放到readyList里面，时间复杂度O(1) 最大连接数 1024（x86）或2048（x64） 无上限 无上限 fd拷贝 每次调用select，都需要把fd集合从用户态拷贝到内核态 每次调用poll，都需要把fd集合从用户态拷贝到内核态 调用epoll_ctl时拷贝进内核并保存，之后每次epoll_wait不拷贝 2.3.4 使用select()解决之前客户端程序的问题123456789101112131415161718192021222324252627voidstr_cli(FILE *fp, int sockfd){ int maxfdp1; fd_set rset; char sendline[MAXLINE], recvline[MAXLINE]; FD_ZERO(&amp;rset); for ( ; ; ) { FD_SET(fileno(fp), &amp;rset); FD_SET(sockfd, &amp;rset); maxfdp1 = max(fileno(fp), sockfd) + 1; Select(maxfdp1, &amp;rset, NULL, NULL, NULL); if (FD_ISSET(sockfd, &amp;rset)) { /* socket is readable */ if (Readline(sockfd, recvline, MAXLINE) == 0) err_quit(&quot;str_cli: server terminated prematurely&quot;); Fputs(recvline, stdout); } if (FD_ISSET(fileno(fp), &amp;rset)) { /* input is readable */ if (Fgets(sendline, MAXLINE, fp) == NULL) return; /* all done */ Writen(sockfd, sendline, strlen(sendline)); } }} 2.3.5 客户端发送完数据后调用close()关闭连接，但服务器仍然有数据没有发完怎么办使用TCP半关闭，客户端发送FIN后，仍然保持套接字描述符打开以便读取，使用shutdown()函数。 12345// howto// SHUT_RD: 关闭读这一半，客户端不再读取数据，但可以写数据// SHUT_WR: 关闭写这一半，客户端不再写数据，但可以接收到服务器未发完的数据。称为“半关闭”// SHUT_RDWR: 全关闭int shutdown(int sockfd, int howto); close()与shutdown()对比： close()把描述符的引用计数减1，仅在该计数变为0时才关闭套接字。而shutdown()直接激发TCP正常终止序列。 close()终止读写两个方向的数据传送，而shutdown()可选。 2.3.6 如何为套接字设置超时 调用alarm()，在指定超时期满时产生SIGALRM信号，使用信号处理函数处理超时。 使用select()阻塞等待I/O，有内置时间限制。 使用较新的SO_RCVTIMEO和SO_SNDTIMEO选项。 2.3.7 在套接字上使用标准I/O函数库(fgets(),fputs()...)需要注意什么标准I/O库的缓冲策略与套接字不同，分为完全缓冲、行缓冲和不缓冲。终端设备使用行缓冲，标准输入/输出以及其它I/O流使用完全缓冲，标准错误输出总是不缓冲。最好避免在套接字上使用标准I/O库。 2.3.8 哪些套接字调用可能阻塞 输入操作：read, readv, recv, recvfrom, recvmsg，有数据到达时进程被唤醒。 输出操作：write, writev, send, sendto, sendmsg，缓冲区有足够空间写时被唤醒。UDP中不存在发送缓冲区，故不会因为空间不足被阻塞。 接收外来连接：accept，有新的连接到达时被唤醒。 发起外出连接：connect，一直阻塞到客户收到对于SYN的ACK才返回，至少等待一个RTT。 2.3.9 使用非阻塞的读写在什么情况下具有优势假设客户机调用write()向服务器发送数据，但是发送缓冲区已满，write()被阻塞。此时，可能有新的数据到达客户机的接收缓冲区，但是由于阻塞，客户机并不能处理收到的数据。 若使用非阻塞的读写，客户机发现write()阻塞后立即返回，此时便可以处理新到达的数据（防止在有效工作期间内阻塞）。 显然，这个问题也可以通过多线程或多进程来解决（推荐做法），一个线程/进程负责读，一个负责写。这样解决更加简单，但是性能不如非阻塞读写。 2.3.10 若使用非阻塞套接字，如何避免使用轮询配合select()或poll()，当有套接字就绪时通知进程，但需要阻塞在select()上。 2.3.11 何时适合使用非阻塞的connect() 在三次握手期间，可以不阻塞转而进行其它处理。 同时建立多个连接，例如web浏览器，客户先建立一个HTTP连接，获取一个主页。该主页含有多个对于其它网页的引用，可使用非阻塞连接同时获取多个主页。 通过指定select()的时间限制，缩短connect()的超时。 2.3.12 TCP会使用信号驱动式I/O吗不会，因为TCP套接字上的众多事件都会产生SIGIO信号，过于频繁，信号处理函数无法辨别发生什么事件。唯一现实用途：基于UDP的NTP服务器程序。 2.4 UDP套接字2.4.1 简述UDP客户机/服务器的工作模型 2.4.2 简述UDP的主要套接字12ssize_t recvfrom(int sockfd, void *buff, size_t nbytes, int flags, struct sockaddr *from, socklen_t *addrlen);ssize_t sendto(int sockfd, void *buff, size_t nbytes, int flags, const struct sockaddr *to, socklen_t addrlen); 与read(),write()极为相似。 写入长度为0的数据报式可行的，接收到0值也是可接受的，不像TCP中接收到0表示对端以关闭连接。 2.4.3 TCP和UDP服务器应该并发还是迭代大多数TCP服务器是并发的，大多数UDP服务器是迭代的。 2.4.4 若客户机上的某个进程得知了UDP分配的临时端口号，并向其中发送数据怎么办根据数据报发送者的IP和端口，保留来自数据报所法网服务器的应答。 2.4.5 使用select()设计一个TCP+UDP服务器程序12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273intmain(int argc, char **argv){ int listenfd, connfd, udpfd, nready, maxfdp1; char mesg[MAXLINE]; pid_t childpid; fd_set rset; ssize_t n; socklen_t len; const int on = 1; struct sockaddr_in cliaddr, servaddr; void sig_chld(int); /* 4create listening TCP socket */ listenfd = Socket(AF_INET, SOCK_STREAM, 0); bzero(&amp;servaddr, sizeof(servaddr)); servaddr.sin_family = AF_INET; servaddr.sin_addr.s_addr = htonl(INADDR_ANY); servaddr.sin_port = htons(SERV_PORT); Setsockopt(listenfd, SOL_SOCKET, SO_REUSEADDR, &amp;on, sizeof(on)); Bind(listenfd, (SA *) &amp;servaddr, sizeof(servaddr)); Listen(listenfd, LISTENQ); /* 4create UDP socket */ udpfd = Socket(AF_INET, SOCK_DGRAM, 0); bzero(&amp;servaddr, sizeof(servaddr)); servaddr.sin_family = AF_INET; servaddr.sin_addr.s_addr = htonl(INADDR_ANY); servaddr.sin_port = htons(SERV_PORT); Bind(udpfd, (SA *) &amp;servaddr, sizeof(servaddr));/* end udpservselect01 *//* include udpservselect02 */ Signal(SIGCHLD, sig_chld); /* must call waitpid() */ FD_ZERO(&amp;rset); maxfdp1 = max(listenfd, udpfd) + 1; for ( ; ; ) { FD_SET(listenfd, &amp;rset); FD_SET(udpfd, &amp;rset); if ( (nready = select(maxfdp1, &amp;rset, NULL, NULL, NULL)) &lt; 0) { if (errno == EINTR) continue; /* back to for() */ else err_sys(&quot;select error&quot;); } if (FD_ISSET(listenfd, &amp;rset)) { len = sizeof(cliaddr); connfd = Accept(listenfd, (SA *) &amp;cliaddr, &amp;len); if ( (childpid = Fork()) == 0) { /* child process */ Close(listenfd); /* close listening socket */ str_echo(connfd); /* process the request */ exit(0); } Close(connfd); /* parent closes connected socket */ } if (FD_ISSET(udpfd, &amp;rset)) { len = sizeof(cliaddr); n = Recvfrom(udpfd, mesg, MAXLINE, 0, (SA *) &amp;cliaddr, &amp;len); Sendto(udpfd, mesg, n, 0, (SA *) &amp;cliaddr, len); } }}/* end udpservselect02 */ 2.4.6 何时使用UDP，何时不使用分析优势：支持广播和组播，没有连接的建立和拆除。 建议（存在例外）： 对于广播和组播应用程序必须使用UDP。 对于简单的请求-应答应用程序可以使用UDP，但是需要在应用程序中自己实现错误检测。 对于海量数据传输（文件传输）绝不应该使用UDP。 2.4.7 如何使UDP应用变得可靠在不可靠的数据服务（UDP）上加入可靠性的应用程序，增加以下特性： 超时和重传：用于处理丢失的数据报 序列号：供客户验证一个应答是否匹配相应的请求。如：客户机为每个请求冠以一个序列号，要求服务器返回时回射这个序列号。 2.4.8 若客户与UDP服务器需要交换多个数据报，服务器如何识别该客户服务器可以为每个这样的客户创建一个新的套接字，绑定一个临时端口，然后使用该套接字发送对该客户的所有应答，并要求客户查看服务器第一个应答的端口号，把本请求的后续数据报都发送到该端口。 2.5 域名解析2.5.1 如何实现名字到地址以及服务到端口的互相转换12345678// hostname: 一个主机名或地址串// service: 一个服务名或十进制端口号// hints: 填入关于期望返回的消息类型的暗示// result: 返回串接起来的addrinfo结构链表int getaddrinfo(const char *hostname, const char *service, const struct addrinfo *hits, struct addrinfo **result);// getaddrinfo的互补函数int getnameinfo(const struct sockaddr *sockaddr, socklen_t addrlen, char *host, socklen_t hostlen, char *sev, socklen_t sevlen, int flags); 2.6 客户/服务器程序设计范式2.6.1 TCP迭代服务器程序总是在完全处理某个客户的请求后才转向下一个客户。比较少见。 2.6.2 TCP并发服务器程序，每个客户一个子进程调用fork()派生一个子进程来处理每个客户。绝大多数服务器程序采用的范式。 2.6.3 TCP预先派生子进程服务器程序，accept无上锁保护服务器在启动阶段预先派生一定数量的子进程，当客户连接到达时，子进程可以立即服务。 优点：无需fork()开销就能立即服务； 缺点：不知道预先需要派生多少子进程。由于所有子进程阻塞于的套接字描述符均指向同一结构，因此当有一个连接到达时，所有子进程都被唤醒，却只有一个进程获得连接，导致性能受损。（惊群） 2.6.4 TCP预先派生子进程服务器程序，accept使用文件上锁保护程序在调用accept前安置文件锁，这样任意时刻只有一个子进程阻塞在accept调用中，其余子进程阻塞在锁上。当accept返回时，文件锁被释放。 缺点：涉及文件系统操作，费时 2.6.5 TCP预先派生子进程服务器程序，accept使用线程上锁保护把文件上锁改为线程上锁，但需要把某种类型的同步锁放在共享内存区中。(使用内存映射mmap()) 2.6.6 TCP预先派生子进程服务器程序，传递描述符只让父进程调用accept，然后把已连接的套接字传递给某个子进程。使用进程通信的任一种方法传递描述符（管道，FIFO，消息队列） 缺点：费时 2.6.7 TCP并发服务器程序，每个客户一个线程调用pthread_create()创建一个线程来处理每个客户。 2.6.8 TCP预先创建线程服务器程序，每个线程各自accept服务器在启动阶段预先创建一个线程池，当客户连接到达时，线程可以立即服务。 每个线程各自accept需要使用互斥锁，保证任何时刻只有一个线程在调用accept。无需使用文件锁，因为同一进程内的各个线程共享互斥锁。 2.6.9 TCP预先创建线程服务器程序，主线程统一accept主线程可以把已连接的套接字传递给某个可用线程，无需进程间通信机制。 （未整理完~） 3 进程间通信3.1 IPC基础3.1.1 什么是IPCInterprocess Communication，进程间通信。运行在某个操作系统上的不同进程间各种消息传递的方式。 3.1.2 有哪些IPC形式 管道和FIFO(有名管道) POSIX消息队列 System V 消息队列 共享内存区（最快） RPC远程过程调用 3.1.3 有哪些同步方式 互斥锁(mutex)和条件变量(conditional variable)，往往用于线程间同步，也能用于进程间同步 读写锁(read-write lock) 记录锁（文件锁） POSIX信号量(semaphore) System V 信号量(semaphore) 3.1.4 进程间共享信息有哪三种方式 共享驻留于文件系统中某个文件上的某些信息，需要穿越内核(read, write)。需要同步。 共享驻留于内核中的某些信息。如管道，System V消息队列和System V 信号量。需要对内核进行系统调用。 共享内存区。每个进程一旦设置好共享内存区，就根本不需要内核的参与就能访问其中的数据。需要同步。 3.1.5 简述各种IPC形式的持续性 随进程持续：IPC对象一直存在到打开该对象的最后一个进程关闭该对象为止。如管道，FIFO，POSIX互斥锁，POSIX条件变量，POSIX读写锁，各种套接字。 对内核持续：IPC对象一直存在到内核重新自举或显示删除该对象为止。如POSIX消息队列，POSIX有名信号量，System V 消息队列，System V 信号量，共享内存区。 随文件系统持续：暂无。原因是可能导致性能下降。 3.1.6 为什么IPC对象需要有名字/标识符当两个或多个无亲缘关系的进程使用IPC对象时，其中一个进程（服务器）需要创建该IPC对象并指定名字，其余进程则可以通过名字指定同一个IPC对象。 管道没有名字，因此不能用于无亲缘关系的进程间。 3.2 管道和FIFO3.2.1 如何创建一个管道连接父子进程1int pipe(int fd[2]); 返回两个文件描述符：fd[0]和fd[1]。前者打开来读，后者打开来写。提供单向数据流。 3.2.2 使用管道设计一个文件访问客户-服务器程序 全双工管道由两个半双工管道构成。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475void client(int, int), server(int, int);intmain(int argc, char **argv){ int pipe1[2], pipe2[2]; pid_t childpid; Pipe(pipe1); /* create two pipes */ Pipe(pipe2); if ( (childpid = Fork()) == 0) { /* child */ Close(pipe1[1]); Close(pipe2[0]); server(pipe1[0], pipe2[1]); exit(0); } /* 4parent */ Close(pipe1[0]); Close(pipe2[1]); client(pipe2[0], pipe1[1]); Waitpid(childpid, NULL, 0); /* wait for child to terminate */ exit(0);}voidclient(int readfd, int writefd){ size_t len; ssize_t n; char buff[MAXLINE]; /* 4read pathname */ Fgets(buff, MAXLINE, stdin); len = strlen(buff); /* fgets() guarantees null byte at end */ if (buff[len-1] == '\\n') len--; /* delete newline from fgets() */ /* 4write pathname to IPC channel */ Write(writefd, buff, len); /* 4read from IPC, write to standard output */ while ( (n = Read(readfd, buff, MAXLINE)) &gt; 0) Write(STDOUT_FILENO, buff, n);}voidserver(int readfd, int writefd){ int fd; ssize_t n; char buff[MAXLINE+1]; /* 4read pathname from IPC channel */ if ( (n = Read(readfd, buff, MAXLINE)) == 0) err_quit(&quot;end-of-file while reading pathname&quot;); buff[n] = '\\0'; /* null terminate pathname */ if ( (fd = open(buff, O_RDONLY)) &lt; 0) { /* 4error: must tell client */ snprintf(buff + n, sizeof(buff) - n, &quot;: can't open, %s\\n&quot;, strerror(errno)); n = strlen(buff); Write(writefd, buff, n); } else { /* 4open succeeded: copy file to IPC channel */ while ( (n = Read(fd, buff, MAXLINE)) &gt; 0) Write(writefd, buff, n); Close(fd); }} 3.2.3 简述popen()和pclose()函数123// command为shell命令行，由sh程序处理。FILE *popen(const char *command, const char *type);int pclose(FILE *stream); 标准I/O库提供的函数，用于在调用进程和所指定命令之间创建一个管道。返回值为标准I/O FILE指针，用于输入或输出，取决于type。 3.2.4 简述FIFO与管道的区别123// pathname指定FIFO的名字，是一个普通的Unix路径名// mode指定文件权限位int mkfifo(const char *pathname, mode_t mode); 管道没有名字，最大劣势时只能用于有一个共同祖先进程的各个进程之间。 FIFO类似于管道，是单向数据流，但有一个路径名与之关联，允许无亲缘关系的进程访问同一个FIFO，也称为有名管道。 创建出FIFO后，使用open()打开路径名，然后可进行读或写之中的一种操作。 3.2.5 使用FIFO设计一个文件访问客户-服务器程序1234567891011121314151617181920212223242526272829303132333435363738void client(int, int), server(int, int);intmain(int argc, char **argv){ int readfd, writefd; pid_t childpid; /* 4create two FIFOs; OK if they already exist */ if ((mkfifo(FIFO1, FILE_MODE) &lt; 0) &amp;&amp; (errno != EEXIST)) err_sys(&quot;can't create %s&quot;, FIFO1); if ((mkfifo(FIFO2, FILE_MODE) &lt; 0) &amp;&amp; (errno != EEXIST)) { unlink(FIFO1); err_sys(&quot;can't create %s&quot;, FIFO2); } if ( (childpid = Fork()) == 0) { /* child */ readfd = Open(FIFO1, O_RDONLY, 0); writefd = Open(FIFO2, O_WRONLY, 0); server(readfd, writefd); exit(0); } /* 4parent */ writefd = Open(FIFO1, O_WRONLY, 0); readfd = Open(FIFO2, O_RDONLY, 0); client(readfd, writefd); Waitpid(childpid, NULL, 0); /* wait for child to terminate */ Close(readfd); Close(writefd); Unlink(FIFO1); Unlink(FIFO2); exit(0);} 3.2.6 如何用FIFO实现单服务器-多客户模型服务器以众所周知的路径名创建一个FIFO，从这个FIFO处读取客户的请求。每个客户通过服务器创建的FIFO发送数据，把FIFO名字和PID发给服务器，创建自己的FIFO，服务器向客户创建的FIFO中发送数据。 3.2.7 管道和FIFO上的数据有消息边界吗没有，它们的数据是一个字节流，类似于TCP，把字节流分隔成各个记录的方法应当由应用程序实现。消息队列会提供消息边界，类似于UDP。 3.3 消息队列 3.3.1 什么是消息队列一个消息链表，有权限的进程可往队列中放置消息，其它有权限的进程可从队列中取走消息。每个消息都是一个记录，由发送者赋予一个优先级。某个进程写消息时，并不需要另一个进程阻塞等待消息。 3.3.2 简述消息的格式 优先级 （类型） 数据部分长度 数据本身 消息有边界。队列头中的相应字段指定队列最大消息数和每个消息的最大大小。 3.3.3 如何创建、关闭、删除一个POSIX消息队列12345678910// 创建或打开已存在的消息队列// name为消息队列的名字// oflag为标志位mqd_t mq_open(const char *name, int oflag, ...);// 关闭并不删除，具有内核持续性int mq_close(mqd_t mqdes);// 删除队列，引用计数为0后才真正删除int mq_unlink(const char *name); mq_open()返回值是消息队列描述符，用于标识队列以及作为消息队列操作函数的第一个参数。 3.3.4 如何设置POSIX消息队列的属性12int mq_getattr(mqd_t mqdes, struct mq_attr *attr);int mq_setattr(mqd_mqdes, const struct mq_attr *attr, struct mq_attr *oattr); 3.3.5 如何在POSIX消息队列中放置或取走消息12int mq_send(mqd_mqdes, const char *ptr, size_t len, unsigned int prio);ssize_t mq_receive(mqd_t mqdes, char *ptr, size_t len, unsigned int *priop); 3.3.6 简述POSIX消息队列的异步事件通知机制1int mq_notify(mqd_t mqdes, const struct sigevent *notification); 若有消息被放置到了空消息队列中，有两种事件处理方式： 产生一个信号，进程收到信号后执行信号处理函数，在处理函数中需使用异步信号安全的函数 创建一个线程执行指定函数 处理方式定义在sigevent中。进程（只准一个）使用mq_notify()注册接收该队列的通知。通知发出后，需重新注册。 3.3.7 简述System V 消息队列的相关函数1234567891011// 创建或访问已打开的消息队列int msgget(key_t key, int oflag);// 放置消息int msgsnd(int msqid, const void *ptr, size_t length, int flag);// 读出消息ssize_t msgrcv(int msqid, void *ptr, size_t length, long type, int flag);// 控制操作int msgctl(int msqid, int cmd, struct msqid_ds *buff); 3.3.8 如何使用单个消息队列实现单服务器-多客户模型服务器使用众所周知的键值创建消息队列，客户将自己的PID作为消息的一部分传递，服务器回复消息时把客户的PID作为消息类型，客户可以在消息队列中取出特定消息的数据。 进一步优化：每个客户创建自己的消息队列，向众所周知队列发送消息时，捎带自己消息队列的键值，服务器可以派生子进程发送消息到客户的消息队列中，每个客户从自己的消息队列中取出数据。 3.3.9 简述POSIX消息队列和System V 消息队列的对比 POSIX消息队列的读总是返回最高优先级的最早消息，System V 消息队列的读可以返回任意指定优先级的消息。 当向空队列放置一个消息时，POSIX消息队列允许产生一个信号或启动一个线程，而System V 消息队列不支持。 两种消息队列都不使用真正的描述符，造成使用select()和poll()的困难。 推荐使用POSIX消息队列。 3.4 同步3.4.1 简述互斥锁及其用法互斥锁指代相互排斥(mutual exclusion)，是最基本的同步形式。通常用于保护临界区中被操纵的数据，保证任何时刻只有一个线程在执行其中的代码。若被初始化在共享内存区中（动态分配），可用于保护进程间的共享数据。 1234567891011// 上锁int pthread_mutex_lock(pthread_mutext_t *mptr);// 非阻塞上锁int pthread_mutex_trylock(pthread_mutex_t *mptr);// 释放锁int pthread_mutex_unlock(pthread_mutex_t *mptr);// 静态分配的初始化static pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER; 3.4.2 简述生产者-消费者问题也被成为有界缓冲区问题。一个或多个生产者线/进程创建者一个个数据条目，然后这些条目由一个或多个消费者线/进程处理。数据条目的传递以某种类型的IPC为媒介。需要某种形式的同步。 3.4.3 简述隐式同步和显式同步隐式同步：如管道，消息队列等，生产者和消费者之间所需的同步由内核自动以一定方式处理。 显式同步：共享内存区作为生产者和消费者之间的IPC时，进程需执行显式同步。 3.4.4 生产者正在生产某条目时加锁，消费者只能轮询等待。如何优化允许消费者暂时休眠，直到生产者完成对目标条目的生产并释放锁。此时需要使用条件变量，允许一个线/进程休眠到发生某件事为止。 3.4.5 简述条件变量及其用法互斥锁用于上锁，条件变量用于等待。每个条件变量总是有一个互斥锁与之关联（防止多个线程同时检验条件）。通常将互斥锁、条件变量和要检验的条件放在同一个结构体中。 1234567891011121314151617struct{ pthread_mutex_t mutex; // 与条件变量关联的互斥锁 pthread_cond_t cond; // 条件变量 int check; // 条件是什么} cv;// (1) 先获取mutex// (2) 检验check条件是否满足// (3) 若不满足，调用pthread_cond_wait，该函数：先给释放mutex(给其它线程检查条件的机会)，然后令线程休眠 (原子操作)// (4) 当有其它线程调用pthread_cond_signal时，休眠线程被唤醒，pthread_cond_wait返回前先获取mutex，因为之后要更新条件int pthread_cond_wait(pthread_cond_t *cptr, pthread_mutex_t *ptr);// 唤醒阻塞在cond上的线程int pthread_cond_signal(pthread_cond_t *cptr);// 静态分配的初始化static pthread_cond_t cond = PTHREAD_COND_INITIALIZER; 3.4.6 简述生产者和消费者如何使用条件变量123456789101112131415// Producerpthread_mutex_lock(&amp;cv.mutex); // 获取锁if(cv.check == false){ // 只在条件由false变为true时发信号 pthread_cond_signal(&amp;cv.cond); // 唤醒等待线程}cv.check == true; // 条件改为truepthread_mutex_unlock(&amp;cv.mutex); // 释放锁// Consumerpthread_mutex_lock(&amp;cv.mutex); // 获取锁while(cv.check == false){ // 若条件不满足就一直休眠。放在循环中的目的是防止虚假唤醒，解决方法就是再测试一次条件 pthread_cond_wait(&amp;cv.cond, &amp;cv.mutex); // 休眠直至被唤醒，此时锁已经被释放}cv.check == false; // 此处再次获得锁，更新条件为falsepthread_mutex_unlock(&amp;cv.mutex); // 释放锁 3.4.7 如何选择唤醒等待在条件变量上的线程的个数通常情况下，pthread_cond_signal()只唤醒等待在相应条件变量上的一个线程。某些情况下，可以唤醒所有等待线程: 1int pthread_cond_broadcast(pthread_cond_t *cptr); 例如，当一个写入者完成访问并释放相应的锁后，它希望唤醒所有排队的读出者，因为允许同时有多个读出者。 没有特殊情况，必须都使用广播唤醒所有进程。 3.4.8 如何设置条件变量的等待时间1int pthread_cond_timewait(pthread_cond_t *cptr, pthread_mutex_t *mptr, const struct timespec *abstime); 3.4.9 如何初始化或摧毁一个互斥锁和条件变量12345// 动态分配int pthread_mutex_init(pthread_mutex_t *mptr, const pthread_mutexattr_t *attr);int pthread_mutex_destroy(pthread_mutex_t *mptr);int pthread_cond_init(pthread_cond_t *cptr, const pthread_condattr_t *attr);int pthread_cond_destroy(pthread_cond_t *mptr); 3.4.10 如何使互斥锁和条件变量在进程间共享1234567// value:// PTHREAD_PROCESS_PRIVATE: 线程间共享// PTHREAD_PROCESS_SHARED: 进程间共享int pthread_mutexattr_getshared(pthread_mutexattr_t *attr, int *valptr);int pthread_mutexattr_setshared(pthread_mutexattr_t *attr, int value);int pthread_condattr_getshared(pthread_condattr_t *attr, int *valptr);int pthread_condattr_setshared(pthread_condattr_t *attr, int value); 3.4.11 什么是读写锁，什么时候使用又叫共享-独占锁，允许同时有多个读者，但只能有一个写者。当读数据比修改数据更频繁时使用。 3.4.12 简述读写锁的用法12345678910111213141516// 获取及释放int pthread_rwlock_rdlock(pthread_rwlock_t *rwptr);int pthread_rwlock_wrlock(pthread_rwlock_t *rwptr);int pthread_rwlock_unlock(pthread_rwlock_t *rwptr);// 非阻塞int pthread_rwlock_tryrdlock(pthread_rwlock_t *rwptr);int pthread_rwlock_trywrlock(pthread_rwlock_t *rwptr);// 初始化及摧毁int pthread_rwlock_init(pthread_rwlock_t *rwptr, const pthread_rwlockattr_t *attr);int pthread_rwlock_destroy(pthread_rwlock_t *rwptr);// 属性设置int pthread_rwlockattr_init(pthread_rwlock_t *rwptr);int pthread_rwlockattr_destroy(pthread_rwlock_t *rwptr); 3.4.13 简述使用互斥锁和条件变量实现读写锁的思路 每个读写锁的数据结构中含有一个互斥锁mutex，读等待的条件变量rdcond，写等待的条件变量wrcond，读等待的线程数量nrdwaiting，写等待的线程数量nwrwaiting，一个引用计数器ref。 ref含义：-1: 该锁为写锁；0：该锁没有被获得过，可用；大于0：容纳了这么多的读锁。 获得读锁的步骤： 先获取mutex 若ref&lt;0或还有写等待者，则nrdwaiting++，等待rdcond。 否则可以获得读锁，ref++ 获得写锁的步骤： 先获取mutex 若ref不为0，则nwrwaiting++，等待wrcond 否则可以获得写锁，ref=-1 释放锁的步骤： 若ref&gt;1：正常释放读锁，ref– 若ref=-1或ref==1，导致锁可用： 若有写者在等待，则唤醒等待在wrcond上的唯一写线程 若没有写者，则唤醒等待在rdcond上的所有读线程 3.4.14 线程被取消或自愿终止后，如何处理获得的锁使用清理处理程序恢复到原先的状态： 12void pthread_cleanup_push(void (*function)(void *), void *arg);void pthread_cleanup_pop(int execute); 3.4.15 什么是记录锁读写锁的一种扩展形式，用于进程间共享某个文件的读写。支持对文件的某一字节范围上锁。 3.4.16 如何使用记录锁12345678910struct flock{ short l_typpe; // 读锁还是写锁还是解锁 short l_whence; // 解释字节偏移：相对于文件开头还是当前字节还是尾部 off_t l_start; // 相对偏移 off_t l_len; // 上/解锁的连续字节数 pid_t l_pid;};// 记录上锁的接口int fcntl(int fd, int cmd, struct flock *arg); 3.4.17 若持有记录锁的进程关闭与文件关联的描述符会发生什么与该文件关联的所有记录锁都会被删除。并且记录锁不能被子进程继承。 3.4.18 劝告性上锁和强制性上锁有什么区别记录锁使用劝告性上锁，不能防止非协作进程读写锁定的文件。 强制性上锁会使内核检查每一个读写系统调用，验证其操作不会干扰某个进程持有的某个记录锁。 3.4.19 如何确保守护进程在任何时刻只有一个副本在运行使用记录锁。守护进程在启动时，都要打开一个文件，写入PID，然后获取整个文件的写锁，以防其它副本创建。 3.4.20 什么是信号量(semaphore)一种线/进程同步原语。一般有下列几种操作： 创建(create)，指定信号量初值，大于零，一般表示可用的共享资源总数。 等待(wait)一个信号量（sem.P()），测试信号量的值，若为0则线程等待，直到值大于0后被唤醒，唤醒后，将信号量的值减1。 挂出(post)一个信号量（sem.V()），信号量被加1。 3.4.21 对比互斥锁、条件变量和信号量 互斥锁总是由给它上锁的线程解锁，信号量的挂出却不必由执行过它的等待操作的同一线程执行。 互斥量要么被锁住，要么被解开，类似二值信号量。 信号量挂出操作总被记住（反映在计数值上），而若没有线程等待在条件变量上，向条件变量发送的信号被丢失。 互斥锁是为上锁而优化的，条件变量是为等待而优化的，信号量即可用于上锁，也可用于等待，因而可能会由更多开销。 3.4.22 有哪几种信号量 POSIX有名信号量，用于线程和进程同步。 POSIX内存信号量（无名），用于线程同步。若存放在内存共享区，则可用于进程同步。 System V 信号量，用于线程和进程同步。 3.4.23 简述POSIX信号量的用法123456789101112131415161718// 新建或打开一个有名信号量sem_t *sem_open(const char *name, int oflag, mode_t mode, usigned int value);// 关闭信号量int sem_close(sem_t *sem);// 删除信号量int sem_unlink(const char *name);// 等待信号量 P()int sem_wait(sem_t *sem);int sem_trywait(sem_t *sum);// 挂出信号量 V(), 所有同步原语中，只有sem_post()是异步信号安全的int sem_post(sem_t *sem);int sem_getvalue(sem_t *sem, int *valp);// 初始化和摧毁,shared决定是否要在进程间共享int sem_init(sem_t *sem, int shared, unsigned int value);int sem_destroy(sem_t *sem); 3.4.24 简述POSIX信号量和System V 信号量的区别 System V 信号量使用了计数信号量集，多个信号量构成一个集合。 System V 信号量对成员操作有3种：测试值是否为0，加一个整数，减一个整数。而POSIX信号量只能加一或减一。 3.5 共享内存区3.5.1 为什么共享内存区是IPC形式中最快的内存区映射到共享它的进程的地址空间后，这些进程间数据的传递就不再涉及内核（无需再使用read,write等系统调用，直接进行内存操作）。需要某种形式的同步。 3.5.2 为什么使用内存映射技术 使用普通文件，提供内存映射I/O，简化代码 使用特殊文件，提供匿名内存映射 使用shm_open()，提供进程间的POSIX共享内存区 3.5.3 简述内存映射的相关函数 1void *mmap(void *addr, size_t len, int prot, int flags, int fd, off_t offset); addr指定描述符fd应该被映射到的进程内空间的起始地址，通常被指定为一个空指针，让内核自己选择。返回值都是最终映射到内存区的起始地址。返回成功后可关闭文件描述符。 len是映射到调用进程地址空间的字节数，从被映射文件开头起第offset个字节处开始算起。 prot指定内存映射区是：可读、可写、可执行、不可访问。 flags：若为MAP_SHARED，则所做修改对所有共享该对象的进程都可见，确实改变了低层支撑对象；若为MAP_PRIVATE，所做修改只对该进程可见，没有改变低层对象。 1int munmap(void *addr, size_t len); 从进程的地址空间中删除一个映射关系。 1int msync(void *addr, size_t len, int flags); 强制使映射区数据与硬盘数据同步。 3.5.4 所有文件都可以内存映射吗不能，比如访问终端的文件描述符，套接字描述符。 3.5.5 简述POSIX共享内存区的用法12int shm_open(const char *name, int oflag, mode_t mode); // 返回fd，然后需要调用mmap()int shm_unlink(const char *name); 指定一个名字参数调用shm_open()，创建一个新的共享内存区对象或打开一个已存在的共享内存区对象。（该函数的返回值就是一个文件描述符） 然后调用mmap把这个共享内存区映射到调用进程的地址空间。名字参数可供其它进程使用。 3.6 过程调用3.6.1 有哪三种过程调用 本地过程调用：被调用过程（函数）与调用过程处于同一进程。 单台主机的远程过程调用（门）：被调用过程和调用过程处于不同的进程中，处于单台主机中。 主机间的远程过程调用：被调用过程和调用过程处于不同的进程中，处于网络连接的不同主机中。 （未整理完~） Reference: UC Berkeley CS168 Introduction to Internet 《TCP/IP: Illustrated - Volume Ⅰ The Protocols》 《UNIX Network Programming》 计算机网络面试突击","link":"/2021/04/26/2021-04-26-interview-internet-protocols/"},{"title":"2020年微信小程序云开发大赛-大学校园闲置物品交易平台","text":"Abstract: 2020年微信小程序云开发大赛参赛作品的简要介绍，包括背景、功能、架构等等，欢迎到GitHub上为项目点赞！ 1. 项目介绍作为一个大学生，经常会有一些闲置的物品需要处理，物品仍有使用价值，直接扔掉有些可惜，只好寻找再次出售的途径；或许也想要买一些物品，但不需要全新的，如二手自行车等。购买出售的途径一般有两个： 二手物品交易平台，如闲鱼等。但是，这种途径并不是十分非常适合大学生，本来就学业繁忙的我们需要抽出时间去寄送包裹，而且此类平台上骗子众多，买到假货后甚至无从申诉，权益可能受到损害。 校内的各种闲置物品交换群（QQ，微信）：此类途径具备了一定的安全性，而且方便快捷，因为都是本校的学生线上联系后线下交易。但是仍然存在信息获取效率低下的问题，很难从几百条群消息中准确的找到自己想要的物品，自己发布的商品也可能被群消息淹没。除此之外，信息的时效性很难得到保障，看到发布的商品后，很可能那件商品已经出售，需要要麻烦卖家亲自删除消息或说明商品已卖出。 针对上述途径存在的问题，我们设计了“大学校园闲置物品交易平台”的微信小程序，使用学生验证（暂未完成）、各大学相互隔离、线下交易的方式确保安全性，提供线上发布、商品列表与商品详情详情展示、商品检索的功能以保障较高的消息获取效率，采用商品问答、商品状态自动更新的方式确保信息的时效性。在大学校园闲置物品交易平台中，大学生能够在不涉及线上支付的情况下安全快捷地出售与购买二手物品。 2. 各页面功能展示2.1 商品列表与搜索 首页为商品列表展示界面。 首页上方显示用户所在大学与搜索框，搜索框下方为大屏轮播图（暂未完成），可用来展示商品或广告。 轮播图下方为商品分类栏，包含了大多数常用分类，用户可以浏览自己感兴趣的分类。 主体部分为商品列表展示卡片，展示商品图片、标题、简介、状态、价格及数量。列表展示采用分页加载，每次加载10条商品信息，下滑到底部后，会自动加载下面10条商品信息，直到加载完所有商品。 搜索后的商品展示与首页的展示方式类似，采用模糊搜索，查询匹配到的商品的标题。 2.2 商品详情页与商品问答 点击商品卡片后，进入商品详情界面。 界面上方为商品详情图片的轮播图，点击图片可以查看具体的图片，左右滑动查看列表中所有图片。 详情图下方为商品详情信息，包括标题、状态、价格、简介、数量、备注及原始购买链接。 详情信息下方为商品的问答区，可以在此询问卖家关于商品的问题，卖家可以在此回复用户。 点击提问/回复后可以发表提问/回复内容，并在问答区展示。 商品问题仍然采用分页加载模式。当问题的回复超过2条时，回复卡片将自动折叠，点击查看全部回答可以跳转至问题详情界面，采用分页加载的模式展示所有回复。 2.3 商品发布 点击底部Tab Bar的加号可以进入商品发布界面，上传前会进行表单验证，防止非法的数据存入数据库。上传时会让用户选择是否接受新交易推送，无论是否同意均不影响商品上传。上传成功后会自动跳转到商品列表界面，用户可以看到自己刚发布的商品。 2.4 发起交易与交易操作 点击商品详情界面的发起交易后，若商品能够被购买，则进入确认交易界面。用户可以选择商品数量（不超过库存），查看总价格，最后点击确认交易。 若商品能够被购买，则更新商品库存，有必要的话更新商品状态，生成交易详情，跳转至交易详情界面。 至此，线上的活动暂告一段落，点击查看对方联系方式，通过对方的联系方式自行进行线下交易，结束后，当双方都点击确认交易完成后，交易结束。若任一方想要中止交易，直接点击取消交易即可。进行中的交易若无人点击确认完成，将在7天后状态自动变为已完成。 2.5 用户信息管理 点击底部Tab Bar我的，可以进入管理界面。 点击头像/昵称/学校或在我的信息中，可以编辑个人信息，修改昵称、微信QQ联系方式与大学。 2.6 交易与商品管理 在“我的交易”与“我发布的商品”中，可以查看交易详情，进行交易操作，或者查看发布的商品，选择删除商品。加载方式均为分页加载。 2.7 新交易推送 为了提醒卖家有人购买其发布的商品，小程序加入消息推送功能。在发布商品时，会让用户选择允许接受新交易通知。点击允许后，若有人对卖家发布的商品成功发起交易，卖家便会收到消息推送，点击推送内容可直接查看交易详情，进行交易操作。 由于微信小程序对于用户隐私的保护，个人小程序的消息订阅仅是一次性的。若想再次收到交易推送，则需要在“我的”界面中点击“接受新交易推送一次”。 2.8 其他其他界面包括index页、用户注册页、小程序介绍页等等，均为辅助功能，在此不再赘述。 3. 项目架构下面时此项目的详细架构，对此项目感兴趣的小伙伴可以仔细阅读，如有不妥，敬请指正。 3.1 总体架构 本项目以云开发为核心，主要包括：云函数，云数据库，云存储，云调用和HTTP API（暂未完成）五个部分。除了云开发外，还有小程序端，后台管理系统（CMS），第三方服务器等部分。 云函数： 接收小程序端发来的请求 接收CMS通过HTTP API发来的请求（暂未完成） 访问云数据库和云存储获取数据，然后发送回复 使用云调用，如消息推送 向第三方服务器发送请求，如用于学生验证的学校服务器（暂未完成） 云数据库： 被云函数访问 通过HTTP API被访问（暂未完成） 云存储： 被云函数访问 通过HTTP API被访问（暂未完成） 云调用： 通过云函数被调用 访问腾讯云服务，如消息推送 HTTP API（暂未完成）： 被后台管理系统调用 调用云函数，访问云数据库，云存储 小程序端： 只访问云函数获取服务 后台管理系统（暂未完成）： 只访问HTTP API获取服务 下面将对上述架构的每一部分进行详述。 3.2 云数据库表结构 由于项目较大，涉及到的实体较多，故先画出该项目的ER Model（为了便于展示，略去了attribute）。实体共有8个：用户，大学，商品，商品分类，商品问题，问题回复，交易，轮播图（暂未完成）。上述实体的关系如图片所示。 根据模型图，可以在云数据库中建立8张数据表，对于特定的键建立索引。本项目，除了图片以外，删除方式都是软删除，故添加is_deleted字段。 3.3 小程序端架构 小程序端共分为以下几个部分：用户模块、商品模块、交易模块、工具类、学生验证（暂未完成）、云函数统一接口、缓存管理、组件库和CSS库。 用户模块：包括用户注册、学生身份验证和用户信息管理。 商品模块：包括商品列表、商品搜索、商品详情、发布商品、商品提问、提问回复和商品管理。 交易模块：包括发起交易、交易操作和交易管理。 工具类：返回内容格式化、时间展示格式化、表单验证。 学生验证（暂未完成）：对于特点操作，访问云函数之前先验证学生身份。 云函数统一接口：将云函数返回的数据加工成合适的格式，直接供页面逻辑层使用。 缓存管理：将商品列表，用户信息，商品分类等数据缓存在本地，提高小程序性能，合适的时候清除缓存，重新访问云函数统一接口。 组件库：为了加快开发速度，专注云开发功能，本项目使用vant-weapp组件库。 CSS库：为了小程序的样式更加美观，本项目使用Color-UI库。 3.4 云函数结构 本项目一共创建了10个云函数，大多与云数据库中的数据表一一对应。由于业务功能较多，所以使用tcb-router进行路由转发，增加服务的数量。每个云函数中的方法不再赘述，见其名就可知其意，都是基本的CURD操作。 需要说明的是： subscribeMsg函数：使用云调用，向用户推送消息（新交易提醒）。 del_trigger函数：定时触发器，每天定时删除一定时间之前的商品、问答、交易等。 transaction函数中的发起交易、取消交易、确认交易完成，以及commodity函数中的删除商品，这几个操作均涉及到多个数据表的改动，为了保障ACID(atomic, consistency, isolation, durable)，都应采用数据库事务去完成数据库的操作。 3.5 云存储结构 云存储中主要存放商品的缩略图和详情图的fileIDs、小程序背景图片及轮播图（暂未完成）。 3.6 云调用 本项目的云调用主要是实现消息推送的功能，先在小程序端获取卖家的授权，然后由买家触发推送消息的云函数。 3.7 HTTP API，后台管理及第三方服务器（暂未完成）由于参加比赛时间较晚，再加上临近开学，时间仓促，故无法完成该平台后台管理系统的搭建。待时间允许，将考虑建立后台管理系统，方便快捷地管理商品、用户、交易、轮播图的数据，通过HTTP API访问云函数，复用写好的方法，或者直接访问云数据库和云存储。 关于第三方服务器的学生验证功能，暂时还无法实现。 4. 体验二维码由于该项目涉及到信息发布内容且是个人开发，故无法上线，只有体验版。 希望日后能争取上线投入使用吧。 5. 部署教程5.1 在开发者工具中新建项目打开微信开发者工具，添加小程序项目，选择合适的文件夹，使用自己的APP ID，勾选云开发服务，新建项目。 5.2 下载代码进入到项目目录中删除所有文件，使用如下命令将代码下载到本地： 1git clone https://github.com/2horse9sun/University_O2O.git 把University_O2O文件夹中文件剪切到小程序项目根目录，删除University_O2O空文件夹 5.3 初始化云环境并修改参数点击开发者工具的云开发，启用云服务。新建自己的云环境，复制云环境ID，然后把app.js和所有cloudfunctions文件夹下所有云函数的index.js中的： 123cloud.init({ env: &quot;dreamland2-a708ef&quot; // !!!!!!替换成自己的云环境ID !!!!! 是ID，不是云环境名称}) 的env的值替换成自己的云环境ID。此处很容易漏掉app.js中的云环境ID配置！ 右击cloudfunctions，选择当前云环境。 分别右击category, commodity, commodity_question, commodity_answer, swiper, transaction, university, user云函数，选择在终端打开，输入如下命令安装依赖： 1npm install --save tcb-router 5.4 云数据库初始化打开 云开发-&gt;数据库-&gt;集合名称 建立8张数据表：category, commodity, commodity_question, commodity_answer, swiper, transaction, university, user 导入resources文件夹下相应json文件到指定数据库。 5.5 上传云存储在 云开发控制台-&gt;存储 中新建bg-image文件夹，将resources文件夹下的图片上传至云存储中。 复制index-bg.jpg的下载地址，替换下面文件的url中的值 路径：miniprogram/pages/index/index.wxss 1234567page{ background-image: url(https://6472-dreamland2-a708ef-1259161827.tcb.qcloud.la/bg-image/index-bg.jpg?sign=5a34df13fbf53f7faba83afa148618a4&amp;t=1599392559); background-repeat:no-repeat; background-size:100% 100%; -moz-background-size:100% 100%;} 复制wave.gif的下载地址，替换下面文件第二个image src的值 路径：miniprogram/pages/home/home.wxml 123456789&lt;view class=&quot;UCenter-bg&quot;&gt; &lt;image src=&quot;{{userAvatarUrl}}&quot; class=&quot;png round&quot; mode=&quot;widthFix&quot; bindtap=&quot;onEnterHomeUserInfo&quot;&gt;&lt;/image&gt; &lt;view class=&quot;text-xl margin-top&quot; bindtap=&quot;onEnterHomeUserInfo&quot;&gt;{{userName}} &lt;/view&gt; &lt;view class=&quot;margin-top-sm&quot; bindtap=&quot;onEnterHomeUserInfo&quot;&gt; &lt;text&gt;{{universityName}}&lt;/text&gt; &lt;/view&gt; &lt;image src=&quot;cloud://dreamland2-a708ef.6472-dreamland2-a708ef-1259161827/bg-image/wave.gif&quot; mode=&quot;scaleToFill&quot; class=&quot;gif-wave&quot;&gt;&lt;/image&gt;&lt;/view&gt; 复制home-bg.jpg的下载地址，替换下面文件的url中的值 路径：miniprogram/pages/home/home.wxss 12345.UCenter-bg { background-image: url(https://6472-dreamland2-a708ef-1259161827.tcb.qcloud.la/bg-image/home-bg.jpg?sign=22e94e92ece78774590d786e3bdaf35f&amp;t=1599313333); background-size: cover;............} 5.6 部署云函数在cloudfunctions下右击每个云函数，点击 上传并部署：云端安装依赖。 5.7 运行项目点击编译，运行项目。 6. 开源许可证GPL许可证","link":"/2020/11/02/2020-11-2-University-O2O/"},{"title":"算法笔记整理","text":"Abstract: 算法笔记、资源、代码。 1. Overview由于本科专业原因，一直没有系统学习过算法课；虽然参加过面试、实习、校内赛，但是对于算法的理解仍然是浅尝辄止。正值大四上学期旅游归来和西安封城之际，闲来无事翻看了UCB CS170 Efficient Algorithms and Intractable Problems的资料，感觉非常不错。于是就跟着这门课提供的资源自学，敲敲代码，写点笔记，希望毕业前能看完吧。做的笔记大多数基于课程的教材和习题，适当补充了CLRS的一些内容，以及自己的一些理解。 2. ContentsChap0 算法基础chap 0-1 算法基础-Start with Fibonacci，chap 0-2 算法基础-渐进表示法 Chap1 数论算法chap 1-1 数论算法-加减法，chap 1-2 数论算法-乘除法，chap 1-3 数论算法-模运算，chap 1-4 数论算法-欧几里得算法，chap 1-5 数论算法-素数，chap 1-6 数论算法-密码学，chap 1-7 数论算法-全域哈希，chap 1-8 数论算法-综合应用 Chap2 分治算法chap 2-1 分治算法-乘法、矩阵乘、主定理，chap 2-2 分治算法-排序和选择 $updating…$ 3. Reference UCB-CS170，Spring 2020 Introduction to Algorithms, CLRS 4. Code使用C++实现课程中的重要算法，以及一些额外的算法，存放在GitHub repo中。 $updating…$","link":"/2021/12/19/2021-12-19-algorithms-notes-overview/"},{"title":"chap 2-3 分治算法-多项式与快速傅里叶变换","text":"1. 信号处理在数字信号处理（Digital Signal Processing）领域中，经常使用到多项式乘法。信号通常是一个关于时间或位置的函数，比如捕获到的人的声音等等。数字信号处理要做的事情一般是，先对信号进行采样（sampling），使之变为离散信号；然后将离散信号输入到一个系统中（滤波器等等），最后得到系统的输出，我们称之为系统的响应（response）。 假设现在输入信号为$a(t)$，我们首先使用单位冲激（unit impulse）函数$\\delta(t)$对$a(t)$进行采样： $$\\begin{equation}\\delta(t)=\\begin{cases} 1, &amp; t=0 \\\\ 0, &amp; t\\neq 0\\end{cases}\\end{equation}$$ 若采样点数为$T$（为简化，暂且忽略采样间隔、归一化等细节），则对$a(t)$的采样为： $$a(t)=\\sum_{i=0}^{T-1}a(i)\\delta(t-i)$$ 下一步应该将离散信号输入到系统中，但是如何描述系统本身的性质？若把$\\delta(t)$输入到系统中，会得到系统对于单位冲激信号的响应$b(t)$，我们称之为该系统的冲激响应（impulse response）。若系统是线性时不变的（linear and time-invariant），则$b(t)$可以描述该系统的性质；把$a(t)$输入系统，根据上述表达式可知，系统对于$a(t)$的响应完全取决于系统的冲激响应，因此在时刻$k$系统的输出应为： $$c(k)=\\sum_{i=0}^{k}a(i)b(k-i)$$ 上述公式似乎非常眼熟。设有两个多项式$A(x)$和$B(x)$： $$A(x)=a_0+a_1x+a_2x^2+\\cdots+a_dx^d$$ $$B(x)=b_0+b_1x+b_2x^2+\\cdots+b_dx^d$$ 则它们相乘的结果$C(x)=A(x)\\cdot B(x)=c_0+c_1x+c_2x^2+\\cdots+c_{2d}x^{2d}$的系数满足： $$c_k=\\sum_{i=0}^{k}a_ib_{k-i}$$ 其中若$i&gt;d$，则令$a_i,b_i=0$。这与系统响应函数的表达式完全相同，我们通常称这个操作为卷积（convolution），记为$c(t)=a(t)*b(t)$。卷积在数字信号处理中非常重要，加快卷积的计算速度也是必然要求。 如果按照上述方法求解两个$d$次多项式的乘法，复杂度为$\\Theta(d^2)$，有没有可能降低复杂度呢？如果还是用列举系数来表示一个多项式的话，似乎很难再优化了，我们可以换一种思路，使用点值表示法。 2. 多项式乘法假设多项式$A(x)$的次数为$n-1$，系数表示法如下： $$A(x)=a_0+a_1x+a_2x^2+\\cdots+a_{n-1}x^{n-1}$$ 该多项式可以唯一地被$n$个不同的点所确定，即： $${(x_0,y_0),(x_1,y_1),\\cdots,(x_{n-1},y_{n-1})}$$ 其中，$y_k=A(x_k),(k=0,1,\\cdots,n-1)$且$x_k$各不相同。 $Proof$：本质上就是解如下的矩阵方程： $$\\begin{equation}\\begin{bmatrix}1 &amp; x_0 &amp; x_0^2 &amp; \\cdots &amp; x_0^{n-1} \\\\ 1 &amp; x_1 &amp; x_1^2 &amp; \\cdots &amp; x_1^{n-1} \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 1 &amp; x_{n-1} &amp; x_{n-1}^2 &amp; \\cdots &amp; x_{n-1}^{n-1} \\\\end{bmatrix}\\begin{bmatrix}a_0 \\\\ a_1 \\\\ \\vdots \\\\ a_{n-1} \\\\end{bmatrix}=\\begin{bmatrix}y_0 \\\\ y_1 \\\\ \\vdots \\\\ y_{n-1} \\\\end{bmatrix}\\end{equation}$$ 左边的矩阵为范德蒙矩阵，因为$x_k$各不相同，该矩阵一定可逆，故可以确定唯一的一组系数向量$\\mathbb{a}$。▮ 如果我们一直使用点值表示法来描述多项式，那么多项式的乘法就变得非常简单了，直接对两组点做点值乘法。但是这样只能得到$n$个点，而得到的多项式应该是$2n-2$次的，故需要先对点值做扩展： $$A(x):{(x_0,y_0),(x_1,y_1),\\cdots,(x_{2n-1},y_{2n-1})}$$ $$B(x):{(x_0,y_0’),(x_1,y_1’),\\cdots,(x_{2n-1},y_{2n-1}’)}$$ $$C(x)=A(x)\\cdot B(x):{(x_0,y_0y_0’),(x_1,y_1y_1’),\\cdots,(x_{2n-1},y_{2n-1}y_{2n-1}’)}$$ 使用这个方法，多项式乘法的复杂度就能降到$\\Theta(n)$。不幸的是，我们很少使用点值表示法，因为我们通常需要计算多项式在任意点处的值，而点值表示法只能给出$n$个点的值。 换个思路，我们可以只在实行多项式乘法的时候使用点值表示法；也就是说，做乘法之前先分别对两个多项式进行$2n$个点的求值（evaluation），将它转化为点值表示，然后做点乘，最后对生成的$2n$个点进行插值(interpolation)，转化为系数表示： 选择：挑选合适的$2n$个点$x_0,x_1,\\cdots,x_{2n-1}$。 求值：计算$A(x_0),A(x_1),\\cdots,A(x_{2n-1})$和$B(x_0),B(x_1),\\cdots,B(x_{2n-1})$。 点乘：$C(x_k)=A(x_k)\\cdot B(x_k)$。 插值：恢复$C(x)=c_0+c_1x+\\cdots+c_{2n-2}x^{2n-2}$。 使用这个方法，我们的主要矛盾就转移到了如何降低求值和插值的复杂度，整个算法的复杂度也取决于这两个步骤。 3. 多项式求值对于多项式$A(x)$，给定$n$个不同的点$x_0,x_1,\\cdots,x_{n-1}$，如何快速的求出$A(x_0),A(x_1),\\cdots,A(x_{n-1})$是我们现在要解决的问题。使用霍纳法则： $$A(x_k)=a_0+x_k(a_1+x_k(a_2+\\cdots+x_k(a_{n-2}+x_ka_{n-1})\\cdots))$$ 求每个点的值花费$\\Theta(n)$，求出全部的点的值需要$\\Theta(n^2)$，仍然是太慢了。但是我们忽略了一点，我们是可以随意选择这些求值点的，是否存在某种选择方法可以让求值更快一些？ 假设$n$为2的幂（若不是，就将多项式系数补零到刚大于$n$的那个2的幂），我们挑选这样的$n$个点： $$x_0,x_1,\\cdots,x_{n/2-1}$$ $$-x_0,-x_1,\\cdots,-x_{n/2-1}$$ 我们把$A(x)$按照系数位置下标的奇偶性分成两个部分： $$A_e(x^2)=a_0+a_2x^2+\\cdots+a_{n-2}x^{n-2}$$ $$xA_o(x^2)=a_1x+a_3x^3+\\cdots+a_{n-1}x^{n-1}$$ 则$A(x)$可以被表示为： $$A(x)=A_e(x^2)+xA_o(x^2)$$ 可以观察到： $$A(x_i)=A_e(x_i^2)+x_iA_o(x_i^2)$$ $$A(-x_i)=A_e(x_i^2)-x_iA_o(x_i^2)$$ 这说明，为了计算$A(x)$在$\\pm x_0,\\pm x_1,\\cdots,\\pm x_{n/2-1}$（$n$个点）处的值，我们只需要分别计算$A_e(x^2)$和$A_o(x^2)$在$x_0^2,x_1^2,\\cdots,x_{n/2-1}^2$（$n/2$个点）处的值，即把一个大小为$n$的问题转化为了两个大小为$n/2$的子问题。如果该分治策略能够顺利进行下去，将有如下的递归关系式： $$T(n)=2T(n/2)+\\Theta(n)$$ 最终的复杂度将为$\\Theta(n\\log n)$，确实大大降低。 但是这个方法只能分治一次，第一次分治我们利用加减号的对称性，将问题规模降到一半。第二次分治，我们需要对$x_0^2,x_1^2,\\cdots,x_{n/2-1}^2$求值，但是我们再也不能找到一种分割方法，仅对一半点求值，就能计算出全部点的值。原因很显然，平方操作让这种加减对称性消失了。是否存在某些点，对其进行平方，仍然存在某种对称性？那就必须要引入复数了。 设复数$\\omega$满足方程$\\omega^n=1$，$n$次单位复数根恰好有$n$个，这些根为： $$\\omega_n^k=e^{2\\pi ik/n}$$ 我们称$\\omega_n=e^{2\\pi i/n}$为主$n$次单位根，其余根都是它的幂次。 若我们选取$\\omega_n^0,\\omega_n^1,\\omega_n^2,\\cdots,\\omega_n^{n-1}$作为$n$个求值点，则可以推出： $$\\begin{equation}\\begin{aligned}A(\\omega_n^k)&amp; = A_e(\\omega_n^{2k})+\\omega_n^kA_o(\\omega_n^{2k}) \\\\ &amp;= A_e(\\omega_{n/2}^{k})+\\omega_n^kA_o(\\omega_{n/2}^{k})\\end{aligned}\\end{equation}$$ $$\\begin{equation}\\begin{aligned}A(\\omega_n^{k+n/2})&amp; = A_e(\\omega_n^{2k+n})+\\omega_n^{k+n/2}A_o(\\omega_n^{2k+n}) \\\\ &amp;= A_e(\\omega_{n}^{2k})-\\omega_n^kA_o(\\omega_{n}^{2k}) \\\\ &amp;= A_e(\\omega_{n/2}^{k})-\\omega_n^kA_o(\\omega_{n/2}^{k})\\end{aligned}\\end{equation}$$ 其中$k=0,1,2,\\cdots,n/2-1$。 为了计算$A(x)$在$\\omega_n^0,\\omega_n^1,\\omega_n^2,\\cdots,\\omega_n^{n-1}$（$n$个点）处的值，我们只需要分别计算$A_e(x^2)$和$A_o(x^2)$在$\\omega_{n/2}^0,\\omega_{n/2}^1,\\omega_{n/2}^2,\\cdots,\\omega_{n/2}^{n/2-1}$（$n/2$个点）处的值，并且可以一直分治下去。该算法的复杂度为$O(n\\log n)$。 3. 快速傅里叶变换（FFT）假设有$n-1$次多项式$A(x)$： $$A(x)=\\sum_{j=0}^{n-1}a_jx^j$$ 计算$A(x)$在$n$个$n$次单位复数根$\\omega_n^0,\\omega_n^1,\\omega_n^2,\\cdots,\\omega_n^{n-1}$处的值，定义结果$y_k$： $$y_k=A(x_n^k)=\\sum_{j=0}^{n-1}a_j\\omega_n^{kj}$$ 则我们称向量$\\mathbb{y}=(y_0,y_1,\\cdots,y_{n-1})$就是系数向量$\\mathbb{a}=(a_0,a_1,\\cdots,a_{n-1})$的离散傅里叶变换（Discrete Fourier Transform, DFT），记为$y=DFT_n(\\mathbb{a})$。（其他数字信号处理教材中，$\\omega_n^{ki}$应该为$\\omega_n^{-ki}$，算法导论里的没有负号，不过不影响） 我们按上述方法对多项式进行求值，其实就是对多项式系数做了一次DFT；采用上述分治法和利用复数根特殊性质来求解DFT的过程，被称为快速傅里叶变换（Fast Fourier Transform, FFT）。递归公式： $$\\begin{equation}\\begin{aligned}y[k]&amp; = y_e[k]+\\omega_n^ky_o[k]\\end{aligned}\\end{equation}$$ $$\\begin{equation}\\begin{aligned}y[n/2+k]&amp; = y_e[k]-\\omega_n^ky_o[k]\\end{aligned}\\end{equation}$$ 下面是使用递归法求解向量$\\mathbb{a}=(a_0,a_1,\\cdots,a_{n-1})$的FFT的步骤： 12345678910111213141516do_recursive_FFT(a): n = a.length if n==1: return a w_n为主n次单位根 w = 1 a_e = [a[0], a[2], ..., a[n-2]] a_o = [a[1], a[3], ..., a[n-1]] y_e = do_recursive_FFT(a_e) y_o = do_recursive_FFT(a_o) for k=0 to n/2-1: y[k] = y_e[k] + w*y_o[k] y[k+n/2] = y_e[k] - w*y_o[k] w = w * w_n return y 下面我们再从矩阵的角度整体回顾一下FFT的原理。 对多项式$A(x)$在$x_0,x_1,\\cdots,x_{n-1}$处取值，可以写成矩阵形式： $$\\begin{equation}\\begin{bmatrix}y_0 \\\\ y_1 \\\\ \\vdots \\\\ y_{n-1}\\end{bmatrix}=\\begin{bmatrix}1 &amp; x_0 &amp; x_0^2 &amp; \\cdots &amp; x_0^{n-1} \\\\ 1 &amp; x_1 &amp; x_1^2 &amp; \\cdots &amp; x_1^{n-1} \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 1 &amp; x_{n-1} &amp; x_{n-1}^2 &amp; \\cdots &amp; x_{n-1}^{n-1}\\end{bmatrix}\\begin{bmatrix}a_0 \\\\ a_1 \\\\ \\vdots \\\\ a_{n-1}\\end{bmatrix}\\end{equation}$$ 记矩阵为$M$。若在$n$个$n$次单位复数根$\\omega_n^0,\\omega_n^1,\\omega_n^2,\\cdots,\\omega_n^{n-1}$处取值，即做DFT操作，则可以表达为： $$\\begin{equation}\\begin{bmatrix}y_0 \\\\ y_1 \\\\ y_2 \\\\ y_3 \\\\ \\vdots \\\\ y_{n-1}\\end{bmatrix}=\\begin{bmatrix}1 &amp; 1 &amp; 1 &amp; 1 &amp; \\cdots &amp; 1\\\\ 1 &amp; \\omega_n^{1} &amp; \\omega_n^{2} &amp; \\omega_n^{3} &amp; \\cdots &amp; \\omega_n^{n-1} \\\\ 1 &amp; \\omega_n^{2} &amp; \\omega_n^{4} &amp; \\omega_n^{6} &amp; \\cdots &amp; \\omega_n^{2(n-1)} \\\\ 1 &amp; \\omega_n^{3} &amp; \\omega_n^{6} &amp; \\omega_n^{9} &amp; \\cdots &amp; \\omega_n^{3(n-1)} \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 1 &amp; \\omega_n^{n-1} &amp; \\omega_n^{2(n-1)} &amp; \\omega_n^{3(n-1)} &amp; \\cdots &amp; \\omega_n^{(n-1)(n-1)}\\end{bmatrix}\\begin{bmatrix}a_0 \\\\ a_1 \\\\ a_2 \\\\ a_3 \\\\ \\vdots \\\\ a_{n-1}\\end{bmatrix}\\end{equation}$$ 记矩阵为$M=M_n(\\omega)$，其中$M(j,k)=\\omega_n^{jk}$。在FFT算法中，我们首先根据系数下标的奇偶性，把系数分成了两个部分，重新排列系数矩阵的列以及系数向量的行： $$\\begin{equation}\\begin{bmatrix}y_0 \\\\ y_1 \\\\ y_2 \\\\ y_3 \\\\ \\vdots \\\\ y_{n-1}\\end{bmatrix}=\\begin{bmatrix}1 &amp; 1 &amp; 1 &amp; \\cdots &amp; 1 &amp; 1 &amp; 1 &amp; \\cdots \\\\ 1 &amp; \\omega_n^{2} &amp; \\omega_n^{4} &amp; \\cdots &amp; \\omega_n^{1} &amp; \\omega_n^{3} &amp; \\omega_n^{5} &amp; \\cdots \\\\ 1 &amp; \\omega_n^{4} &amp; \\omega_n^{8} &amp; \\cdots &amp; \\omega_n^{2} &amp; \\omega_n^{6} &amp; \\omega_n^{10} &amp; \\cdots \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots \\\\ 1 &amp; \\omega_n^{2n/2} &amp; \\omega_n^{4n/2} &amp; \\cdots &amp; \\omega_n^{n/2} &amp; \\omega_n^{3n/2} &amp; \\omega_n^{5n/2} &amp; \\cdots \\\\ 1 &amp; \\omega_n^{2n/2+2} &amp; \\omega_n^{4n/2+4} &amp; \\cdots &amp; \\omega_n^{n/2+1} &amp; \\omega_n^{3n/2+3} &amp; \\omega_n^{5n/2+5} &amp; \\cdots \\\\ 1 &amp; \\omega_n^{2n/2+4} &amp; \\omega_n^{4n/2+8} &amp; \\cdots &amp; \\omega_n^{n/2+2} &amp; \\omega_n^{3n/2+6} &amp; \\omega_n^{5n/2+10} &amp; \\cdots \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots\\end{bmatrix}\\begin{bmatrix}a_0 \\\\ a_2 \\\\ a_4 \\\\ \\vdots \\\\ a_1 \\\\ a_3 \\\\ a_5 \\\\ \\vdots\\end{bmatrix}\\end{equation}$$ 利用复数根的性质，继续化简上式： $$\\begin{equation}\\begin{bmatrix}y_0 \\\\ y_1 \\\\ y_2 \\\\ y_3 \\\\ \\vdots \\\\ y_{n-1}\\end{bmatrix}=\\begin{bmatrix}1 &amp; 1 &amp; 1 &amp; \\cdots &amp; \\omega_n^{0}\\cdot 1 &amp; \\omega_n^{0}\\cdot1 &amp; \\omega_n^{0}\\cdot1 &amp; \\cdots \\\\ 1 &amp; \\omega_n^{2} &amp; \\omega_n^{4} &amp; \\cdots &amp; \\omega_n^{1}\\cdot 1 &amp; \\omega_n^{1}\\cdot\\omega_n^{2} &amp; \\omega_n^{1}\\cdot\\omega_n^{4} &amp; \\cdots \\\\ 1 &amp; \\omega_n^{4} &amp; \\omega_n^{8} &amp; \\cdots &amp; \\omega_n^{2}\\cdot 1 &amp; \\omega_n^{2}\\cdot\\omega_n^{4} &amp; \\omega_n^{2}\\cdot\\omega_n^{8} &amp; \\cdots \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots \\\\ 1 &amp; 1 &amp; 1 &amp; \\cdots &amp; \\omega_n^{n/2}\\cdot 1 &amp; \\omega_n^{n/2}\\cdot 1 &amp; \\omega_n^{n/2}\\cdot 1 &amp; \\cdots \\\\ 1 &amp; \\omega_n^{2} &amp; \\omega_n^{4} &amp; \\cdots &amp; \\omega_n^{n/2+1}\\cdot 1 &amp; \\omega_n^{n/2+1}\\cdot\\omega_n^{2} &amp; \\omega_n^{n/2+1}\\cdot\\omega_n^{4} &amp; \\cdots \\\\ 1 &amp; \\omega_n^{4} &amp; \\omega_n^{8} &amp; \\cdots &amp; \\omega_n^{n/2+2}\\cdot 1 &amp; \\omega_n^{n/2+2}\\cdot\\omega_n^{4} &amp; \\omega_n^{n/2+2}\\cdot\\omega_n^{8} &amp; \\cdots \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots\\end{bmatrix}\\begin{bmatrix}a_0 \\\\ a_2 \\\\ a_4 \\\\ \\vdots \\\\ a_1 \\\\ a_3 \\\\ a_5 \\\\ \\vdots\\end{bmatrix}\\end{equation}$$ 观察发现，上式中的矩阵可以分成四个部分，每个部分都含有一个公共的矩阵$M_{n/2}(\\omega^2)$： $$\\begin{equation}\\begin{bmatrix} y_0 \\\\ y_1 \\\\ y_2 \\\\ y_3 \\\\ \\vdots \\\\ y_{n-1} \\end{bmatrix} = \\begin{bmatrix} \\begin{bmatrix} 1 &amp; 1 &amp; 1 &amp; \\cdots \\\\ 1 &amp; \\omega_n^{2} &amp; \\omega_n^{4} &amp; \\cdots \\\\ 1 &amp; \\omega_n^{4} &amp; \\omega_n^{8} &amp; \\cdots \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots \\end{bmatrix} \\begin{bmatrix} a_0 \\\\ a_2 \\\\ a_4 \\\\ \\vdots \\end{bmatrix} + \\begin{bmatrix} \\omega_n^{0} \\\\ \\omega_n^{1} \\\\ \\omega_n^{2} \\\\ \\vdots \\end{bmatrix}^T \\begin{bmatrix} 1 &amp; 1 &amp; 1 &amp; \\cdots \\\\ 1 &amp; \\omega_n^{2} &amp; \\omega_n^{4} &amp; \\cdots \\\\ 1 &amp; \\omega_n^{4} &amp; \\omega_n^{8} &amp; \\cdots \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots \\end{bmatrix} \\begin{bmatrix} a_1 \\\\ a_3 \\\\ a_5 \\\\ \\vdots\\end{bmatrix} \\\\ \\begin{bmatrix} 1 &amp; 1 &amp; 1 &amp; \\cdots \\\\ 1 &amp; \\omega_n^{2} &amp; \\omega_n^{4} &amp; \\cdots \\\\ 1 &amp; \\omega_n^{4} &amp; \\omega_n^{8} &amp; \\cdots \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots \\end{bmatrix} \\begin{bmatrix} a_0 \\\\ a_2 \\\\ a_4 \\\\ \\vdots \\end{bmatrix} - \\begin{bmatrix}\\omega_n^{0} \\\\ \\omega_n^{1} \\\\ \\omega_n^{2} \\\\ \\vdots \\end{bmatrix}^T \\begin{bmatrix} 1 &amp; 1 &amp; 1 &amp; \\cdots \\\\ 1 &amp; \\omega_n^{2} &amp; \\omega_n^{4} &amp; \\cdots \\\\ 1 &amp; \\omega_n^{4} &amp; \\omega_n^{8} &amp; \\cdots \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots \\end{bmatrix} \\begin{bmatrix} a_1 \\\\ a_3 \\\\ a_5 \\\\ \\vdots \\end{bmatrix} \\end{bmatrix} \\end{equation}$$ 即： $$\\begin{equation} \\begin{bmatrix} y_0 \\\\ y_1 \\\\ y_2 \\\\ y_3 \\\\ \\vdots \\\\ y_{n-1} \\end{bmatrix} = M_n(\\omega) \\begin{bmatrix} a_0 \\\\ a_1 \\\\ a_2 \\\\ a_3 \\\\ a_4 \\\\ \\vdots \\\\ a_{n-1} \\end{bmatrix} = \\begin{bmatrix} M_{n/2}(\\omega^2) \\begin{bmatrix} a_0 \\\\ a_2 \\\\ a_4 \\\\ \\vdots \\end{bmatrix} + \\begin{bmatrix} \\omega_n^{0} \\\\ \\omega_n^{1} \\\\ \\omega_n^{2} \\\\ \\vdots \\end{bmatrix}^T M_{n/2}(\\omega^2) \\begin{bmatrix} a_1 \\\\ a_3 \\\\ a_5 \\\\ \\vdots \\end{bmatrix} \\\\ M_{n/2}(\\omega^2) \\begin{bmatrix} a_0 \\\\ a_2 \\\\ a_4 \\\\ \\vdots \\end{bmatrix} - \\begin{bmatrix} \\omega_n^{0} \\\\ \\omega_n^{1} \\\\ \\omega_n^{2} \\\\ \\vdots \\end{bmatrix}^T M_{n/2}(\\omega^2) \\begin{bmatrix} a_1 \\\\ a_3 \\\\ a_5 \\\\ \\vdots \\end{bmatrix} \\end{bmatrix} \\end{equation}$$ 观察发现，FFT的本质就是把$M_n(\\omega)$乘以向量$(a_0,a_1,\\cdots,a_{n-1})^T$的问题转化成了$M_{n/2}(\\omega^2)$乘以向量$(a_0,a_2,\\cdots,a_{n-2})^T$和$M_{n/2}(\\omega^2)$乘以向量$(a_1,a_3,\\cdots,a_{n-1})^T$的两个子问题，有如下的递归关系式： $$T(n)=2T(n/2)+\\Theta(n)$$ 最终的复杂度为$\\Theta(n\\log n)$。 4. 高效FFT实现在实际应用中，DFT同时要求较低的时间和空间复杂度，FFT的递归实现占用大量空间，下面介绍FFT的迭代实现方法，将比递归版快一些，而且占用更少的空间。 首先分析一下递归FFT的运行过程，画出如下的递归树： 我们需要模拟递归中自底向上的计算过程。首先注意到，数组元素的次序在最底层是被打乱的，出现的顺序是原数组的位逆序置换。比如做8点DFT时，最底层的第001（1）个元素应该是原数组的第100（4）个元素。实际操作中，通常提前准备好bit-reverse lookup table，达到$O(1)$的位逆序置换速度。 从最底层开始，成对取出元素，做一次蝴蝶操作计算出每对的DFT，用其DFT取代这对元素： $$t =\\omega_n^ky_o[k]$$ $$\\begin{equation}\\begin{aligned}y[k]&amp; = y_e[k]+t\\end{aligned}\\end{equation}$$ $$\\begin{equation}\\begin{aligned}y[n/2+k]&amp; = y_e[k]-t\\end{aligned}\\end{equation}$$ 这样向量中就包含了$n/2$个二元素的DFT。然后，按对取出这$n/2$个元素的DFT，通过两次蝴蝶操作计算出四元素向量的DFT。以此类推，最终我们就得到了一个具有$n$元素的DFT。 设当前自底向上所处递归树的层次为$s$，最底层为$s=1$，则每次应该取出$m=2^s$个元素做蝴蝶操作。每次蝴蝶操作就是把$A[k:k+m/2-1]$和$A[k+m/2:k+m-1]$两个数组合并成$A[k:k+m-1]$。伪代码如下： 123456789101112131415do_iterative_FFT(a): A = bit_reverse(a) n = a.length for s=1 to log2(n): m = 2^s w_m为主m次单位根 for k = 0 to n-1 by m: w = 1 for j = 0 to m/2-1: u = A[k+j] t = A[k+m/2+j] A[k+j] = u + t A[k+m/2+j] = u - t w = w * w_mreturn A 复杂度计算： $$T(n)=\\sum_{s=1}^{\\log n}\\frac{n}{2^s}\\cdot 2^{s-1}=\\Theta(n\\log n)$$ 再次观察递归树，我们发现每一层的计算其实可以改为并行操作，因为它们之间没有依赖性。故可以设计出下面的并行FFT电路，深度为$\\Theta(\\log n)$级，这也是实际硬件中使用的电路模型： 5. 多项式插值与IFFT回到多项式乘法的主题上来，我们使用了FFT使对$2n$个点求值这一步的复杂度降低到了$\\Theta(n\\log n)$，之后对这$2n$个点进行点乘。现在还差最后一步操作，就是对$2n$个点插值，得到乘积多项式的系数向量。再次回顾一下这个等式： $$\\begin{equation}\\begin{bmatrix}y_0 \\\\ y_1 \\\\ y_2 \\\\ y_3 \\\\ \\vdots \\\\ y_{n-1}\\end{bmatrix}=\\begin{bmatrix}1 &amp; 1 &amp; 1 &amp; 1 &amp; \\cdots &amp; 1\\\\ 1 &amp; \\omega_n^{1} &amp; \\omega_n^{2} &amp; \\omega_n^{3} &amp; \\cdots &amp; \\omega_n^{n-1} \\\\ 1 &amp; \\omega_n^{2} &amp; \\omega_n^{4} &amp; \\omega_n^{6} &amp; \\cdots &amp; \\omega_n^{2(n-1)} \\\\ 1 &amp; \\omega_n^{3} &amp; \\omega_n^{6} &amp; \\omega_n^{9} &amp; \\cdots &amp; \\omega_n^{3(n-1)} \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 1 &amp; \\omega_n^{n-1} &amp; \\omega_n^{2(n-1)} &amp; \\omega_n^{3(n-1)} &amp; \\cdots &amp; \\omega_n^{(n-1)(n-1)}\\end{bmatrix}\\begin{bmatrix}a_0 \\\\ a_1 \\\\ a_2 \\\\ a_3 \\\\ \\vdots \\\\ a_{n-1}\\end{bmatrix}\\end{equation}$$ 现在我们知道了$\\mathbb{y}$和$M_n(\\omega)$，需要求出$\\mathbb{a}$。由于$M_n(\\omega)$一定可逆，所以： $$\\begin{equation}\\begin{bmatrix}a_0 \\\\ a_1 \\\\ a_2 \\\\ a_3 \\\\ \\vdots \\\\ a_{n-1}\\end{bmatrix}=M_n(\\omega)^{-1}\\begin{bmatrix}y_0 \\\\ y_1 \\\\ y_2 \\\\ y_3 \\\\ \\vdots \\\\ y_{n-1}\\end{bmatrix}\\end{equation}$$ 那么$M_n(\\omega)$的逆矩阵等于多少呢？我们构造一个矩阵$M_n(\\omega)^*$，里面的每个元素都是$M_n(\\omega)$对应元素的共轭。那么$M_n(\\omega)M_n(\\omega)^*$的$(j,k)$位置元素的值为： $$1+\\omega_n^{j-k}+\\omega_n^{2(j-k)}+\\omega_n^{3(j-k)}+\\cdots+\\omega_n^{(n-1)(j-k)}$$ 当$j=k$时，结果为$n$；当$j\\neq k$时，结果为$(1-\\omega_n^{n(j-k)})/(1-\\omega_n^{j-k})=0$。我们发现： $$M_n(\\omega)M_n(\\omega)^*=nI$$ 可以看出，$M_n(\\omega)^{-1}=\\frac{1}{n}M_n(\\omega)^*=\\frac{1}{n}M_n(\\omega^{-1})$。利用这个结论，可以直接写出逆DFT的表达式： $$\\mathbb{a}=DFT^{-1}_n(\\mathbb{y})$$ $$a_k=\\frac{1}{n}\\sum_{j=0}^{n-1}y_j\\omega_n^{-jk}$$ 计算逆FFT的方式很简单，在原FFT程序中将$\\mathbb{a}$和$\\mathbb{y}$互换，用$\\omega_n^{-1}$替换$\\omega_n$，并将计算结果的每个元素都除以$n$即可。复杂度仍然是$\\Theta(n\\log n)$。 总结一下，多项式乘法的过程可以用卷积定理来说明： 对于任意两个向量$\\mathbb{a}$和$\\mathbb{b}$，将它们的长度补零至$2n$，$n$为2的幂，则： $$\\mathbb{a}*\\mathbb{b}=DFT_{2n}^{-1}(DFT_{2n}(\\mathbb{a})\\cdot DFT_{2n}(\\mathbb{b}))$$ 其中$*$表示卷积，$\\cdot$表示点乘。计算DFT的过程可以使用FFT算法。 下面的图也清晰地描述了使用FFT求解多项式乘法的过程： 我们把多项式中的$x$换成$2$或者$10$，可以发现多项式的系数向量可以表示一个以2或10为base的数，这就意味着可以使用FFT求解整数乘法，复杂度为$\\Theta(n\\log n)$，比以前介绍过的任何一种乘法算法都要快！ Quick Link: 算法笔记整理","link":"/2022/01/13/2022-01-13-algorithms-notes-chap2-3-fft/"}],"tags":[{"name":"Interview","slug":"Interview","link":"/tags/Interview/"},{"name":"C++","slug":"C","link":"/tags/C/"},{"name":"Algorithms-Notes","slug":"Algorithms-Notes","link":"/tags/Algorithms-Notes/"},{"name":"Sorting","slug":"Sorting","link":"/tags/Sorting/"},{"name":"Statistics","slug":"Statistics","link":"/tags/Statistics/"},{"name":"Divide and Conquer","slug":"Divide-and-Conquer","link":"/tags/Divide-and-Conquer/"},{"name":"Number Theory","slug":"Number-Theory","link":"/tags/Number-Theory/"},{"name":"Hashing","slug":"Hashing","link":"/tags/Hashing/"},{"name":"Cryptography","slug":"Cryptography","link":"/tags/Cryptography/"},{"name":"Internet","slug":"Internet","link":"/tags/Internet/"},{"name":"Database","slug":"Database","link":"/tags/Database/"},{"name":"Web APP","slug":"Web-APP","link":"/tags/Web-APP/"},{"name":"FFT","slug":"FFT","link":"/tags/FFT/"}],"categories":[{"name":"Blog","slug":"Blog","link":"/categories/Blog/"},{"name":"Essay","slug":"Essay","link":"/categories/Essay/"},{"name":"Project","slug":"Project","link":"/categories/Project/"}]}